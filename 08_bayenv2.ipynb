{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### from __future__ import division\n",
    "import sys\n",
    "from ipyparallel import Client\n",
    "import os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from fractions import Fraction\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "import vcf\n",
    "import random\n",
    "from geopy.distance import vincenty\n",
    "import math\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from os import path as op\n",
    "from os import listdir as ls\n",
    "import shutil\n",
    "from scipy.stats import hmean\n",
    "from skbio.stats.distance import mantel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make SNPSFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stpDF = pd.read_csv('/home/lindb/wbp/sampsTOpop.txt',header=0,sep=\"\\t\")\n",
    "stpDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pops = np.unique(stpDF['pop']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popDict = OrderedDict()\n",
    "for row in stpDF.index:\n",
    "    pop = stpDF.loc[row,'pop']\n",
    "    samp = stpDF.loc[row,'sampID']\n",
    "    if not pop in popDict.keys():\n",
    "        popDict[pop] = []\n",
    "    popDict[pop].append(samp)\n",
    "for pop in popDict.keys():\n",
    "    print pop,len(popDict[pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time data = pd.read_csv('/home/lindb/wbp/bayenv2/imputed_z12_maf_swp_trans_z12.txt',header=0,index_col=0,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popDictImp = OrderedDict()\n",
    "for pop in sorted(pops):\n",
    "    popDictImp[pop]  = data[data.index.isin(popDict[pop])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total  = 0\n",
    "for pop in popDictImp.keys():\n",
    "    print pop, len(popDictImp[pop])\n",
    "    total = total + len(popDictImp[pop])\n",
    "print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popDictImp['Dicks_Pass']['NODE_1000013_length_91_cov_1.802198_37'].tolist().count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just a test\n",
    "locCount = 0\n",
    "bayDict = OrderedDict()\n",
    "for locus in data.columns:\n",
    "    bayDict[locus] = OrderedDict()\n",
    "    popCount = 0\n",
    "    for pop in sorted(pops):\n",
    "        \n",
    "        zero = popDictImp[pop][locus].tolist().count(0) #count the first homozygotes\n",
    "        one = popDictImp[pop][locus].tolist().count(1) #count the heterozygotes\n",
    "        two = popDictImp[pop][locus].tolist().count(2) #count the second homozygotes        \n",
    "        \n",
    "        A1 = 2*zero + one #count of global major allele\n",
    "        A2 = 2*two + one #count of global minor allele\n",
    "        \n",
    "        if len(bayDict[locus].keys()) == 0:\n",
    "            bayDict[locus]['A1'] = OrderedDict()\n",
    "            bayDict[locus]['A2'] = OrderedDict()\n",
    "        bayDict[locus]['A1'][pop] = A1\n",
    "        bayDict[locus]['A2'][pop] = A2\n",
    "        #break\n",
    "    locCount += 1\n",
    "    if locCount % 10 == 0:\n",
    "        print locCount\n",
    "        break \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for locus in bayDict.keys():\n",
    "    count = 0\n",
    "    for allele in bayDict[locus].keys():\n",
    "        for pop in bayDict[locus][allele].keys():\n",
    "            count = count + bayDict[locus][allele][pop]\n",
    "    print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure allele counts are correct\n",
    "filE = '/home/lindb/wbp/bayenv2/testUnbinnedImputedSNPSFILE.txt'\n",
    "with open(filE, 'w') as o:\n",
    "    line = '\\t'.join([str(pop) for pop in bayDict[bayDict.keys()[0]][bayDict[bayDict.keys()[0]].keys()[0]].keys()]) + str('\\n')\n",
    "    o.write(\"%s\" % line)\n",
    "    for locus in bayDict.keys():\n",
    "        for allele in bayDict[locus].keys():\n",
    "            line = str(locus) + '\\t' + '\\t'.join([str(x) for x in bayDict[locus][allele].values()]) + str('\\n')\n",
    "            #print locus,allele,line\n",
    "            o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#because it's way faster this way\n",
    "text = '''from __future__ import division\n",
    "import sys\n",
    "from ipyparallel import Client\n",
    "import os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from fractions import Fraction\n",
    "from collections import defaultdict, OrderedDict\n",
    "import vcf\n",
    "import random\n",
    "\n",
    "filE1 = '/home/lindb/wbp/bayenv2/update.txt'\n",
    "with open(filE1,'w') as o:\n",
    "    text = 'reading stpDF\\\\n'\n",
    "    o.write(\"%s\" % text)\n",
    "    \n",
    "stpDF = pd.read_csv('/home/lindb/wbp/sampsTOpop.txt',header=0,sep=\"\\\\t\")\n",
    "\n",
    "pops = np.unique(stpDF['pop']).tolist()\n",
    "\n",
    "popDict = OrderedDict()\n",
    "for row in stpDF.index:\n",
    "    pop = stpDF.loc[row,'pop']\n",
    "    samp = stpDF.loc[row,'sampID']\n",
    "    if not pop in popDict.keys():\n",
    "        popDict[pop] = []\n",
    "    popDict[pop].append(samp)\n",
    "\n",
    "with open(filE1,'a') as o:\n",
    "    text = 'reading data\\\\n'\n",
    "    o.write(\"%s\" % text)\n",
    "    \n",
    "data = pd.read_csv('/home/lindb/wbp/bayenv2/imputed_z12_maf_swp_trans_z12.txt',header=0,index_col=0,sep=\"\\\\t\")\n",
    "\n",
    "popDictImp = OrderedDict()\n",
    "for pop in sorted(pops):\n",
    "    popDictImp[pop]  = data[data.index.isin(popDict[pop])]\n",
    "    \n",
    "with open(filE1,'a') as o:\n",
    "    text = 'iterating loci\\\\n'\n",
    "    o.write(\"%s\" % text)\n",
    "\n",
    "locCount = 0\n",
    "bayDict = OrderedDict()\n",
    "for locus in data.columns:\n",
    "    bayDict[locus] = OrderedDict()\n",
    "    popCount = 0\n",
    "    for pop in sorted(pops):\n",
    "        \n",
    "        zero = popDictImp[pop][locus].tolist().count(0) #count the first homozygotes\n",
    "        one = popDictImp[pop][locus].tolist().count(1) #count the heterozygotes\n",
    "        two = popDictImp[pop][locus].tolist().count(2) #count the second homozygotes        \n",
    "        \n",
    "        A1 = 2*zero + one\n",
    "        A2 = 2*two + one\n",
    "        \n",
    "        if len(bayDict[locus].keys()) == 0:\n",
    "            bayDict[locus]['A1'] = OrderedDict()\n",
    "            bayDict[locus]['A2'] = OrderedDict()\n",
    "        bayDict[locus]['A1'][pop] = A1\n",
    "        bayDict[locus]['A2'][pop] = A2\n",
    "        #break\n",
    "    locCount += 1\n",
    "    if locCount % 1000 == 0:\n",
    "        print locCount\n",
    "        with open(filE1,'a') as o:\n",
    "            text = \"%s\\\\n\" % str(locCount)\n",
    "            o.write(\"%s\" % text)\n",
    "        #break\n",
    "    #break\n",
    "\n",
    "filE = '/home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE.txt'\n",
    "with open(filE, 'w') as o:\n",
    "    line = '\\\\t'.join([str(pop) for pop in bayDict[bayDict.keys()[0]][bayDict[bayDict.keys()[0]].keys()[0]].keys()]) + str('\\\\n')\n",
    "    o.write(\"%s\" % line)\n",
    "    for locus in bayDict.keys():\n",
    "        for allele in bayDict[locus].keys():\n",
    "            line = str(locus) + '\\\\t' + '\\\\t'.join([str(x) for x in bayDict[locus][allele].values()]) + str('\\\\n')\n",
    "            #print locus,allele,line\n",
    "            o.write(\"%s\" % line)\n",
    "with open(filE1,'a') as o:\n",
    "    text = 'Done!\\\\n'\n",
    "    o.write(\"%s\" % text)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/wbp/bayenv2/get_SNPSFILE.py'\n",
    "with open(filE,'w') as o:\n",
    "    o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shtext = '''#!/bin/bash\n",
    "#$ -N snpsfile\n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd /home/lindb/wbp/bayenv2/\n",
    "python get_SNPSFILE.py\n",
    "\n",
    "'''\n",
    "filE = '/home/lindb/wbp/bayenv2/get_SNPSFILE.sh'\n",
    "with open(filE,'w') as o:\n",
    "    o.write(\"%s\" % shtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!qsub /home/lindb/wbp/bayenv2/get_SNPSFILE.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impbayenv = pd.read_csv('/home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "impbayenv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impbayenv.to_csv('/home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE_NOHEADERIDX.txt',header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate MATRIXFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.randint(100,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shtext = '''#!/bin/bash\n",
    "#$ -N matrixfile\n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd /home/lindb/wbp/bayenv2/\n",
    "./bayenv2 -i UnbinnedImputedSNPSFILE_NOHEADERIDX.txt -p 8 -k 100000 -r %d > matrix.out\n",
    "\n",
    "''' % random.randint(100,100000)\n",
    "filE = '/home/lindb/wbp/bayenv2/get_MATRIXFILE.sh'\n",
    "with open(filE,'w') as o:\n",
    "    o.write(\"%s\" % shtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!qsub /home/lindb/wbp/bayenv2/get_MATRIXFILE.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make ENVIRONFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/lindb/wbp/WBP_IDS_MATCHED_POP_FINAL_02162016.csv',header=0,sep=\"\\t\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test.columns[10:-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.columns[8:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envdf = pd.DataFrame(data=[],columns=sorted(pops))\n",
    "envCount = 0\n",
    "for col in test.columns[8:-11]: #for each environmental variable\n",
    "    popMeans = [] #I'm averaging over the plots to get one measurement per population\n",
    "    for pop in sorted(pops): #for each population\n",
    "        data = test[test['Population_ID']==pop] # grab all data for samples in that pop\n",
    "        popMean = np.mean(np.unique([x for x in data[col] if math.isnan(x) == False]).tolist())\n",
    "        popMeans.append(popMean)\n",
    "\n",
    "    mean = np.mean([float(x) for x in popMeans])\n",
    "    std = np.std([float(x) for x in popMeans])\n",
    "    est = [((x-mean)/(std)) for i,x in enumerate(popMeans)]\n",
    "    envdf.loc[envCount,] = est\n",
    "    envCount += 1\n",
    "envdf.index = test.columns[8:-11]\n",
    "envdf.sort_index(inplace=True)\n",
    "envdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename them for usage\n",
    "envdf.index = ['AWS0-25',\n",
    " 'AWS0-50',\n",
    " 'Ann-ppt',\n",
    " 'CEC',\n",
    " 'Clay',\n",
    " 'Elev',\n",
    " 'GDD-Aug',\n",
    " 'GDD-May',\n",
    " 'Sand',\n",
    " 'Silt',\n",
    " 'Tmax-July',\n",
    " 'Tmin-Jan',\n",
    " 'WC15Bar',\n",
    " 'WC3rdbar',\n",
    " 'Lat',\n",
    " 'Lon',\n",
    " 'Max-rad-input',\n",
    " 'Rock-cov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "envdf[''] = \"\"\n",
    "envdf.sort_index(inplace=True)\n",
    "envdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "envdf.to_csv('/home/lindb/wbp/bayenv2/ENVIRONFILE.txt',header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "envdf.to_csv('/home/lindb/wbp/bayenv2/ENVIRONFILE_headerIDX.txt',header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make usable matrix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixfile = open('/home/lindb/wbp/bayenv2/matrix.out')\n",
    "r = matrixfile.readlines()\n",
    "usable = '/home/lindb/wbp/bayenv2/usable_matrix.txt'\n",
    "with open(usable,'w') as o:\n",
    "    for line in r[2005:][:-1]:\n",
    "        o.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "umat = pd.read_csv(usable,header=None,sep=\"\\t\")\n",
    "umat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "umat.loc[:,:7].to_csv(usable,header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "umat = umat.loc[:,:7]\n",
    "umat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make bayenv .sh files - 1st chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we did a runthrough once (code in this section) and found that one chain isn't enough and can give spurious results \n",
    "    #depending on the seed given\n",
    "#below this section here we've written code to do the remaining 4 chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpdir = '/home/lindb/wbp/bayenv2/snps/'\n",
    "if not os.path.exists(snpdir):\n",
    "    os.makedirs(snpdir)\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/bayenv2',os.path.join(snpdir,'bayenv2'))\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/ENVIRONFILE.txt',os.path.join(snpdir,'ENVIRONFILE.txt'))\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE_NOHEADERIDX.txt',\n",
    "                os.path.join(snpdir,'UnbinnedImputedSNPSFILE_NOHEADERIDX.txt'))\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/usable_matrix.txt',os.path.join(snpdir,'usable_matrix.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpsfile = pd.read_csv('/home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "snpsfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make SNPFILEs by using the SNP as the name of the file - will be easier reading the bf.environ.ENVIRONFILE.txt\n",
    "df = snpsfile\n",
    "for j in range(0,len(df.index),2):\n",
    "    DF = df.loc[df.index[j],:]\n",
    "    dfile = os.path.join(snpdir,df.index[j])\n",
    "    DF.to_csv(dfile,header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv = os.listdir(snpdir)\n",
    "bayenv = sorted([os.path.join(snpdir,f) for f in bayenv if 'NODE' in f])\n",
    "len(bayenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_jobs = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_chunks = int(np.round(len(bayenv)/bayenv_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks=[bayenv[x:x+num_chunks] for x in range(0, len(bayenv), num_chunks)]\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.dirname(bayenv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_exe = \"/home/lindb/wbp/bayenv2/bayenv2\"\n",
    "bayenv_opt = \"-i /home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE_NOHEADERIDX.txt -m \\\n",
    "/home/lindb/wbp/bayenv2/usable_matrix.txt -e \\\n",
    "/home/lindb/wbp/bayenv2/ENVIRONFILE.txt \\\n",
    "-p 8 -k 100000 -n 18 -t -X -c -f -r placeholder\"\n",
    "\n",
    "#-t = test mode - calcs Z,BF, or rho for single snps\n",
    "#-X = calc XTX\n",
    "#-c = calculate rho in addition to BF\n",
    "#-f = calc stand'd allele freqs\n",
    "#-\n",
    "\n",
    "\n",
    "total = 0\n",
    "cpu = 0\n",
    "max_cpu = 30\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(os.path.join(os.path.dirname(bayenv[0]), \"bayenv_parallel_%s\" % str(i).zfill(3)), \"w\") as o:\n",
    "        text = 'cd /home/lindb/wbp/bayenv2/snps'\n",
    "        o.write(\"%s\" % text)\n",
    "        for bayenv_file in chunk:\n",
    "            bayenv_cmd = \" \".join([bayenv_exe, bayenv_opt]).split()\n",
    "            if cpu == max_cpu:\n",
    "                cpu = 0\n",
    "            \n",
    "            bayenv_cmd[2] = os.path.join('/home/lindb/wbp/bayenv2/snps',bayenv_file)\n",
    "            bayenv_cmd[-1] = int(random.getrandbits(16))\n",
    "            bayenv_cmd.insert(0, \"taskset -c %d\" % cpu)\n",
    "            #bayenv_cmd.append(\"-o bayenv_%d\" % i)\n",
    "            bayenv_cmd.append(\"-o /home/lindb/wbp/bayenv2/bf_environfile.ENVIRONFILE.txt\")\n",
    "            o.write(\"%s\\n\" % \" \".join([str(x) for x in bayenv_cmd]))\n",
    "            total += 1\n",
    "            cpu += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile='xmn')\n",
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_line_count(f):\n",
    "    res = !wc -l {f}\n",
    "    return int(res[2].split()[0])\n",
    "dview['get_line_count'] = get_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_par = os.listdir(snpdir)\n",
    "bay_par = [os.path.join(snpdir,f) for f in bay_par if 'parallel' in f]\n",
    "len(bay_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for f in bay_par:\n",
    "    print(f)\n",
    "    total += get_line_count(f)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bay_par = sorted(bay_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bay_par[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_qsub_files(bayenv_parallel):\n",
    "    files = []\n",
    "    for i, f in enumerate(bayenv_parallel):\n",
    "        d = '/home/lindb/wbp/bayenv2/qsubs/'\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "        qsub_file = os.path.join(d, \"qsub_%s.sh\" % str(i).zfill(3))\n",
    "        files.append(qsub_file)\n",
    "        with open(qsub_file, \"w\") as o:\n",
    "            os.chmod(o.name, 0o744)\n",
    "            print(o.name)\n",
    "            o.write(\"%s\\n\" % \"\\n\".join([\"#!/bin/bash\", \n",
    "                                        \"#$ -N bayenv%d\" % i,\n",
    "                                        \"#$ -V\",\n",
    "                                        \"#$ -cwd\",\n",
    "                                        \"#$ -pe smp 30\",\n",
    "                                        \"#$ -j y\",\n",
    "                                        \"#$ -q all.q\",\n",
    "                                        \"unset module\",\n",
    "                                        \"echo \\\"Running on $HOSTNAME\\\"\",\n",
    "                                        \"cat %s | ~/bin/parallel -j 30 --progress --\" % f]))\n",
    "    return files\n",
    "qsub_files = write_qsub_files(bay_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = '/home/lindb/wbp/bayenv2/'\n",
    "with open(os.path.join(d, \"qsub_runner.sh\"), \"w\") as o:\n",
    "    os.chmod(o.name, 0o744)\n",
    "    o.write(\"#!/bin/bash\\n\")\n",
    "    o.write(\"unset module\\n\")\n",
    "    for q in qsub_files:\n",
    "        o.write(\"qsub %s\\n\" % q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hey = !qhost | grep godel\n",
    "qhost = hey[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qhost[0].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('/home/lindb/wbp/bayenv2/snps/')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    if not 'NODE' in f:\n",
    "        print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = [f for f in files if not 'NODE' in f and 'bay' not in f]\n",
    "len(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir as ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests = [f for f in ls('/home/lindb/wbp/bayenv2/snps/') if not 'freqs' in f]\n",
    "len(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = [f for f in ls('/home/lindb/wbp/bayenv2/snps/') if 'freqs' in f]\n",
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = [f for f in tests if 'NODE' in f]\n",
    "sec = [f for f in tests if 'NODE' not in f]\n",
    "len(nodes),len(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests2 = [f for f in ls('/home/lindb/wbp/bayenv2/snps2/') if 'freqs' in f]\n",
    "len(tests2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tests2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "104452+11730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(list(set(tests2) - set(freq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do remaining 4 chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the 116231 SNPFILEs\n",
    "DIR = '/home/lindb/wbp/bayenv2/snps/'\n",
    "theSNPFILEs = [op.join(DIR,snp) for snp in ls(DIR) if 'NODE' in snp and 'freqs' not in snp]\n",
    "len(theSNPFILEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.basename(theSNPFILEs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make directories for the 4 chains\n",
    "for i in range(4):\n",
    "    num = i+2 #so we can consider our original run the 1st chain\n",
    "    DIR = '/home/lindb/wbp/bayenv2/chain_%s' % str(num)\n",
    "    print num\n",
    "    \n",
    "    #make a DIR for each chain and copy relevant files\n",
    "    if not op.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/bayenv2',os.path.join(DIR,'bayenv2'))\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/ENVIRONFILE.txt',os.path.join(DIR,'ENVIRONFILE.txt'))\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/UnbinnedImputedSNPSFILE_NOHEADERIDX.txt',\n",
    "                os.path.join(DIR,'UnbinnedImputedSNPSFILE_NOHEADERIDX.txt'))\n",
    "    shutil.copy('/home/lindb/wbp/bayenv2/usable_matrix.txt',os.path.join(DIR,'usable_matrix.txt'))    \n",
    "    \n",
    "    \n",
    "    #copy all of the SNPFILEs to the chain's snpdir\n",
    "    print \"copying SNPFILEs\"\n",
    "    snpdir = op.join(DIR,'snps')\n",
    "    count = 0\n",
    "    if i == 0: #just do this once,\n",
    "        #make a DIR for SNPFILEs\n",
    "        if not op.exists(snpdir):\n",
    "            os.makedirs(snpdir)\n",
    "        \n",
    "        #copy the SNPFILEs\n",
    "        for snp in theSNPFILEs:\n",
    "            shutil.copy(snp,op.join(snpdir,op.basename(snp)))\n",
    "            count += 1\n",
    "            if count % 10000 == 0: #so I know progress\n",
    "                print i, count\n",
    "    else: #just copy the directory from the first chain\n",
    "        shutil.copytree('/home/lindb/wbp/bayenv2/chain_2/snps',snpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of all of the SNPFILEs across chains\n",
    "allsnps = []\n",
    "for i in range(4):\n",
    "    num = i+2\n",
    "    DIR = '/home/lindb/wbp/bayenv2/chain_%s/snps' % num\n",
    "    if len(allsnps) == 0:\n",
    "        allsnps = [op.join(DIR,snp) for snp in ls(DIR)]\n",
    "    else:\n",
    "        allsnps.extend([op.join(DIR,snp) for snp in ls(DIR)])\n",
    "len(allsnps) #116231*4 = 464,924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsnps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsnps[200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set limit to number of cores requested\n",
    "bayenv_jobs = 192#cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#devide the 4chains among the jobs\n",
    "num_chunks = int(math.ceil((len(allsnps))/bayenv_jobs)) \n",
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks=[allsnps[x:x+num_chunks] for x in range(0, len(allsnps), num_chunks)]\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(chunks[190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(chunks[191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for chunk in chunks:\n",
    "    total = total + len(chunk)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a dir for the chunks\n",
    "DIR = '/home/lindb/wbp/bayenv2/chunks'\n",
    "os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.dirname(op.dirname(SNPFILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.basename(exeDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "cpu = 0\n",
    "max_cpu = 32\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print i\n",
    "    with open(op.join('/home/lindb/wbp/bayenv2/chunks',\"bayenv_parallel_%s\" % str(i).zfill(3)), 'w') as o:\n",
    "        for SNPFILE in chunk:\n",
    "            if cpu == max_cpu: #reset if necessary\n",
    "                cpu = 0\n",
    "            \n",
    "            #get path where SNPFILEs are\n",
    "            snpdir = op.dirname(SNPFILE)\n",
    "            \n",
    "            #get folder of ./bayenv2, MATRIXFILE, ENVIRONFILE, and future outfile\n",
    "            exeDIR = op.dirname(snpdir)\n",
    "            \n",
    "            #set options\n",
    "            bayenv2_exe = op.join(exeDIR,'bayenv2')\n",
    "            MATRIXFILE = op.join(exeDIR,'usable_matrix.txt')\n",
    "            ENVIRONFILE = op.join(exeDIR,'ENVIRONFILE.txt')\n",
    "            outfile = op.join(exeDIR,'%s_outfile' % op.basename(exeDIR))\n",
    "            bay_cmd = '''%s \\\n",
    "%s \\\n",
    "-i %s \\\n",
    "-m %s \\\n",
    "-e %s \\\n",
    "-r %s \\\n",
    "-o %s \\\n",
    "-p 8 -k 100000 -n 18 -t -X -c -f\\n''' % (\"taskset -c %d\" % cpu,\n",
    "                                         bayenv2_exe,\n",
    "                                         SNPFILE,\n",
    "                                         MATRIXFILE,\n",
    "                                         ENVIRONFILE,\n",
    "                                         int(random.getrandbits(16)),\n",
    "                                         outfile\n",
    "                                        )\n",
    "            total += 1\n",
    "            cpu += 1\n",
    "            #print SNPFILE\n",
    "            #print bay_cmd\n",
    "            o.write(\"%s\" % bay_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/wbp/bayenv2/chunks'\n",
    "par_files = [op.join(DIR,f) for f in ls(DIR)]\n",
    "len(par_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in sorted(par_files):\n",
    "    text ='''#!/bin/bash\n",
    "#$ -N chains%s\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -pe smp 30\n",
    "#$ -j y\n",
    "#$ -q all.q\n",
    "unset module\n",
    "echo \"Running on $HOSTNAME\"\n",
    "cat %s | ~/bin/parallel -j 30 --progress --\n",
    "''' % (str(p[-3:]),\n",
    "       p\n",
    "      )\n",
    "    filE = '/home/lindb/wbp/bayenv2/chunks/qsubs/qsub_%s.sh' % str(p[-3:])\n",
    "    print text\n",
    "    with open(filE,'w') as o:\n",
    "        os.chmod(o.name, 0o744)\n",
    "        o.write(\"%s\" % text)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finish the rest of the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpsfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snpset = snpsfile.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chains = [chain for chain in ls('/home/lindb/wbp/bayenv2/') if 'chain' in chain]\n",
    "len(chdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redoDict = OrderedDict()\n",
    "for chain in chains:\n",
    "    DIR = op.join('/home/lindb/wbp/bayenv2/',chain)\n",
    "    bffile = op.join(DIR,'%s_outfile.bf' % chain)\n",
    "    bfdf = pd.read_csv(bffile,header=None,sep='\\t')\n",
    "    print chain,len(bfdf.index),len(np.unique(bfdf[0].tolist()).tolist())\n",
    "    loci = [op.basename(path) for path in bfdf[0]]\n",
    "    \n",
    "    redoDict[chain] = list( set(snpset) - set(loci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redoDict['chain_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for chain in chains:\n",
    "    filE = '/home/lindb/wbp/bayenv2/%s/redos.txt' % chain\n",
    "    with open(filE,'w') as o:\n",
    "        for locus in redoDict[chain]:\n",
    "            text = '''/home/lindb/wbp/bayenv2/bayenv2 -i /home/lindb/wbp/bayenv2/%s/snps/%s \\\n",
    "-m /home/lindb/wbp/bayenv2/usable_matrix.txt \\\n",
    "-e /home/lindb/wbp/bayenv2/ENVIRONFILE.txt \\\n",
    "-r %d \\\n",
    "-o %s \\\n",
    "-p 8 -k 100000 -n 18 -t -X -c -f\n",
    "''' % (chain,\n",
    "       locus,\n",
    "       int(random.getrandbits(16)),\n",
    "       op.join(op.dirname(filE),'%s_outfile' % chain)\n",
    "      )\n",
    "            o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# are there environmental clines? (related to geographic distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### these relationships are better explored in the 'allele frequency shifts' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "envdf = envdf.loc[:,[col for col in envdf.columns[:-1]]]\n",
    "envdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#double check each row has mean =0 , stdev=1.0\n",
    "for row in envdf.index:\n",
    "    print row,np.mean(envdf.loc[row,:]),np.std(envdf.loc[row,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get pairwise environmental distances across all environmental variables\n",
    "envdifDict = OrderedDict()\n",
    "for i,popi in enumerate(envdf.columns):\n",
    "    envdifDict[popi] = OrderedDict()\n",
    "    for j,popj in enumerate(envdf.columns):\n",
    "        if i < j: #lower tri - reverse logic when put into dataframe\n",
    "            sqdif = []\n",
    "            for envf in envdf.index:\n",
    "                xi = envdf.loc[env,popi]\n",
    "                xj = envdf.loc[env,popj]\n",
    "                difsq = (xi - xj)**2\n",
    "                sqdif.append(difsq)\n",
    "            sums = sum(sqdif)\n",
    "            envdifDict[popi][popj] = np.sqrt(sums)\n",
    "        else:\n",
    "            envdifDict[popi][popj] = np.nan\n",
    "envdist = pd.DataFrame(envdifDict)\n",
    "envdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/wbp/bayenv2/matrices/environmental_distances.txt'\n",
    "envdist.to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get pop coordinates\n",
    "pops = np.unique(test['Population_ID']).tolist()\n",
    "popDict = OrderedDict()\n",
    "for pop in pops:\n",
    "    data = test[test['Population_ID'] == pop]\n",
    "    ulat = [lat for lat in np.unique(data['lat']).tolist() if math.isnan(lat) == False]\n",
    "    ulon = [lon for lon in np.unique(data['lon']).tolist() if math.isnan(lon) == False]\n",
    "    mlat = np.mean(ulat)\n",
    "    mlon = np.mean(ulon)\n",
    "    popDict[pop] = (mlat,mlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get vincenty distances between populations to account for earth curvature\n",
    "geoDict = OrderedDict()\n",
    "for i,popi in enumerate(envdf.columns):\n",
    "    geoDict[popi] = OrderedDict()\n",
    "    for j,popj in enumerate(envdf.columns):\n",
    "        if i < j: #lower tri - reverse logic when put into dataframe\n",
    "            geoDict[popi][popj] = vincenty(popDict[popi],popDict[popj])\n",
    "        else:\n",
    "            geoDict[popi][popj] = np.nan\n",
    "geodist = pd.DataFrame(geoDict)\n",
    "geodist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/wbp/bayenv2/matrices/geographic_distances.txt'\n",
    "geodist.to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "envs = []\n",
    "for i,popi in enumerate(envdist.index):\n",
    "    for j,popj in enumerate(envdist.index):\n",
    "        if i > j:\n",
    "            envs.append(envdist.loc[popi,popj])\n",
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geos = []\n",
    "for i,popi in enumerate(geodist.index):\n",
    "    for j,popj in enumerate(geodist.index):\n",
    "        if i > j:\n",
    "            geos.append(float(str(geodist.loc[popi,popj]).split(\" \")[0]))\n",
    "geos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spearmanr(envs,geos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(envs,geos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what about for envs which we expect to be clinal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envdf.index[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get pairwise environmental distances\n",
    "precipDict = OrderedDict()\n",
    "for i,popi in enumerate(envdf.columns):\n",
    "    precipDict[popi] = OrderedDict()\n",
    "    for j,popj in enumerate(envdf.columns):\n",
    "        if i < j: #lower tri - reverse logic when put into dataframe\n",
    "            sqdif = []\n",
    "            for env in [envdf.index[2]]: #just for Ann-ppt\n",
    "                xi = envdf.loc[env,popi]\n",
    "                xj = envdf.loc[env,popj]\n",
    "                difsq = (xi - xj)**2\n",
    "                sqdif.append(difsq)\n",
    "            sums = sum(sqdif)\n",
    "            precipDict[popi][popj] = np.sqrt(sums)\n",
    "        else:\n",
    "            precipDict[popi][popj] = np.nan\n",
    "precipdist = pd.DataFrame(precipDict)\n",
    "precipdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precips = []\n",
    "for i,popi in enumerate(precipdist.index):\n",
    "    for j,popj in enumerate(precipdist.index):\n",
    "        if i > j:\n",
    "            precips.append(precipdist.loc[popi,popj])\n",
    "precips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spearmanr(precips,geos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(precips,geos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(envs,geos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(envs,precips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get harmonic mean of BFs across chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envDict['Ann-ppt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a dictionary to name columns in bf_environfile.ENVIRONFILE\n",
    "orderDict = {}\n",
    "orderDict[0] = 'BF'\n",
    "orderDict[1] = 'rho'\n",
    "orderDict[2] = 'pearson'\n",
    "colDict = OrderedDict()\n",
    "for env,cols in envDict.items():\n",
    "    #print env,cols\n",
    "    colCount = 0\n",
    "    for col in cols:\n",
    "        sub = '_'.join([str(env), orderDict[colCount]]) \n",
    "        colDict[col] = sub\n",
    "        colCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chains = sorted([chain for chain in ls('/home/lindb/wbp/bayenv2/') if 'chain' in chain])\n",
    "chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load and transform the outfile to have indices and column names\n",
    "#put df into a dictionary based on chain ID\n",
    "outDict = OrderedDict()\n",
    "for chain in chains:\n",
    "    print chain\n",
    "    bff = '/home/lindb/wbp/bayenv2/%s/%s_outfile.bf' % (chain,chain)\n",
    "    bfdf = pd.read_csv(bff,header=None,sep='\\t')\n",
    "    loci = []\n",
    "    for row in bfdf.index:\n",
    "        locus = bfdf.loc[row,0].split(\"/\")[-1]\n",
    "        loci.append(locus)\n",
    "    outdf = bfdf.loc[:,[x for x in bfdf.columns[1:-1]]]\n",
    "    outdf.columns = [col for col in range(len(outdf.columns))]\n",
    "    outdf.columns = [colDict[col] for col in outdf.columns]\n",
    "    outdf.index = [locus for locus in loci]\n",
    "    outDict[chain] = outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDict['chain_5'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDict['chain_5'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary which has BFs separated by environment\n",
    "bfDict = OrderedDict() #bfDict[env] = dataframe, cols = chain1-5 for a single env\n",
    "for env in envDict.keys():\n",
    "    print env\n",
    "    for c,chain in enumerate(outDict.keys()):\n",
    "        if c == 0:\n",
    "            df = outDict[chain].loc[:,[col for col in outDict[chain].columns if ('%s_BF' % env) in col]]\n",
    "            df.columns = ['%s_BF_%s' % (env,chain)]\n",
    "        else:\n",
    "            new = outDict[chain].loc[:,[col for col in outDict[chain].columns if ('%s_BF' % env) in col]]\n",
    "            new.columns = ['%s_BF_%s' % (env,chain)]\n",
    "            df = pd.merge(df,new,left_index=True,right_index=True)\n",
    "    bfDict[env] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import variation as spvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statsDict = OrderedDict()\n",
    "for env in bfDict.keys():\n",
    "    print env\n",
    "    statsDict[env] = OrderedDict() #keys = coef (std/mean), |max - min|\n",
    "    statsDict[env]['coef'] = []\n",
    "    statsDict[env]['abs_diff'] = []\n",
    "    \n",
    "    for locus in bfDict[env].index:\n",
    "        data = bfDict[env].loc[locus,:].tolist()\n",
    "        coef = spvar(data)\n",
    "        absdiff = abs(max(data) - min(data))\n",
    "        statsDict[env]['coef'].append(coef)\n",
    "        statsDict[env]['abs_diff'].append(absdiff)\n",
    "    #print pd.Series(statsDict[env]['abs_diff']).describe()\n",
    "    #plt.hist(statsDict[env]['abs_diff'],bins = np.arange(0,max(statsDict[env]['abs_diff']),10))[2]\n",
    "    \n",
    "    #print pd.Series(statsDict[env]['coef']).describe()\n",
    "    #plt.hist(statsDict[env]['coef'],bins = np.arange(0,max(statsDict[env]['coef']),0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(statsDict['AWS0-25']['coef'],bins = np.arange(-0.05,max(statsDict['AWS0-25']['coef']),0.05))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(statsDict['AWS0-25']['abs_diff'],bins = np.arange(0,1400,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(statsDict['AWS0-25']['abs_diff']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i,x in enumerate(statsDict['AWS0-25']['abs_diff']):\n",
    "    if x > 18:\n",
    "        idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bfDict['AWS0-25'].loc[bfDict['AWS0-25'].index[[x for x in idx]],:]\n",
    "#NODE_280450_length_96_cov_2.343750_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmean([450,580,400,425,0.1]),hmean([450,580,400,425]),np.mean([450,580,400,425,0.1]),np.mean([450,580,400,425])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmean([.045,.0580,.0400,.0425,0.1]),hmean([.0450,.0580,.0400,.0425]),np.mean([.0450,.0580,.0400,.0425,0.1]),\n",
    "np.mean([.0450,.0580,.0400,.0425])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmean([62.197,0.083,.362,.054,.078]),np.mean([62.197,0.083,.362,.054,.078])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate harmonic mean, flag SNPs with >=2 chains with BF>1\n",
    "harmDict= OrderedDict()\n",
    "for env in bfDict.keys():\n",
    "    print env\n",
    "    harmDict[env] = OrderedDict()\n",
    "    for locus in bfDict[env].index:\n",
    "        data = bfDict[env].loc[locus,:].tolist()\n",
    "        bigs = [x for x in data if x>1]\n",
    "        if len(bigs) >2:\n",
    "            print bigs\n",
    "            harmDict[env][locus] = hmean(bigs)\n",
    "        else:\n",
    "            good = [x for x in data if x not in bigs]\n",
    "            harmDict[env][locus] = hmean(good)\n",
    "    print sorted(harmDict[env].values())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out hmean for each snp to file\n",
    "for env in harmDict.keys():\n",
    "    print env\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_all_BFs.txt' % env\n",
    "    with open(filE,'w') as o:\n",
    "        line = '\\t'.join(['locus','BF']) + '\\n'\n",
    "        o.write(\"%s\" % line)\n",
    "        for locus in harmDict[env].keys():\n",
    "            line = '\\t'.join([str(locus),str(harmDict[env][locus])])+'\\n'\n",
    "            o.write(\"%s\" % line)\n",
    "harmdfDict = OrderedDict()\n",
    "for env in harmDict.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_BFs.txt' % env\n",
    "    harmdfDict[env] = pd.read_csv(filE,header=0,sep='\\t')\n",
    "harmdfDict[env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do some sorting, rewrite the file\n",
    "for env in harmdfDict.keys():\n",
    "    harmdfDict[env].sort_values(by='BF',inplace=True)\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_BFs.txt' % env\n",
    "    harmdfDict[env].to_csv(filE,header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in case I have to restart my notebook\n",
    "harmdfDict = OrderedDict()\n",
    "for env in harmDict.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_BFs.txt' % env\n",
    "    harmdfDict[env] = pd.read_csv(filE,header=0,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "harmdfDict[env]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get harmonic mean of abs rho across chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary which has Rho's separated by environment\n",
    "rhoDict = OrderedDict() #rhoDict[env] = dataframe, cols = chain1-5 for a single env\n",
    "for env in envDict.keys():\n",
    "    print env\n",
    "    for c,chain in enumerate(outDict.keys()):\n",
    "        if c == 0:\n",
    "            df = outDict[chain].loc[:,[col for col in outDict[chain].columns if ('%s_rho' % env) in col]]\n",
    "            df.columns = ['%s_rho_%s' % (env,chain)]\n",
    "        else:\n",
    "            new = outDict[chain].loc[:,[col for col in outDict[chain].columns if ('%s_rho' % env) in col]]\n",
    "            new.columns = ['%s_rho_%s' % (env,chain)]\n",
    "            df = pd.merge(df,new,left_index=True,right_index=True)\n",
    "    rhoDict[env] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get harmonic means of the absolute value of rho\n",
    "hrhoDict= OrderedDict()\n",
    "for env in rhoDict.keys():\n",
    "    print env\n",
    "    hrhoDict[env] = OrderedDict()\n",
    "    for locus in rhoDict[env].index:\n",
    "        data = rhoDict[env].loc[locus,:].tolist()\n",
    "        data = [abs(x) for x in data if x != 0] #harmonic mean can't use 0s\n",
    "        hrhoDict[env][locus] = hmean(data)\n",
    "    print sorted(hrhoDict[env].values())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write to file\n",
    "for env in hrhoDict.keys():\n",
    "    print env\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_all_rhos.txt' % env\n",
    "    with open(filE,'w') as o:\n",
    "        line = '\\t'.join(['locus','rho']) + '\\n'\n",
    "        o.write(\"%s\" % line)\n",
    "        for locus in hrhoDict[env].keys():\n",
    "            line = '\\t'.join([str(locus),str(hrhoDict[env][locus])])+'\\n'\n",
    "            o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sort and rewrite to file\n",
    "hrhodfDict = OrderedDict()\n",
    "for env in hrhoDict.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_all_rhos.txt' % env\n",
    "    hrhodfDict[env] = pd.read_csv(filE,header=0,sep='\\t')\n",
    "    hrhodfDict[env].sort_values(by='rho',inplace=True)\n",
    "    hrhodfDict[env].to_csv(filE,header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## get loci in intersection of top BFs and top rhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 0.5% BF (n=582), top 1%rho (n=1,163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get top rhos and BFs from dataframes for each env - since sorted by value, just the top % using index\n",
    "topBFs  = OrderedDict()\n",
    "topRhos = OrderedDict()\n",
    "for env in harmdfDict.keys():\n",
    "    topbfs = pd.DataFrame(harmdfDict[env].loc[harmdfDict[env].index[-582:],:])\n",
    "    topBFs[env] = topbfs['locus'].tolist()\n",
    "    \n",
    "    toprhos = pd.DataFrame(hrhodfDict[env].loc[hrhodfDict[env].index[-1163:],:])\n",
    "    topRhos[env] = toprhos['locus'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look at min and max values\n",
    "minrho = 1\n",
    "maxrho = -1\n",
    "for env in harmdfDict.keys():\n",
    "    topbfs = pd.DataFrame(harmdfDict[env].loc[harmdfDict[env].index[-582:],:])\n",
    "    print env\n",
    "    print 'BF =',round(min(topbfs['BF']),3),\",\",round(max(topbfs['BF']),3)\n",
    "    \n",
    "    toprhos = pd.DataFrame(hrhodfDict[env].loc[hrhodfDict[env].index[-1163:],:])\n",
    "    print 'rho =',round(min(toprhos['rho']),3),\",\",round(max(toprhos['rho']),3)\n",
    "    print '\\n'\n",
    "    if min(toprhos['rho']) < minrho:\n",
    "        minrho = min(toprhos['rho'])\n",
    "    if max(toprhos['rho']) > maxrho:\n",
    "        maxrho = max(toprhos['rho'])\n",
    "print 'min=',minrho\n",
    "print 'max=',maxrho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at min and max values\n",
    "minrho = 1\n",
    "maxrho = -1\n",
    "for env in harmdfDict.keys():\n",
    "    topbfs = pd.DataFrame(harmdfDict[env].loc[harmdfDict[env].index[-582:],:])\n",
    "    print env\n",
    "    print 'BF =',min(topbfs['BF']),max(topbfs['BF'])\n",
    "    \n",
    "    toprhos = pd.DataFrame(hrhodfDict[env].loc[hrhodfDict[env].index[-1163:],:])\n",
    "    print 'rho =',min(toprhos['rho']),max(toprhos['rho'])\n",
    "    print '\\n'\n",
    "    if min(toprhos['rho']) < minrho:\n",
    "        minrho = min(toprhos['rho'])\n",
    "    if max(toprhos['rho']) > maxrho:\n",
    "        maxrho = max(toprhos['rho'])\n",
    "print 'min=',minrho\n",
    "print 'max=',maxrho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toprhos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get robust SNPs via intersection of top BFs and top rhos\n",
    "intset = OrderedDict()\n",
    "for env in topRhos.keys():\n",
    "    intset[env] = list(set(topBFs[env]).intersection(set(topRhos[env])))\n",
    "    print env, len(intset[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens = [len(intset[env]) for env in intset.keys()]\n",
    "max(lens),min(lens),np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write list of robust SNPs to file\n",
    "for env in intset.keys():\n",
    "    df = pd.DataFrame(intset[env])\n",
    "    df.columns = [str(env)]\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/sigsnps/%s_top_p05%%BF_1%%rho.txt' % env\n",
    "    df.to_csv(filE,header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#when I restart my notebook\n",
    "DIR = '/home/lindb/wbp/bayenv2/results/sigsnps/'\n",
    "files = [op.join(DIR,f) for f in ls(DIR)]\n",
    "intset = {}\n",
    "for f in files:\n",
    "    env = op.basename(f).split(\"_\")[0]\n",
    "    df = pd.read_csv(f,header=0,sep='\\t')\n",
    "    intset[env] = df[env].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check against previous\n",
    "for env in sorted(intset):\n",
    "    print env,len(intset[env])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file made in 09_OutFLANK.ipynb\n",
    "impMAF = pd.read_csv('/home/lindb/wbp/OutFLANK/imputed_MAF.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "impMAF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count > 0.5\n",
    "for pop in impMAF:\n",
    "    df = pd.DataFrame(impMAF[pop][impMAF[pop]>0.5])\n",
    "    print pop,len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check to make sure impMAF doesn't just have MAFs - impMAF = freq of global minor allele\n",
    "for pop in impMAF:\n",
    "    print pop,max(impMAF[pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file made in 09_OutFLANK.ipynb\n",
    "globmafs = pd.read_csv('/home/lindb/wbp/OutFLANK/global_mafs.txt',header=0,sep='\\t')\n",
    "globmafs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(globmafs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dictionary, key = SNP, val = maf\n",
    "glob = OrderedDict()\n",
    "for row in globmafs.index:\n",
    "    locus = globmafs.loc[row,'locus']\n",
    "    glob[locus] = globmafs.loc[row,'maf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#population sizes\n",
    "popDict = {'Dicks_Pass':25,\n",
    "'Freel_Peak':48,\n",
    "'Little_Round_Top':25,\n",
    "'Heavenly':25,\n",
    "'Mt_Rose_Ophir':49,\n",
    "'Rifle_Peak':24,\n",
    "'Snow_Valley_Peak':24,\n",
    "'West_Shore_Peaks':24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(popDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do pairwise to get Dij\n",
    "dijDict = OrderedDict() \n",
    "for env in intset.keys():\n",
    "    outliersnps = intset[env]\n",
    "    \n",
    "    dijDict[env] = OrderedDict() \n",
    "    icount = 0\n",
    "    for i,locusi in enumerate(outliersnps):\n",
    "        dijDict[env][locusi] = OrderedDict()\n",
    "        qi = glob[locusi] #global maf\n",
    "\n",
    "        for j,locusj in enumerate(outliersnps):\n",
    "            if i > j: #i=row, j=col : lower triangle \n",
    "                qj = glob[locusj] #global maf\n",
    "\n",
    "                sums = 0\n",
    "                for pop in impMAF.columns:\n",
    "                    qik = impMAF.loc[locusi,pop] #get pop af\n",
    "                    qjk = impMAF.loc[locusj,pop] #get pop af\n",
    "                    nk = popDict[pop]\n",
    "\n",
    "                    sums += (nk/sum(popDict.values()))*((qik*qjk)-(qi*qj))\n",
    "\n",
    "                dijDict[env][locusi][locusj] = sums\n",
    "            else:\n",
    "                dijDict[env][locusi][locusj] = np.nan\n",
    "        icount += 1\n",
    "        if icount % 10 == 0:\n",
    "            print env,icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write out the file\n",
    "for env in dijDict.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/covariances/dvals/%s_dvals.txt' % env\n",
    "    with open(filE,'w') as o:\n",
    "        key0 = dijDict[env].keys()[0]\n",
    "        line = '\\t'.join(dijDict[env][key0].keys()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        for locusi in dijDict[env].keys():\n",
    "            line = str(locusi)+'\\t'+'\\t'.join([str(x) for x in dijDict[env][locusi].values()]) + str('\\n')\n",
    "            o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check out a file\n",
    "dvals = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "dvals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get H_exp for each snp\n",
    "#file made in 09_OutFLANK.ipynb\n",
    "filE = '/home/lindb/wbp/OutFLANK/Hexp_by_snp_withbins.txt'\n",
    "H = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "H = pd.DataFrame(H.loc[:,['h_exp','bin']])\n",
    "H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hexp for the complete set of SNPs\n",
    "plt.hist(H['h_exp'],bins = [x for x in np.arange(0,.51,0.01)])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a dataframe with the outlier loci and their bins\n",
    "outlierdata = OrderedDict()\n",
    "for env in dijDict.keys():\n",
    "    outliersnps = intset[env]\n",
    "\n",
    "    outlierdata[env] = pd.DataFrame(H[H.index.isin(outliersnps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dijDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PdfPages('/home/lindb/wbp/figures/grid_imp_hexp_hist_by_env_AWSO-Lat.pdf') as pdf:\n",
    "    plt.close('all')\n",
    "    fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "    a1 = plt.subplot(331)\n",
    "    a1.hist(outlierdata['AWS0-25']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a1.spines['right'].set_visible(False)\n",
    "    a1.spines['top'].set_visible(False)\n",
    "    a1.yaxis.set_ticks_position('left')\n",
    "    a1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a2 = plt.subplot(332)\n",
    "    a2.hist(outlierdata['AWS0-50']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a2.spines['right'].set_visible(False)\n",
    "    a2.spines['top'].set_visible(False)\n",
    "    a2.yaxis.set_ticks_position('left')\n",
    "    a2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a3 = plt.subplot(333)\n",
    "    a3.hist(outlierdata['Ann-ppt']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a3.set_title('C',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a3.spines['right'].set_visible(False)\n",
    "    a3.spines['top'].set_visible(False)\n",
    "    a3.yaxis.set_ticks_position('left')\n",
    "    a3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a4 = plt.subplot(334)\n",
    "    a4.hist(outlierdata['CEC']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a4.set_title('D',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a4.spines['right'].set_visible(False)\n",
    "    a4.spines['top'].set_visible(False)\n",
    "    a4.yaxis.set_ticks_position('left')\n",
    "    a4.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a5 = plt.subplot(335)\n",
    "    a5.hist(outlierdata['Clay']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a5.spines['right'].set_visible(False)\n",
    "    a5.spines['top'].set_visible(False)\n",
    "    a5.yaxis.set_ticks_position('left')\n",
    "    a5.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a6 = plt.subplot(336)\n",
    "    a6.hist(outlierdata['Elev']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a6.spines['right'].set_visible(False)\n",
    "    a6.spines['top'].set_visible(False)\n",
    "    a6.yaxis.set_ticks_position('left')\n",
    "    a6.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a7 = plt.subplot(337)\n",
    "    a7.hist(outlierdata['GDD-Aug']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a7.spines['right'].set_visible(False)\n",
    "    a7.spines['top'].set_visible(False)\n",
    "    a7.yaxis.set_ticks_position('left')\n",
    "    a7.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a8 = plt.subplot(338)\n",
    "    a8.hist(outlierdata['GDD-May']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a8.set_title('H',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a8.spines['right'].set_visible(False)\n",
    "    a8.spines['top'].set_visible(False)\n",
    "    a8.yaxis.set_ticks_position('left')\n",
    "    a8.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a9 = plt.subplot(339)\n",
    "    a9.hist(outlierdata['Lat']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a9.spines['right'].set_visible(False)\n",
    "    a9.spines['top'].set_visible(False)\n",
    "    a9.yaxis.set_ticks_position('left')\n",
    "    a9.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    fig.set_size_inches(13,10)\n",
    "    pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PdfPages('/home/lindb/wbp/figures/grid_imp_hexp_hist_by_env_lon-WC3rdbar.pdf') as pdf:\n",
    "    plt.close('all')\n",
    "    fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "    a1 = plt.subplot(331)\n",
    "    a1.hist(outlierdata['Lon']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a1.spines['right'].set_visible(False)\n",
    "    a1.spines['top'].set_visible(False)\n",
    "    a1.yaxis.set_ticks_position('left')\n",
    "    a1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a2 = plt.subplot(332)\n",
    "    a2.hist(outlierdata['Max-rad-input']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a2.spines['right'].set_visible(False)\n",
    "    a2.spines['top'].set_visible(False)\n",
    "    a2.yaxis.set_ticks_position('left')\n",
    "    a2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a3 = plt.subplot(333)\n",
    "    a3.hist(outlierdata['Rock-cov']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a3.set_title('C',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a3.spines['right'].set_visible(False)\n",
    "    a3.spines['top'].set_visible(False)\n",
    "    a3.yaxis.set_ticks_position('left')\n",
    "    a3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a4 = plt.subplot(334)\n",
    "    a4.hist(outlierdata['Sand']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a4.set_title('D',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a4.spines['right'].set_visible(False)\n",
    "    a4.spines['top'].set_visible(False)\n",
    "    a4.yaxis.set_ticks_position('left')\n",
    "    a4.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a5 = plt.subplot(335)\n",
    "    a5.hist(outlierdata['Silt']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a5.spines['right'].set_visible(False)\n",
    "    a5.spines['top'].set_visible(False)\n",
    "    a5.yaxis.set_ticks_position('left')\n",
    "    a5.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a6 = plt.subplot(336)\n",
    "    a6.hist(outlierdata['Tmax-July']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a6.spines['right'].set_visible(False)\n",
    "    a6.spines['top'].set_visible(False)\n",
    "    a6.yaxis.set_ticks_position('left')\n",
    "    a6.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a7 = plt.subplot(337)\n",
    "    a7.hist(outlierdata['Tmin-Jan']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a7.spines['right'].set_visible(False)\n",
    "    a7.spines['top'].set_visible(False)\n",
    "    a7.yaxis.set_ticks_position('left')\n",
    "    a7.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a8 = plt.subplot(338)\n",
    "    a8.hist(outlierdata['WC15Bar']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a8.set_title('H',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a8.spines['right'].set_visible(False)\n",
    "    a8.spines['top'].set_visible(False)\n",
    "    a8.yaxis.set_ticks_position('left')\n",
    "    a8.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a9 = plt.subplot(339)\n",
    "    a9.hist(outlierdata['WC3rdbar']['h_exp'].tolist(),bins = [binn for binn in np.arange(0,0.51,0.01)])[2]\n",
    "    a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a9.spines['right'].set_visible(False)\n",
    "    a9.spines['top'].set_visible(False)\n",
    "    a9.yaxis.set_ticks_position('left')\n",
    "    a9.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    fig.set_size_inches(13,10)\n",
    "    pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get sets of SNPs to make random draws\n",
    "nonsigsnps = OrderedDict()\n",
    "for env in outlierdata.keys():\n",
    "    nonsigs = list(set(H.index.tolist()) - set(outlierdata[env].index.tolist()))\n",
    "    nonsigsnps[env] = pd.DataFrame(H[H.index.isin(nonsigs)])\n",
    "    print len(outlierdata[env].index.tolist())+len(nonsigsnps[env].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many random snps to draw from each bin?\n",
    "binCounter = OrderedDict()\n",
    "for env in outlierdata.keys():\n",
    "    binCounter[env] = Counter()\n",
    "    for row in outlierdata[env].index:\n",
    "        binCounter[env][outlierdata[env].loc[row,'bin']] += 1\n",
    "    for b in binCounter[env].keys():\n",
    "        print env,b,binCounter[env][b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binCounter['AWS0-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.makedirs('/home/lindb/wbp/bayenv2/covariances/randmatrices')\n",
    "os.makedirs('/home/lindb/wbp/bayenv2/covariances/randmatrices/randsnps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for each env make 1000 dataframes with a set of snps == len(outliersnps[env])\n",
    "for env in outlierdata.keys():\n",
    "    print env\n",
    "    for i in range(1000):  \n",
    "        snps = []        \n",
    "        for binn in binCounter[env].keys():\n",
    "            data = nonsigsnps[env][nonsigsnps[env]['bin'] == binn]\n",
    "                \n",
    "            [snps.append(snp) for snp in random.sample(data.index,binCounter[env][binn])]\n",
    "        \n",
    "        assert len(np.unique(snps).tolist()) == sum(binCounter[env].values())\n",
    "\n",
    "        DIR = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randsnps/%s' % env\n",
    "        if not op.exists(DIR):\n",
    "            os.makedirs(DIR)\n",
    "        filE = op.join(DIR,\"%s_%s_randsnps.txt\" % (env,str(i).zfill(3)))\n",
    "        df = pd.DataFrame(snps)\n",
    "        df.to_csv(filE,header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quicker to do it this way\n",
    "#get dvals for the sets of random snps for each env\n",
    "for env in outlierdata.keys():\n",
    "    for i in range(1000):\n",
    "        text = '''from __future__ import division\n",
    "import os\n",
    "from collections import OrderedDict,Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from os import path as op\n",
    "from os import listdir as ls\n",
    "\n",
    "#get pop assignment for each samp\n",
    "filE = '/home/lindb/wbp/sampsTOpop.txt'\n",
    "stp = pd.read_csv(filE,header=0,sep=\"\\t\")\n",
    "\n",
    "\n",
    "#pops matched to samps\n",
    "ptsDict = OrderedDict() #pop to samp dictionary\n",
    "for row in stp.index:\n",
    "    pop = stp.loc[row,'pop']\n",
    "    if not pop in ptsDict.keys():\n",
    "        ptsDict[pop] = []\n",
    "    ptsDict[pop].append(stp.loc[row,'sampID'])\n",
    "\n",
    "\n",
    "#get a dict with num indiv in pop\n",
    "popDict = OrderedDict()\n",
    "total = 0\n",
    "for pop in ptsDict.keys():\n",
    "    popDict[pop] = len(ptsDict[pop])\n",
    "    print pop,popDict[pop]\n",
    "    total += popDict[pop]\n",
    "\n",
    "\n",
    "filE = '/home/lindb/wbp/OutFLANK/global_mafs.txt'\n",
    "globs = pd.read_csv(filE,header=0,sep='\\\\t')\n",
    "glob = OrderedDict()\n",
    "for row in globs.index:\n",
    "    snp = globs.loc[row,'locus']\n",
    "    maf = globs.loc[row,'maf']\n",
    "    glob[snp] = maf\n",
    "\n",
    "impMAF = pd.read_csv('/home/lindb/wbp/OutFLANK/imputed_MAF.txt',header=0,index_col=0,sep=\"\\\\t\")\n",
    "\n",
    "filE= '/home/lindb/wbp/bayenv2/covariances/randmatrices/randsnps/%s/%s_%s_randsnps.txt' \n",
    "df = pd.read_csv(filE,header=None,sep=\"\\\\t\")\n",
    "randomsnps = df[0].tolist()\n",
    "\n",
    "dijDict = OrderedDict() \n",
    "for i,locusi in enumerate(randomsnps):\n",
    "    dijDict[locusi] = OrderedDict()\n",
    "    qi = glob[locusi] #global af\n",
    "\n",
    "    for j,locusj in enumerate(randomsnps):\n",
    "        if i > j: #i=row, j=col : lower triangle \n",
    "            qj = glob[locusj] #global af\n",
    "\n",
    "            sums = 0\n",
    "            for pop in impMAF.columns:\n",
    "                qik = impMAF.loc[locusi,pop] #get pop af\n",
    "                qjk = impMAF.loc[locusj,pop] #get pop af\n",
    "                nk = popDict[pop]\n",
    "\n",
    "                sums += (nk/sum(popDict.values()))*((qik*qjk)-(qi*qj))\n",
    "\n",
    "            dijDict[locusi][locusj] = sums\n",
    "        else:\n",
    "            dijDict[locusi][locusj] = np.nan\n",
    "\n",
    "filE = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randDVALS/%s/%s_%s_randDVALS.txt'\n",
    "if not op.exists('/home/lindb/wbp/bayenv2/covariances/randmatrices/randDVALS/'):\n",
    "    os.makedirs('/home/lindb/wbp/bayenv2/covariances/randmatrices/randDVALS/')\n",
    "DIR = op.dirname(filE)\n",
    "if not op.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "\n",
    "with open(filE,'w') as o:\n",
    "    key0 = dijDict.keys()[0]\n",
    "    line = '\\\\t'.join(dijDict[key0].keys()) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locusi in dijDict.keys():\n",
    "        line = str(locusi)+'\\\\t'+'\\\\t'.join([str(x) for x in dijDict[locusi].values()]) + str('\\\\n')\n",
    "        o.write(\"%%s\" %% line)\n",
    "\n",
    "\n",
    "''' % (env,env,str(i).zfill(3),\n",
    "       env,env,str(i).zfill(3))\n",
    "        filE = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randpyfiles/get_rand_dvals_%s_%s.py' % (env,\n",
    "                                                                                                      str(i).zfill(3)\n",
    "                                                                                                     )\n",
    "        if not op.exists(op.dirname(filE)):\n",
    "            os.makedirs(op.dirname(filE))\n",
    "        with open(filE,'w') as o:\n",
    "            o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randpyfiles/'\n",
    "pyfiles = [op.join(DIR,py) for py in ls(DIR)]\n",
    "len(pyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#spread out the jobs across 25 files\n",
    "#18000/200=90\n",
    "count = 0\n",
    "fcount = 0\n",
    "for f in sorted(pyfiles):\n",
    "    if count == 0:\n",
    "        text = '''#!/bin/bash\n",
    "#$ -N pyfile%s\n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "python %s\\n''' % (str(fcount),\n",
    "                  f)\n",
    "    else:\n",
    "        newtext = 'python %s\\n' % f\n",
    "        text = text + newtext\n",
    "    count += 1\n",
    "    if count == 90:\n",
    "        count = 0\n",
    "        fcount += 1\n",
    "        filE = '/home/lindb/wbp/bayenv2/covariances/randmatrices/runpyfiles/%s_cmds.sh' % str(fcount).zfill(3)\n",
    "        if not op.exists('/home/lindb/wbp/bayenv2/covariances/randmatrices/runpyfiles/'):\n",
    "            os.makedirs('/home/lindb/wbp/bayenv2/covariances/randmatrices/runpyfiles/')\n",
    "        with open(filE,'w') as o:\n",
    "            o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#qsub the qsub files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress godzilla\n",
    "DIR = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randDVALS/'\n",
    "ds = [op.join(DIR,d) for d in ls(DIR)]\n",
    "count = 0\n",
    "for DIR in ds:\n",
    "    count = count + len(ls(DIR))\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF = pd.read_csv('/home/lindb/wbp/bayenv2/covariances/dvals/Ann-ppt_dvals.txt',\n",
    "                 header=0,index_col=0,sep='\\t')\n",
    "len(DF.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# get observed dvals\n",
    "dvals = OrderedDict()\n",
    "medvals = OrderedDict()\n",
    "for env in get:\n",
    "    print env\n",
    "    DF = pd.read_csv('/home/lindb/wbp/bayenv2/covariances/dvals/%s_dvals.txt' % env,\n",
    "                     header=0,index_col=0,sep=\"\\t\")\n",
    "    dvals[env] = []\n",
    "    for i,row in enumerate(DF.index):\n",
    "        for j,col in enumerate(DF.columns):\n",
    "            if i > j:\n",
    "                dvals[env].append(abs(DF.loc[row,col]))\n",
    "\n",
    "    DIR = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randDVALS/%s/' % env\n",
    "    files = [op.join(DIR,f) for f in ls(DIR)]\n",
    "\n",
    "    fcount = 0\n",
    "    medvals[env] = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f,header=0,index_col=0,sep=\"\\t\")\n",
    "        rvals = [] #random dij values\n",
    "        for lst in df.values.tolist():\n",
    "            for x in lst:\n",
    "                if math.isnan(x) == False:\n",
    "                    rvals.append(x)\n",
    "\n",
    "\n",
    "        medvals[env].append(np.median([abs(val) for val in rvals]))\n",
    "\n",
    "        fcount += 1\n",
    "        if fcount % 100 == 0:\n",
    "            print fcount\n",
    "\n",
    "    filE = '/home/lindb/wbp/bayenv2/covariances/randmatrices/randmedvals/%s_randmedvalues.txt' % env\n",
    "    if not op.exists(op.dirname(filE)):\n",
    "        os.makedirs(op.dirname(filE))\n",
    "    medvaldf = pd.DataFrame(medvals[env])\n",
    "    medvaldf.to_csv(filE,header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n5th = OrderedDict()    #get 95th percentile\n",
    "gt_hth = OrderedDict()  #how much greater is the empirical median dvalue than the 100th percentile of random SNPs?\n",
    "gt_n5th = OrderedDict() #how much greater is the empirical median dvalue than the 95th percentile of random SNPs?\n",
    "bmax=OrderedDict()      #below what percentile of the observed dvals are the values less than the maximum randdvals\n",
    "bn5th = OrderedDict()   #below what percentile of the observed dvals are the values less than the 95th perc randdvals\n",
    "for env in sorted(get):\n",
    "    print env,'has',len(intset[env]),'associated SNPs'\n",
    "    sorts        = sorted(medvals[env])\n",
    "    n5th[env]    = sorts[949]\n",
    "    gt_hth[env]  = np.median(dvals[env])/max(medvals[env])\n",
    "    print 'emp median is %sx greater than 100th percentile of random'%str(round(gt_hth[env],3))\n",
    "    gt_n5th[env] = np.median(dvals[env])/n5th[env]\n",
    "    print 'emp median is %sx greater than 95th percentile of random'%str(round(gt_n5th[env],3))\n",
    "    for i,dval in enumerate(sorted(dvals[env])):\n",
    "        if not dval < max(sorts): #the max(randDval) corresponds to the xth percentile of empirical d-values\n",
    "            bmax[env]=(i+1,(i+1)/len(dvals[env]))\n",
    "            break\n",
    "    for i,dval in enumerate(sorted(dvals[env])):\n",
    "        if not dval < sorts[949]:\n",
    "            bn5th[env]=(i+1,(i+1)/len(dvals[env]))\n",
    "            break\n",
    "    print 'the max random value corresponds to the %s precentile' % str(round(bmax[env][1],3)*100),\"(%s/%s)\" % (bmax[env][0],len(dvals[env])),'of emp values'\n",
    "    print 'the 95th perc rand val corresponds to the %s percentile',str(round(bn5th[env][1],3)*100),\"(%s/%s)\" % (bn5th[env][0],len(dvals[env])),'of emp values'\n",
    "    print 'emp med dval =',\"{:.4}\".format(np.median(dvals[env]))\n",
    "    print 'max rand dval =',\"{:.4}\".format(max(medvals[env]))\n",
    "    print '95th rand dval =',\"{:.4}\".format(n5th[env])\n",
    "    print '\\n' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is old- from when I calculated Dij using the maf of either allele within pops\n",
    "n5th = OrderedDict()    #get 95th percentile\n",
    "gt_hth = OrderedDict()  #how much greater is the empirical median dvalue than the 100th percentile of random SNPs?\n",
    "gt_n5th = OrderedDict() #how much greater is the empirical median dvalue than the 95th percentile of random SNPs?\n",
    "bmax=OrderedDict()      #below what percentile of the observed dvals are the values less than the maximum randdvals\n",
    "bn5th = OrderedDict()   #below what percentile of the observed dvals are the values less than the 95th perc randdvals\n",
    "for env in outlierdata.keys():\n",
    "    print env,len(intset[env])\n",
    "    sorts        = sorted(medvals[env])\n",
    "    n5th[env]    = sorts[949]\n",
    "    gt_hth[env]  = np.median(dvals[env])/max(medvals[env])\n",
    "    print 'gt_hth',round(gt_hth[env],3)\n",
    "    gt_n5th[env] = np.median(dvals[env])/n5th[env]\n",
    "    print 'gt_n5th',round(gt_n5th[env],3)\n",
    "    for i,dval in enumerate(sorted(dvals[env])):\n",
    "        if not dval < max(sorts): #the max(randDval) corresponds to the xth percentile of empirical d-values\n",
    "            bmax[env]=(i+1,i/len(dvals[env]))\n",
    "            break\n",
    "    for i,dval in enumerate(sorted(dvals[env])):\n",
    "        if not dval < sorts[949]:\n",
    "            bn5th[env]=(i+1,i/len(dvals[env]))\n",
    "            break\n",
    "    print 'bmax',round(bmax[env][1],3),\"(%s/%s)\" % (bmax[env][0],len(dvals[env]))\n",
    "    print 'bn5th',round(bn5th[env][1],3),\"(%s/%s)\" % (bn5th[env][0],len(dvals[env]))\n",
    "    print 'med dval',\"{:.2}\".format(np.median(dvals[env]))\n",
    "    print 'max rand dval',\"{:.4}\".format(max(medvals[env]))\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/lindb/wbp/OutFLANK/imputed_MAF.txt',header=0,index_col=0,sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pop in df:\n",
    "    print pop,max(df[pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtmin = 1000000000\n",
    "\n",
    "gtmax = 0\n",
    "for env in gt_hth.keys():\n",
    "    if gt_hth[env] < gtmin:\n",
    "        gtmin = gt_hth[env]\n",
    "        minenv = env\n",
    "    if gt_hth[env] > gtmax:\n",
    "        gtmax = gt_hth[env]\n",
    "        maxenv = env\n",
    "print minenv,gtmin\n",
    "print maxenv,gtmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dvals[env]),len(dvals['Ann-ppt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allele frequency shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for env in intset.keys():\n",
    "    print env,len(intset[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataframe to get population MAF across 8 pops using all n=244 samples (can't use this for GEMMA since pop sizes r diff\n",
    "impMAF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pop in impMAF:\n",
    "    print pop,max(impMAF[pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#population sizes\n",
    "popDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"xmn\")  \n",
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(lview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#do pairwise pops for empirical SNPs IDed by bayenv2 and calculate median Dij for each pop pair\n",
    "def getshiftDict(tokens):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from collections import OrderedDict\n",
    "    \n",
    "    env,impMAF,popDict = tokens\n",
    "    \n",
    "    shiftDict = OrderedDict() \n",
    "    kcount = 0\n",
    "    print env\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/sigsnps/%s_top_p05%%BF_1%%rho.txt' % env\n",
    "    df = pd.read_csv(filE,header=0,sep='\\t')\n",
    "    outliersnps = df[env].tolist()\n",
    "    for m,popm in enumerate(impMAF.columns):\n",
    "        print popm\n",
    "        shiftDict[popm] = OrderedDict()\n",
    "        for l,popl in enumerate(impMAF.columns):\n",
    "            if m>l: #only need to do the lower triangle - can reflect across diagonal later more quickly\n",
    "                dijlist = []\n",
    "                for i,locusi in enumerate(outliersnps):\n",
    "                    for j,locusj in enumerate(outliersnps):\n",
    "                        if i > j: #i=row, j=col : lower triangle \n",
    "                            sums =0 #Dij\n",
    "                            kcount += 1\n",
    "                            for popk in [popm,popl]:\n",
    "                                qik = impMAF.loc[locusi,popk]        #get locusi maf for pop k\n",
    "                                qjk = impMAF.loc[locusj,popk]        #get locusj maf for pop k\n",
    "                                nk = popDict[popk]                   #N  individuals  in pop k\n",
    "\n",
    "                                globN = 2*(popDict[popm]+popDict[popl]) # number of alleles across 2 pops\n",
    "\n",
    "                                #get global mafs\n",
    "                                fqim = impMAF.loc[locusi,popm]        #allele locusi freq  in popm\n",
    "                                nqim = round(fqim*2*popDict[popm])    #allele locusi count in popm\n",
    "                                fqil = impMAF.loc[locusi,popl]        #allele locusi freq  in popl\n",
    "                                nqil = round(fqil*2*popDict[popl])    #allele locusi count in popl\n",
    "\n",
    "                                fqjm = impMAF.loc[locusj,popm]        #allele locusj freq  in popm\n",
    "                                nqjm = round(fqjm*2*popDict[popm])    #allele locusj count in popm\n",
    "                                fqjl = impMAF.loc[locusj,popl]        #allele locusj freq  in popl\n",
    "                                nqjl = round(fqjl*2*popDict[popl])    #allele locusj count in popl\n",
    "\n",
    "                                qi = float(nqim+nqil)/float(globN) #global af locusi\n",
    "                                qj = float(nqjm+nqjl)/float(globN) #global af locusj\n",
    "\n",
    "                                sums += (float(nk)/float(popDict[popm]+popDict[popl]))*((qik*qjk)-(qi*qj))\n",
    "\n",
    "                            dijlist.append(sums) #each pairwise pop comparison has a matrix of Dij\n",
    "                        else:\n",
    "                            pass #no redundancies, no diagonal. \n",
    "                shiftDict[popm][popl] = np.median([abs(d) for d in dijlist])\n",
    "            else:\n",
    "                shiftDict[popm][popl] = np.nan #no redundancies,no diagonal. will be faster to reflect across diag later\n",
    "    #    if kcount > 1:\n",
    "    #        break\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_dij.txt' % env \n",
    "    with open(filE,'w') as o:\n",
    "        key0 = shiftDict.keys()[0]\n",
    "        line = '\\t'.join(shiftDict[key0].keys()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        for popk in shiftDict.keys():\n",
    "            text = str(popk)+'\\t'+'\\t'.join([str(d) for d in shiftDict[popk].values()])+'\\n'\n",
    "            o.write(\"%s\" % text)\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for env in sorted(intset):\n",
    "    jobs.append(lview.apply_async(getshiftDict,[env,impMAF,popDict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count =0\n",
    "for j in jobs:\n",
    "    if j.ready():\n",
    "        count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get pDij matrices, make them symmetric\n",
    "shiftDF = OrderedDict()\n",
    "for env in intset:\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_dij.txt' % env\n",
    "    shiftDF[env] = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "    for i,row in enumerate(shiftDF[env].index):\n",
    "        for j,col in enumerate(shiftDF[env].columns):\n",
    "            if i == j:\n",
    "                shiftDF[env].loc[row,col] = 0\n",
    "            elif math.isnan(shiftDF[env].loc[row,col]) == True:\n",
    "                shiftDF[env].loc[row,col] = shiftDF[env].loc[col,row]\n",
    "    filE = filE.split(\".\")[0]\n",
    "    filE =  \"%s_symm.txt\" % filE\n",
    "    print filE\n",
    "    shiftDF[env].to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shiftDF[env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/wbp/bayenv2/distance_matrices/geographic_distances.txt'\n",
    "geodist = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "geodist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get rid of the km\n",
    "for i,popi in enumerate(geodist.index):\n",
    "    for j,popj in enumerate(geodist.columns):\n",
    "        if i>j:\n",
    "            geodist.loc[popi,popj] = float(geodist.loc[popi,popj].split()[0])\n",
    "geodist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,popi in enumerate(geodist.index):\n",
    "    for j,popj in enumerate(geodist.columns):\n",
    "        if i == j:\n",
    "            geodist.loc[popi,popj] = 0\n",
    "        elif math.isnan(geodist.loc[popi,popj]) == True:\n",
    "            geodist.loc[popi,popj] = geodist.loc[popj,popi]\n",
    "geodist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#are pairwise population LD distances correlated to pairwise population geographic distances?\n",
    "#corrected for pop freq\n",
    "for env in sorted(shiftDF.keys()):\n",
    "    print env, mantel(shiftDF[env],geodist,permutations=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#are pairwise population LD distances correlated to pairwise population geographic distances?\n",
    "#old\n",
    "for env in shiftDF.keys():\n",
    "    print env, mantel(shiftDF[env],geodist,permutations=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get environmental distance data\n",
    "#files made in 09_OutFLANK\n",
    "envdDict = OrderedDict()\n",
    "for env in shiftDF.keys():\n",
    "    filE = '/home/lindb/wbp/distance_matrices/%s_dist_symm.txt' % env\n",
    "    envdDict[env] = pd.read_csv(filE,header=0,index_col=0,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data for scatter plots\n",
    "shiftlst = OrderedDict()\n",
    "for env in shiftDF.keys():\n",
    "    shiftlst[env] = []\n",
    "    for i,row in enumerate(shiftDF[env].index):\n",
    "        for j,col in enumerate(shiftDF[env].columns):\n",
    "            if i >j:\n",
    "                shiftlst[env].append(shiftDF[env].loc[row,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PdfPages('/home/lindb/wbp/figures/abs_dij_v_envdist_sameenv_AWSO-Lat.pdf') as pdf:\n",
    "    plt.close('all')\n",
    "    fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "    a1 = plt.subplot(331)\n",
    "    a1.scatter(shiftlst['AWS0-25'],distlst['AWS0-25'])\n",
    "    a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a1.spines['right'].set_visible(False)\n",
    "    a1.spines['top'].set_visible(False)\n",
    "    a1.yaxis.set_ticks_position('left')\n",
    "    a1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a2 = plt.subplot(332)\n",
    "    a2.scatter(shiftlst['AWS0-50'],distlst['AWS0-50'])\n",
    "    a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a2.spines['right'].set_visible(False)\n",
    "    a2.spines['top'].set_visible(False)\n",
    "    a2.yaxis.set_ticks_position('left')\n",
    "    a2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a3 = plt.subplot(333)\n",
    "    a3.scatter(shiftlst['Ann-ppt'],distlst['Ann-ppt'])\n",
    "    a3.set_title('C',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a3.spines['right'].set_visible(False)\n",
    "    a3.spines['top'].set_visible(False)\n",
    "    a3.yaxis.set_ticks_position('left')\n",
    "    a3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a4 = plt.subplot(334)\n",
    "    a4.scatter(shiftlst['CEC'],distlst['CEC'])\n",
    "    a4.set_title('D',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a4.spines['right'].set_visible(False)\n",
    "    a4.spines['top'].set_visible(False)\n",
    "    a4.yaxis.set_ticks_position('left')\n",
    "    a4.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a5 = plt.subplot(335)\n",
    "    a5.scatter(shiftlst['Clay'],distlst['Clay'])\n",
    "    a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a5.spines['right'].set_visible(False)\n",
    "    a5.spines['top'].set_visible(False)\n",
    "    a5.yaxis.set_ticks_position('left')\n",
    "    a5.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a6 = plt.subplot(336)\n",
    "    a6.scatter(shiftlst['Elev'],distlst['Elev'])\n",
    "    a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a6.spines['right'].set_visible(False)\n",
    "    a6.spines['top'].set_visible(False)\n",
    "    a6.yaxis.set_ticks_position('left')\n",
    "    a6.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a7 = plt.subplot(337)\n",
    "    a7.scatter(shiftlst['GDD-Aug'],distlst['GDD-Aug'])\n",
    "    a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a7.spines['right'].set_visible(False)\n",
    "    a7.spines['top'].set_visible(False)\n",
    "    a7.yaxis.set_ticks_position('left')\n",
    "    a7.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a8 = plt.subplot(338)\n",
    "    a8.scatter(shiftlst['GDD-May'],distlst['GDD-May'])\n",
    "    a8.set_title('H',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a8.spines['right'].set_visible(False)\n",
    "    a8.spines['top'].set_visible(False)\n",
    "    a8.yaxis.set_ticks_position('left')\n",
    "    a8.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a9 = plt.subplot(339)\n",
    "    a9.scatter(shiftlst['Lat'],distlst['Lat'])\n",
    "    a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a9.spines['right'].set_visible(False)\n",
    "    a9.spines['top'].set_visible(False)\n",
    "    a9.yaxis.set_ticks_position('left')\n",
    "    a9.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    fig.set_size_inches(13,10)\n",
    "    pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PdfPages('/home/lindb/wbp/figures/log_abs_dij_v_envdist_sameenv_AWSO-Lat.pdf') as pdf:\n",
    "    plt.close('all')\n",
    "    fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "    a1 = plt.subplot(331)\n",
    "    a1.scatter([math.log(x,10) for x in shiftlst['AWS0-25'] if x != 0],[x for i,x in enumerate(distlst['AWS0-25']) if shiftlst['AWS0-25'][i] !=0])\n",
    "    a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a1.spines['right'].set_visible(False)\n",
    "    a1.spines['top'].set_visible(False)\n",
    "    a1.yaxis.set_ticks_position('left')\n",
    "    a1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a2 = plt.subplot(332)\n",
    "    a2.scatter([math.log(x,10) for x in shiftlst['AWS0-50'] if x != 0],[x for i,x in enumerate(distlst['AWS0-50']) if shiftlst['AWS0-50'][i] !=0])\n",
    "    a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a2.spines['right'].set_visible(False)\n",
    "    a2.spines['top'].set_visible(False)\n",
    "    a2.yaxis.set_ticks_position('left')\n",
    "    a2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a3 = plt.subplot(333)\n",
    "    a3.scatter([math.log(x,10) for x in shiftlst['Ann-ppt'] if x != 0],[x for i,x in enumerate(distlst['Ann-ppt']) if shiftlst['Ann-ppt'][i] !=0])\n",
    "    a3.set_title('C*',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a3.spines['right'].set_visible(False)\n",
    "    a3.spines['top'].set_visible(False)\n",
    "    a3.yaxis.set_ticks_position('left')\n",
    "    a3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a4 = plt.subplot(334)\n",
    "    a4.scatter([math.log(x,10) for x in shiftlst['CEC'] if x != 0],[x for i,x in enumerate(distlst['CEC']) if shiftlst['CEC'][i] !=0])\n",
    "    a4.set_title('D',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a4.spines['right'].set_visible(False)\n",
    "    a4.spines['top'].set_visible(False)\n",
    "    a4.yaxis.set_ticks_position('left')\n",
    "    a4.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a5 = plt.subplot(335)\n",
    "    a5.scatter([math.log(x,10) for x in shiftlst['Clay'] if x != 0],[x for i,x in enumerate(distlst['Clay']) if shiftlst['Clay'][i] !=0])\n",
    "    a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a5.spines['right'].set_visible(False)\n",
    "    a5.spines['top'].set_visible(False)\n",
    "    a5.yaxis.set_ticks_position('left')\n",
    "    a5.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a6 = plt.subplot(336)\n",
    "    a6.scatter([math.log(x,10) for x in shiftlst['Elev'] if x != 0],[x for i,x in enumerate(distlst['Elev']) if shiftlst['Elev'][i] !=0])\n",
    "    a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a6.spines['right'].set_visible(False)\n",
    "    a6.spines['top'].set_visible(False)\n",
    "    a6.yaxis.set_ticks_position('left')\n",
    "    a6.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a7 = plt.subplot(337)\n",
    "    a7.scatter([math.log(x,10) for x in shiftlst['GDD-Aug'] if x != 0],[x for i,x in enumerate(distlst['GDD-Aug']) if shiftlst['GDD-Aug'][i] !=0])\n",
    "    a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a7.spines['right'].set_visible(False)\n",
    "    a7.spines['top'].set_visible(False)\n",
    "    a7.yaxis.set_ticks_position('left')\n",
    "    a7.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a8 = plt.subplot(338)\n",
    "    a8.scatter([math.log(x,10) for x in shiftlst['GDD-May'] if x != 0],[x for i,x in enumerate(distlst['GDD-May']) if shiftlst['GDD-May'][i] !=0])\n",
    "    a8.set_title('H*',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a8.spines['right'].set_visible(False)\n",
    "    a8.spines['top'].set_visible(False)\n",
    "    a8.yaxis.set_ticks_position('left')\n",
    "    a8.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a9 = plt.subplot(339)\n",
    "    a9.scatter([math.log(x,10) for x in shiftlst['Lat'] if x != 0],[x for i,x in enumerate(distlst['Lat']) if shiftlst['Lat'][i] !=0])\n",
    "    a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a9.spines['right'].set_visible(False)\n",
    "    a9.spines['top'].set_visible(False)\n",
    "    a9.yaxis.set_ticks_position('left')\n",
    "    a9.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    fig.set_size_inches(13,10)\n",
    "    pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against the same env Euclidian distance \n",
    "#corrected\n",
    "for env in sorted(shiftDF.keys()):\n",
    "    mant = mantel(shiftDF[env],envdDict[env],permutations=9999)\n",
    "    if mant[1] <= 0.05:\n",
    "        print env, mant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against the same env Euclidian distance \n",
    "#old\n",
    "for env in shiftDF.keys():\n",
    "    mant = mantel(shiftDF[env],envdDict[env],permutations=9999)\n",
    "    if mant[1] <= 0.05:\n",
    "        print env, mant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against other env Euclidian distances - deleted print to comment\n",
    "#corrected\n",
    "mant = OrderedDict()\n",
    "for i,envi in enumerate(sorted(shiftDF.keys())):\n",
    "    mant[envi] = OrderedDict()\n",
    "    for j,envj in enumerate(sorted(envdDict.keys())):\n",
    "        if i > j:\n",
    "            mant[envi][envj] = mantel(shiftDF[envi],envdDict[envj],permutations=9999) # ,permutations=9999\n",
    "            #print envi,envj, mant[1]\n",
    "            if mant[envi][envj][1] <= 0.05:\n",
    "                print envi,'loci Dij vs ',envj,'Euclidian distances\\n',mant[envi][envj],'\\n' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against other env Euclidian distances - deleted print to comment\n",
    "#old\n",
    "mant = OrderedDict()\n",
    "for i,envi in enumerate(shiftDF.keys()):\n",
    "    mant[envi] = OrderedDict()\n",
    "    for j,envj in enumerate(envdDict.keys()):\n",
    "        if i > j:\n",
    "            mant[envi][envj] = mantel(shiftDF[envi],envdDict[envj],permutations=9999) # ,permutations=9999\n",
    "            #print envi,envj, mant[1]\n",
    "            if mant[envi][envj][1] <= 0.05:\n",
    "                print envi,'loci Dij vs ',envj,'Euclidian distances\\n',mant[envi][envj],'\\n' \n",
    "#Lon loci Dij vs  Ann-ppt Euclidian distances\n",
    "#(0.7716010350739726, 0.0016000000000000001, 8) \n",
    "#\n",
    "#Lon loci Dij vs  Lat Euclidian distances\n",
    "#(-0.42566652606664973, 0.0332, 8) \n",
    "#\n",
    "#Rock-cov loci Dij vs  Ann-ppt Euclidian distances\n",
    "#(0.55424357362000032, 0.022200000000000001, 8) \n",
    "#\n",
    "#Rock-cov loci Dij vs  Lon Euclidian distances\n",
    "#(0.55685544364774331, 0.0252, 8) \n",
    "#\n",
    "#Sand loci Dij vs  Clay Euclidian distances\n",
    "#(0.53454002690746905, 0.0207, 8) \n",
    "#\n",
    "#Silt loci Dij vs  Sand Euclidian distances\n",
    "#(0.44079182582652993, 0.023699999999999999, 8) \n",
    "#\n",
    "#Tmin-Jan loci Dij vs  Ann-ppt Euclidian distances\n",
    "#(0.57650137127397227, 0.0135, 8) \n",
    "#\n",
    "#Tmin-Jan loci Dij vs  Lon Euclidian distances\n",
    "#(0.48221840890815115, 0.028799999999999999, 8) \n",
    "#\n",
    "#WC15Bar loci Dij vs  Tmax-July Euclidian distances\n",
    "#(0.34904867738608325, 0.028500000000000001, 8) \n",
    "#\n",
    "#WC3rdbar loci Dij vs  AWS0-25 Euclidian distances\n",
    "#(0.43294142988706169, 0.036600000000000001, 8) \n",
    "#\n",
    "#WC3rdbar loci Dij vs  AWS0-50 Euclidian distances\n",
    "#(0.45379228695092727, 0.046699999999999998, 8) \n",
    "#\n",
    "#WC3rdbar loci Dij vs  Tmax-July Euclidian distances\n",
    "#(0.45389697231068271, 0.0030999999999999999, 8) \n",
    "#\n",
    "#WC3rdbar loci Dij vs  WC15Bar Euclidian distances\n",
    "#(0.51257777427440188, 0.029499999999999998, 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sigenvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#look for patters from euclidian dists\n",
    "#corrected\n",
    "eucs = OrderedDict()\n",
    "for i,envi in enumerate(sorted(envdDict.keys())):\n",
    "    eucs[envi] = OrderedDict()\n",
    "    for j,envj in enumerate(sorted(envdDict.keys())):\n",
    "        if i > j:\n",
    "            eucs[envi][envj] = mantel(envdDict[envi],envdDict[envj],permutations = 9999)\n",
    "            if eucs[envi][envj][1] <=0.05:\n",
    "                print envi,envj,eucs[envi][envj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#look for patters from euclidian dists\n",
    "#old\n",
    "eucs = OrderedDict()\n",
    "for i,envi in enumerate(envdDict.keys()):\n",
    "    eucs[envi] = OrderedDict()\n",
    "    for j,envj in enumerate(envdDict.keys()):\n",
    "        if i > j:\n",
    "            eucs[envi][envj] = mantel(envdDict[envi],envdDict[envj],permutations = 9999)\n",
    "            if eucs[envi][envj][1] <=0.05:\n",
    "                print envi,envj,eucs[envi][envj]\n",
    "#AWS0-50 AWS0-25 (0.92563195780663798, 0.00059999999999999995, 8)\n",
    "#Clay CEC (0.94243026430775967, 0.0015, 8)\n",
    "#Lat Elev (0.39876994024295709, 0.045199999999999997, 8)\n",
    "#Lon Ann-ppt (0.7145343340679835, 0.0022000000000000001, 8)\n",
    "#Max-rad-input Lat (0.46285891784178229, 0.033000000000000002, 8)\n",
    "#Sand AWS0-50 (0.43931703114531706, 0.018800000000000001, 8)\n",
    "#Sand Clay (0.3723300732412157, 0.032500000000000001, 8)\n",
    "#Silt AWS0-25 (0.56910810657784439, 0.020500000000000001, 8)\n",
    "#Silt AWS0-50 (0.75523793270279638, 0.0057000000000000002, 8)\n",
    "#Silt Sand (0.83954421938148982, 0.0001, 8)\n",
    "#Tmin-Jan GDD-Aug (0.45450267193847571, 0.0361, 8)\n",
    "#WC15Bar AWS0-25 (0.67219012746044704, 0.01, 8)\n",
    "#WC15Bar AWS0-50 (0.8511126463087334, 0.002, 8)\n",
    "#WC15Bar Silt (0.68065119836969423, 0.0152, 8)\n",
    "#WC3rdbar AWS0-25 (0.60929292004599522, 0.0177, 8)\n",
    "#WC3rdbar AWS0-50 (0.77608813807768406, 0.0057000000000000002, 8)\n",
    "#WC3rdbar Silt (0.55818888588782412, 0.030099999999999998, 8)\n",
    "#WC3rdbar WC15Bar (0.94230567933893883, 0.00020000000000000001, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#patterns of environmental distance to geographic distance\n",
    "#corrected\n",
    "for env in sorted(envdDict.keys()):\n",
    "    mant = mantel(envdDict[env],geodist,permutations=9999)\n",
    "    #if mant[1] <= 0.05:\n",
    "        #print env,mant\n",
    "    print env,mant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#patterns of environmental distance to geographic distance\n",
    "#old\n",
    "for env in envdDict.keys():\n",
    "    mant = mantel(envdDict[env],geodist,permutations=9999)\n",
    "    #if mant[1] <= 0.05:\n",
    "        #print env,mant\n",
    "    print env,mant\n",
    "#AWS0-25 (-0.10608611710064117, 0.6159, 8)\n",
    "#AWS0-50 (-0.10662414876775597, 0.69989999999999997, 8)\n",
    "#Ann-ppt (-0.1825290530704001, 0.28789999999999999, 8)\n",
    "#CEC (0.24308086638413512, 0.15240000000000001, 8)\n",
    "#Clay (0.27161756617669391, 0.091499999999999998, 8)\n",
    "#Elev (0.40617770554536675, 0.044400000000000002, 8)\n",
    "#GDD-Aug (0.060192865042875195, 0.73899999999999999, 8)\n",
    "#GDD-May (0.091559881387966044, 0.74639999999999995, 8)\n",
    "#Lat (0.96306650501124502, 0.00020000000000000001, 8)\n",
    "#Lon (0.11594248224889436, 0.51459999999999995, 8)\n",
    "#Max-rad-input (0.39916883319045005, 0.044600000000000001, 8)\n",
    "#Rock-cov (-0.0013653758034187704, 0.99319999999999997, 8)\n",
    "#Sand (-0.065400320530522443, 0.70289999999999997, 8)\n",
    "#Silt (-0.11938536549339876, 0.5847, 8)\n",
    "#Tmax-July (0.36685027020170108, 0.0717, 8)\n",
    "#Tmin-Jan (-0.008502374494668636, 0.96970000000000001, 8)\n",
    "#WC15Bar (0.080797777802775472, 0.79679999999999995, 8)\n",
    "#WC3rdbar (0.19001363716445102, 0.30890000000000001, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# split positive and negative Dij and run mantel tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do pairwise pops for empirical SNPs IDed by bayenv2 and calculate median Dij for each pop pair\n",
    "def getrawshiftDict(tokens):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from collections import OrderedDict\n",
    "    \n",
    "    env,impMAF,popDict = tokens\n",
    "    \n",
    "    shiftDictpos = OrderedDict() \n",
    "    shiftDictneg = OrderedDict()\n",
    "    kcount = 0\n",
    "    print env\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/sigsnps/%s_top_p05%%BF_1%%rho.txt' % env\n",
    "    df = pd.read_csv(filE,header=0,sep='\\t')\n",
    "    outliersnps = df[env].tolist()\n",
    "    for m,popm in enumerate(impMAF.columns):\n",
    "        print popm\n",
    "        shiftDictpos[popm] = OrderedDict()\n",
    "        shiftDictneg[popm] = OrderedDict()\n",
    "        for l,popl in enumerate(impMAF.columns):\n",
    "            if m>l: #only need to do the lower triangle - can reflect across diagonal later more quickly\n",
    "                dijlist = []\n",
    "                for i,locusi in enumerate(outliersnps):\n",
    "                    for j,locusj in enumerate(outliersnps):\n",
    "                        if i > j: #i=row, j=col : lower triangle \n",
    "                            sums =0 #Dij\n",
    "                            kcount += 1\n",
    "                            for popk in [popm,popl]:\n",
    "                                qik = impMAF.loc[locusi,popk]        #get locusi maf for pop k\n",
    "                                qjk = impMAF.loc[locusj,popk]        #get locusj maf for pop k\n",
    "                                nk = popDict[popk]                   #N  individuals  in pop k\n",
    "\n",
    "                                globN = 2*(popDict[popm]+popDict[popl]) # number of alleles across 2 pops\n",
    "\n",
    "                                #get global mafs\n",
    "                                fqim = impMAF.loc[locusi,popm]        #minor allele locusi freq  in popm\n",
    "                                nqim = round(fqim*2*popDict[popm])    #minor allele locusi count in popm\n",
    "                                fqil = impMAF.loc[locusi,popl]        #minor allele locusi freq  in popl\n",
    "                                nqil = round(fqil*2*popDict[popl])    #minor allele locusi count in popl\n",
    "\n",
    "                                fqjm = impMAF.loc[locusj,popm]        #minor allele locusj freq  in popm\n",
    "                                nqjm = round(fqjm*2*popDict[popm])    #minor allele locusj count in popm\n",
    "                                fqjl = impMAF.loc[locusj,popl]        #minor allele locusj freq  in popl\n",
    "                                nqjl = round(fqjl*2*popDict[popl])    #minor allele locusj count in popl\n",
    "\n",
    "                                qi = float(nqim+nqil)/float((2*popDict[popm])+(2*popDict[popl])) #global maf locusi\n",
    "                                qj = float(nqjm+nqjl)/float((2*popDict[popm])+(2*popDict[popl])) #global maf locusj\n",
    "\n",
    "                                sums += (float(nk)/float(popDict[popm]+popDict[popl]))*((qik*qjk)-(qi*qj))\n",
    "\n",
    "                            dijlist.append(sums) #each pairwise pop comparison has a matrix of Dij\n",
    "                        else:\n",
    "                            pass #no redundancies, no diagonal. \n",
    "                pos = [x for x in dijlist if x >= 0]\n",
    "                neg = [x for x in dijlist if x <=  0]\n",
    "                shiftDictpos[popm][popl] = np.median([d for d in pos])\n",
    "                shiftDictneg[popm][popl] = np.median([d for d in neg])\n",
    "                \n",
    "            else:\n",
    "                shiftDictpos[popm][popl] = np.nan #no redundancies,no diagonal. will be faster to reflect across diag later\n",
    "                shiftDictneg[popm][popl] = np.nan #no redundancies,no diagonal. will be faster to reflect across diag later\n",
    "    #    if kcount > 1:\n",
    "    #        break\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_positive_dij_withzeros.txt' % env \n",
    "    with open(filE,'w') as o:\n",
    "        key0 = shiftDictpos.keys()[0]\n",
    "        line = '\\t'.join(shiftDictpos[key0].keys()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        for popk in shiftDictpos.keys():\n",
    "            text = str(popk)+'\\t'+'\\t'.join([str(d) for d in shiftDictpos[popk].values()])+'\\n'\n",
    "            o.write(\"%s\" % text)\n",
    "            \n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_negative_dij_withzeros.txt' % env \n",
    "    with open(filE,'w') as o:\n",
    "        key0 = shiftDictneg.keys()[0]\n",
    "        line = '\\t'.join(shiftDictneg[key0].keys()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        for popk in shiftDictneg.keys():\n",
    "            text = str(popk)+'\\t'+'\\t'.join([str(d) for d in shiftDictneg[popk].values()])+'\\n'\n",
    "            o.write(\"%s\" % text)\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for env in outlierdata.keys():\n",
    "    jobs.append(lview.apply_async(getrawshiftDict,[env,impMAF,popDict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for j in jobs:\n",
    "    if j.ready():\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nozeroposDF = OrderedDict()\n",
    "for env in outlierdata.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_positive_dij_nozeros.txt' % env\n",
    "    nozeroposDF[env] = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "    for i,row in enumerate(nozeroposDF[env].index):\n",
    "        for j,col in enumerate(nozeroposDF[env].columns):\n",
    "            if i == j:\n",
    "                nozeroposDF[env].loc[row,col] = 0\n",
    "            elif math.isnan(float(nozeroposDF[env].loc[row,col])) == True:\n",
    "                nozeroposDF[env].loc[row,col] = nozeroposDF[env].loc[col,row]\n",
    "    filE = filE.split(\".\")[0]\n",
    "    filE =  \"%s_symm.txt\" % filE\n",
    "    print filE\n",
    "    nozeroposDF[env].to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nozeroposDF['Ann-ppt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nozeronegDF = OrderedDict()\n",
    "for env in outlierdata.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_negative_dij_nozeros.txt' % env\n",
    "    nozeronegDF[env] = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "    for i,row in enumerate(nozeronegDF[env].index):\n",
    "        for j,col in enumerate(nozeronegDF[env].columns):\n",
    "            if i == j:\n",
    "                nozeronegDF[env].loc[row,col] = 0\n",
    "            elif nozeronegDF[env].loc[row,col] == 'zero':\n",
    "                print 'zero',nozeronegDF[env].loc[row,col]\n",
    "                nozeronegDF[env].loc[row,col] = float(0)\n",
    "                print 'changed',nozeronegDF[env].loc[row,col]\n",
    "            elif math.isnan(float(nozeronegDF[env].loc[row,col])) == True:\n",
    "                nozeronegDF[env].loc[row,col] = nozeronegDF[env].loc[col,row]\n",
    "    filE = filE.split(\".\")[0]\n",
    "    filE =  \"%s_symm.txt\" % filE\n",
    "    print filE\n",
    "    nozeronegDF[env].to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nozeronegDF['Ann-ppt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withzeroposDF = OrderedDict()\n",
    "for env in outlierdata.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_positive_dij_withzeros.txt' % env\n",
    "    withzeroposDF[env] = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "    for i,row in enumerate(withzeroposDF[env].index):\n",
    "        for j,col in enumerate(withzeroposDF[env].columns):\n",
    "            if i == j:\n",
    "                withzeroposDF[env].loc[row,col] = 0\n",
    "            elif math.isnan(float(withzeroposDF[env].loc[row,col])) == True:\n",
    "                withzeroposDF[env].loc[row,col] = withzeroposDF[env].loc[col,row]\n",
    "    filE = filE.split(\".\")[0]\n",
    "    filE =  \"%s_symm.txt\" % filE\n",
    "    print filE\n",
    "    withzeroposDF[env].to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withzeronegDF = OrderedDict()\n",
    "for env in outlierdata.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_negative_dij_withzeros.txt' % env\n",
    "    withzeronegDF[env] = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "    for i,row in enumerate(withzeronegDF[env].index):\n",
    "        for j,col in enumerate(withzeronegDF[env].columns):\n",
    "            if i == j:\n",
    "                withzeronegDF[env].loc[row,col] = 0\n",
    "            elif math.isnan(float(withzeronegDF[env].loc[row,col])) == True:\n",
    "                withzeronegDF[env].loc[row,col] = withzeronegDF[env].loc[col,row]\n",
    "    filE = filE.split(\".\")[0]\n",
    "    filE =  \"%s_symm.txt\" % filE\n",
    "    print filE\n",
    "    withzeronegDF[env].to_csv(filE,header=True,index=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlierdata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_r(): \n",
    "    os.environ['R_HOME'] = '/home/lindb/g/R3/lib64/R/' \n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_r()\n",
    "import readline\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri as pd2ri\n",
    "pd2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "envs = c('AWS0-25',\n",
    " 'AWS0-50',\n",
    " 'Ann-ppt',\n",
    " 'CEC',\n",
    " 'Clay',\n",
    " 'Elev',\n",
    " 'GDD-Aug',\n",
    " 'GDD-May',\n",
    " 'Lat',\n",
    " 'Lon',\n",
    " 'Max-rad-input',\n",
    " 'Rock-cov',\n",
    " 'Sand',\n",
    " 'Silt',\n",
    " 'Tmax-July',\n",
    " 'Tmin-Jan',\n",
    " 'WC15Bar',\n",
    " 'WC3rdbar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#read in the Dij files\n",
    "library(stringr)\n",
    "nozerosneg = list()\n",
    "for (env in envs){\n",
    "    i = which(envs == env)\n",
    "    f = \"/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_negative_dij_nozeros_symm.txt\"\n",
    "    filE = str_replace(f,\"%s\",env)\n",
    "    nozerosneg[[i]] = read.table(filE,sep='\\t',header=TRUE,row.names=1)\n",
    "    names(nozerosneg)[i] = env\n",
    "}\n",
    "wzerosneg = list()\n",
    "for (env in envs){\n",
    "    i = which(envs == env)\n",
    "    f = \"/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_negative_dij_withzeros_symm.txt\"\n",
    "    filE = str_replace(f,\"%s\",env)\n",
    "    wzerosneg[[i]] = read.table(filE,sep='\\t',header=TRUE,row.names=1)\n",
    "    names(wzerosneg)[i] = env\n",
    "}\n",
    "nozerospos = list()\n",
    "for (env in envs){\n",
    "    i = which(envs == env)\n",
    "    f = \"/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_positive_dij_nozeros_symm.txt\"\n",
    "    filE = str_replace(f,\"%s\",env)\n",
    "    nozerospos[[i]] = read.table(filE,sep='\\t',header=TRUE,row.names=1)\n",
    "    names(nozerospos)[i] = env\n",
    "}\n",
    "wzerospos = list()\n",
    "for (env in envs){\n",
    "    i = which(envs == env)\n",
    "    f = \"/home/lindb/wbp/bayenv2/freqshifts/%s_pop_pairwise_median_positive_dij_withzeros_symm.txt\"\n",
    "    filE = str_replace(f,\"%s\",env)\n",
    "    wzerospos[[i]] = read.table(filE,sep='\\t',header=TRUE,row.names=1)\n",
    "    names(wzerospos)[i] = env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#get the environmental distance matrices\n",
    "envdist = list()\n",
    "for (env in envs){\n",
    "    i = which(envs==env)\n",
    "    f = \"/home/lindb/wbp/distance_matrices/%s_dist_symm.txt\"\n",
    "    filE = str_replace(f,\"%s\",env)\n",
    "    envdist[[i]] = read.table(filE,sep='\\t',header=TRUE,row.names=1)\n",
    "    names(envdist)[i] = env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(vegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "nozerosneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#run mantel tests for neg Dijs calculated without zeros\n",
    "for(env in envs){\n",
    "    i = which(envs==env)\n",
    "    mant = mantel(nozerosneg[[env]],envdist[[env]],method=\"pearson\",permutations=999,na.rm=TRUE)\n",
    "    if (mant$signif <= 0.05){\n",
    "        print(env)\n",
    "        print(mant)        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#run mantel tests for neg Dijs calculated with zeros\n",
    "for(env in envs){\n",
    "    i = which(envs==env)\n",
    "    mant = mantel(wzerosneg[[env]],envdist[[env]],method=\"pearson\",permutations=999,na.rm=TRUE)\n",
    "    if (mant$signif <= 0.05){\n",
    "        print(env)\n",
    "        print(mant)        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#run mantel tests for pos Dijs calculated with zeros\n",
    "for(env in envs){\n",
    "    mant = mantel(wzerospos[[env]],envdist[[env]],method=\"pearson\",permutations=999,na.rm=TRUE)\n",
    "    if (mant$signif <= 0.05){\n",
    "        print(env)\n",
    "        print(mant)        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#run mantel tests for pos Dijs calculated without zeros\n",
    "for(env in envs){\n",
    "    mant = mantel(nozerospos[[env]],envdist[[env]],method=\"pearson\",permutations=999,na.rm=TRUE)\n",
    "    if (mant$signif <= 0.05){\n",
    "        print(env)\n",
    "        print(mant)        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "annpptnozeros = nozerospos[['Ann-ppt']][lower.tri(nozerospos[['Ann-ppt']])]\n",
    "annpptnozeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "apptenvdist = envdist[['Ann-ppt']][lower.tri(envdist[['Ann-ppt']])]\n",
    "apptenvdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(annpptnozeros,apptenvdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against the same env Euclidian distance - deleted print to comment\n",
    "for env in posshiftDF.keys():\n",
    "    mant = mantel(posshiftDF[env],envdDict[env],permutations=9999)\n",
    "    if mant[1] <= 0.05:\n",
    "        print env, mant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against other env Euclidian distances - deleted print to comment\n",
    "posmant= OrderedDict()\n",
    "for i,envi in enumerate(posshiftDF.keys()):\n",
    "    posmant[envi] = OrderedDict()\n",
    "    for j,envj in enumerate(posshiftDF.keys()):\n",
    "        if i > j:\n",
    "            posmant[envi][envj] = mantel(posshiftDF[envi],envdDict[envj],permutations=999) # ,permutations=9999\n",
    "            #print envi,envj, posmant[1]\n",
    "            if posmant[envi][envj][1] <= 0.05:\n",
    "                print envi,'loci Dij vs ',envj,'Euclidian distances\\n',posmant[envi][envj],'\\n' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against the same env Euclidian distance - deleted print to comment\n",
    "for env in negshiftDF.keys():\n",
    "    mant = mantel(negshiftDF[env],envdDict[env],permutations=999)\n",
    "    if mant[1] <= 0.05:\n",
    "        print env, mant\n",
    "#AWS0-50 (-0.5187120808294664, 0.048000000000000001, 8)\n",
    "#Elev (-0.38386332885151592, 0.035999999999999997, 8)\n",
    "#GDD-May (-0.49436024387658395, 0.025999999999999999, 8)\n",
    "#Lat (-0.38351080073888355, 0.047, 8)\n",
    "#Lon (-0.39247528366555717, 0.017000000000000001, 8)\n",
    "#Silt (-0.50109539481141629, 0.035000000000000003, 8)\n",
    "#WC15Bar (-0.55864761263082974, 0.050000000000000003, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance correlations for env Dij among outliers against other env Euclidian distances - deleted print to comment\n",
    "negmant= OrderedDict()\n",
    "for i,envi in enumerate(negshiftDF.keys()):\n",
    "    negmant[envi] = OrderedDict()\n",
    "    for j,envj in enumerate(negshiftDF.keys()):\n",
    "        if i > j:\n",
    "            negmant[envi][envj] = mantel(negshiftDF[envi],envdDict[envj],permutations=999) # ,permutations=9999\n",
    "            #print envi,envj, negmant[1]\n",
    "            if negmant[envi][envj][1] <= 0.05:\n",
    "                print envi,'loci Dij vs ',envj,'Euclidian distances\\n',negmant[envi][envj],'\\n' \n",
    "#AWS0-50 loci Dij vs  AWS0-25 Euclidian distances\n",
    "#(-0.45711120411044837, 0.049000000000000002, 8) \n",
    "#\n",
    "#CEC loci Dij vs  Ann-ppt Euclidian distances\n",
    "#(-0.39739357529313168, 0.032000000000000001, 8) \n",
    "#\n",
    "#GDD-Aug loci Dij vs  Elev Euclidian distances\n",
    "#(-0.43586420866039266, 0.031, 8) \n",
    "#\n",
    "#Lat loci Dij vs  CEC Euclidian distances\n",
    "#(-0.54522328655821961, 0.033000000000000002, 8) \n",
    "#\n",
    "#Lat loci Dij vs  Elev Euclidian distances\n",
    "#(-0.42828652409270873, 0.032000000000000001, 8) \n",
    "#\n",
    "#Lon loci Dij vs  Ann-ppt Euclidian distances\n",
    "#(-0.44268477932420164, 0.017000000000000001, 8) \n",
    "#\n",
    "#Max-rad-input loci Dij vs  Ann-ppt Euclidian distances\n",
    "#(-0.49073697619324924, 0.014999999999999999, 8) \n",
    "#\n",
    "#Max-rad-input loci Dij vs  Lon Euclidian distances\n",
    "#(-0.36898951713648914, 0.045999999999999999, 8) \n",
    "#\n",
    "#Sand loci Dij vs  Clay Euclidian distances\n",
    "#(-0.50749772113017022, 0.021000000000000001, 8) \n",
    "#\n",
    "#Silt loci Dij vs  AWS0-25 Euclidian distances\n",
    "#(-0.45042297309726187, 0.047, 8) \n",
    "#\n",
    "#Silt loci Dij vs  Sand Euclidian distances\n",
    "#(-0.38456814005183487, 0.047, 8) \n",
    "#\n",
    "#WC15Bar loci Dij vs  AWS0-25 Euclidian distances\n",
    "#(-0.51462685560320931, 0.029000000000000001, 8) \n",
    "#\n",
    "#WC15Bar loci Dij vs  AWS0-50 Euclidian distances\n",
    "#(-0.5537241770139858, 0.037999999999999999, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neglst = OrderedDict()\n",
    "for env in envdDict.keys():\n",
    "    neglst[env] = []\n",
    "    for i,row in enumerate(negshiftDF[env].index):\n",
    "        for j,col in enumerate(negshiftDF[env].columns):\n",
    "            if i > j:\n",
    "                neglst[env].append(negshiftDF[env].loc[row,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poslst = OrderedDict()\n",
    "for env in envdDict.keys():\n",
    "    poslst[env] = []\n",
    "    for i,row in enumerate(posshiftDF[env].index):\n",
    "        for j,col in enumerate(posshiftDF[env].columns):\n",
    "            if i > j:\n",
    "                poslst[env].append(posshiftDF[env].loc[row,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distlst = OrderedDict()\n",
    "for env in envdDict.keys():\n",
    "    distlst[env] = []\n",
    "    for i,row in enumerate(envdDict[env].index):\n",
    "        for j,col in enumerate(envdDict[env].columns):\n",
    "            if i > j:\n",
    "                distlst[env].append(envdDict[env].loc[row,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#with PdfPages('/home/lindb/wbp/figures/neg_dij_v_envdist_sameenv_AWSO-Lat.pdf') as pdf:\n",
    "plt.close('all')\n",
    "fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "a1 = plt.subplot(331)\n",
    "a1.scatter(neglst['AWS0-25'],distlst['AWS0-25'])\n",
    "a1.set_title('AWS0-25',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a1.spines['right'].set_visible(False)\n",
    "a1.spines['top'].set_visible(False)\n",
    "a1.yaxis.set_ticks_position('left')\n",
    "a1.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a2 = plt.subplot(332)\n",
    "a2.scatter(neglst['AWS0-50'],distlst['AWS0-50'])\n",
    "a2.set_title('AWS0-50',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a2.spines['right'].set_visible(False)\n",
    "a2.spines['top'].set_visible(False)\n",
    "a2.yaxis.set_ticks_position('left')\n",
    "a2.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a3 = plt.subplot(333)\n",
    "a3.scatter(neglst['Ann-ppt'],distlst['Ann-ppt'])\n",
    "a3.set_title('Ann-ppt',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a3.spines['right'].set_visible(False)\n",
    "a3.spines['top'].set_visible(False)\n",
    "a3.yaxis.set_ticks_position('left')\n",
    "a3.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a4 = plt.subplot(334)\n",
    "a4.scatter(neglst['CEC'],distlst['CEC'])\n",
    "a4.set_title('CEC',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a4.spines['right'].set_visible(False)\n",
    "a4.spines['top'].set_visible(False)\n",
    "a4.yaxis.set_ticks_position('left')\n",
    "a4.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a5 = plt.subplot(335)\n",
    "a5.scatter(neglst['Clay'],distlst['Clay'])\n",
    "a5.set_title('Clay',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a5.spines['right'].set_visible(False)\n",
    "a5.spines['top'].set_visible(False)\n",
    "a5.yaxis.set_ticks_position('left')\n",
    "a5.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a6 = plt.subplot(336)\n",
    "a6.scatter(neglst['Elev'],distlst['Elev'])\n",
    "a6.set_title('Elev',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a6.spines['right'].set_visible(False)\n",
    "a6.spines['top'].set_visible(False)\n",
    "a6.yaxis.set_ticks_position('left')\n",
    "a6.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a7 = plt.subplot(337)\n",
    "a7.scatter(neglst['GDD-Aug'],distlst['GDD-Aug'])\n",
    "a7.set_title('GDD-Aug',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a7.spines['right'].set_visible(False)\n",
    "a7.spines['top'].set_visible(False)\n",
    "a7.yaxis.set_ticks_position('left')\n",
    "a7.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a8 = plt.subplot(338)\n",
    "a8.scatter(neglst['GDD-May'],distlst['GDD-May'])\n",
    "a8.set_title('GDD-May',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a8.spines['right'].set_visible(False)\n",
    "a8.spines['top'].set_visible(False)\n",
    "a8.yaxis.set_ticks_position('left')\n",
    "a8.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a9 = plt.subplot(339)\n",
    "a9.scatter(neglst['Lat'],distlst['Lat'])\n",
    "a9.set_title('Lat',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a9.spines['right'].set_visible(False)\n",
    "a9.spines['top'].set_visible(False)\n",
    "a9.yaxis.set_ticks_position('left')\n",
    "a9.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "fig.set_size_inches(13,10)\n",
    "#pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with PdfPages('/home/lindb/wbp/figures/log_neg_dij_v_envdist_sameenv_nozeros_AWSO-Lat.pdf') as pdf:\n",
    "plt.close('all')\n",
    "fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "a1 = plt.subplot(331)\n",
    "a1.scatter([x for x in neglst['AWS0-25'] if x != 0],[x for i,x in enumerate(distlst['AWS0-25']) if neglst['AWS0-25'][i] != 0])\n",
    "a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a1.spines['right'].set_visible(False)\n",
    "a1.spines['top'].set_visible(False)\n",
    "a1.yaxis.set_ticks_position('left')\n",
    "a1.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a2 = plt.subplot(332)\n",
    "a2.scatter([x for x in neglst['AWS0-50'] if x != 0],[x for i,x in enumerate(distlst['AWS0-50']) if neglst['AWS0-50'][i] != 0])\n",
    "a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a2.spines['right'].set_visible(False)\n",
    "a2.spines['top'].set_visible(False)\n",
    "a2.yaxis.set_ticks_position('left')\n",
    "a2.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a3 = plt.subplot(333)\n",
    "a3.scatter([x for x in neglst['Ann-ppt'] if x != 0],[x for i,x in enumerate(distlst['Ann-ppt']) if neglst['Ann-ppt'][i] != 0])\n",
    "a3.set_title('C',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a3.spines['right'].set_visible(False)\n",
    "a3.spines['top'].set_visible(False)\n",
    "a3.yaxis.set_ticks_position('left')\n",
    "a3.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a4 = plt.subplot(334)\n",
    "a4.scatter([x for x in neglst['CEC'] if x != 0],[x for i,x in enumerate(distlst['CEC']) if neglst['CEC'][i] != 0])\n",
    "a4.set_title('D',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a4.spines['right'].set_visible(False)\n",
    "a4.spines['top'].set_visible(False)\n",
    "a4.yaxis.set_ticks_position('left')\n",
    "a4.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a5 = plt.subplot(335)\n",
    "a5.scatter([x for x in neglst['Clay'] if x != 0],[x for i,x in enumerate(distlst['Clay']) if neglst['Clay'][i] != 0])\n",
    "a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a5.spines['right'].set_visible(False)\n",
    "a5.spines['top'].set_visible(False)\n",
    "a5.yaxis.set_ticks_position('left')\n",
    "a5.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a6 = plt.subplot(336)\n",
    "a6.scatter([x for x in neglst['Elev'] if x != 0],[x for i,x in enumerate(distlst['Elev']) if neglst['Elev'][i] != 0])\n",
    "a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a6.spines['right'].set_visible(False)\n",
    "a6.spines['top'].set_visible(False)\n",
    "a6.yaxis.set_ticks_position('left')\n",
    "a6.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a7 = plt.subplot(337)\n",
    "a7.scatter([x for x in neglst['GDD-Aug'] if x != 0],[x for i,x in enumerate(distlst['GDD-Aug']) if neglst['GDD-Aug'][i] != 0])\n",
    "a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a7.spines['right'].set_visible(False)\n",
    "a7.spines['top'].set_visible(False)\n",
    "a7.yaxis.set_ticks_position('left')\n",
    "a7.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a8 = plt.subplot(338)\n",
    "a8.scatter([x for x in neglst['GDD-May'] if x != 0],[x for i,x in enumerate(distlst['GDD-May']) if neglst['GDD-May'][i] != 0])\n",
    "a8.set_title('H',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a8.spines['right'].set_visible(False)\n",
    "a8.spines['top'].set_visible(False)\n",
    "a8.yaxis.set_ticks_position('left')\n",
    "a8.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "a9 = plt.subplot(339)\n",
    "a9.scatter([x for x in neglst['Lat'] if x != 0],[x for i,x in enumerate(distlst['Lat']) if neglst['Lat'][i] != 0])\n",
    "a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "a9.spines['right'].set_visible(False)\n",
    "a9.spines['top'].set_visible(False)\n",
    "a9.yaxis.set_ticks_position('left')\n",
    "a9.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "fig.set_size_inches(13,10)\n",
    "#pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PdfPages('/home/lindb/wbp/figures/log_neg_dij_v_envdist_sameenv_nozeros_AWSO-Lat.pdf') as pdf:\n",
    "    plt.close('all')\n",
    "    fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "    a1 = plt.subplot(331)\n",
    "    a1.scatter([math.log(-1*x,10) for x in neglst['AWS0-25'] if x != 0],[x for i,x in enumerate(distlst['AWS0-25']) if neglst['AWS0-25'][i] != 0])\n",
    "    a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a1.spines['right'].set_visible(False)\n",
    "    a1.spines['top'].set_visible(False)\n",
    "    a1.yaxis.set_ticks_position('left')\n",
    "    a1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a2 = plt.subplot(332)\n",
    "    a2.scatter([math.log(-1*x,10) for x in neglst['AWS0-50'] if x != 0],[x for i,x in enumerate(distlst['AWS0-50']) if neglst['AWS0-50'][i] != 0])\n",
    "    a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a2.spines['right'].set_visible(False)\n",
    "    a2.spines['top'].set_visible(False)\n",
    "    a2.yaxis.set_ticks_position('left')\n",
    "    a2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a3 = plt.subplot(333)\n",
    "    a3.scatter([math.log(-1*x,10) for x in neglst['Ann-ppt'] if x != 0],[x for i,x in enumerate(distlst['Ann-ppt']) if neglst['Ann-ppt'][i] != 0])\n",
    "    a3.set_title('C',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a3.spines['right'].set_visible(False)\n",
    "    a3.spines['top'].set_visible(False)\n",
    "    a3.yaxis.set_ticks_position('left')\n",
    "    a3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a4 = plt.subplot(334)\n",
    "    a4.scatter([math.log(-1*x,10) for x in neglst['CEC'] if x != 0],[x for i,x in enumerate(distlst['CEC']) if neglst['CEC'][i] != 0])\n",
    "    a4.set_title('D*',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a4.spines['right'].set_visible(False)\n",
    "    a4.spines['top'].set_visible(False)\n",
    "    a4.yaxis.set_ticks_position('left')\n",
    "    a4.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a5 = plt.subplot(335)\n",
    "    a5.scatter([math.log(-1*x,10) for x in neglst['Clay'] if x != 0],[x for i,x in enumerate(distlst['Clay']) if neglst['Clay'][i] != 0])\n",
    "    a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a5.spines['right'].set_visible(False)\n",
    "    a5.spines['top'].set_visible(False)\n",
    "    a5.yaxis.set_ticks_position('left')\n",
    "    a5.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a6 = plt.subplot(336)\n",
    "    a6.scatter([math.log(-1*x,10) for x in neglst['Elev'] if x != 0],[x for i,x in enumerate(distlst['Elev']) if neglst['Elev'][i] != 0])\n",
    "    a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a6.spines['right'].set_visible(False)\n",
    "    a6.spines['top'].set_visible(False)\n",
    "    a6.yaxis.set_ticks_position('left')\n",
    "    a6.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a7 = plt.subplot(337)\n",
    "    a7.scatter([math.log(-1*x,10) for x in neglst['GDD-Aug'] if x != 0],[x for i,x in enumerate(distlst['GDD-Aug']) if neglst['GDD-Aug'][i] != 0])\n",
    "    a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a7.spines['right'].set_visible(False)\n",
    "    a7.spines['top'].set_visible(False)\n",
    "    a7.yaxis.set_ticks_position('left')\n",
    "    a7.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a8 = plt.subplot(338)\n",
    "    a8.scatter([math.log(-1*x,10) for x in neglst['GDD-May'] if x != 0],[x for i,x in enumerate(distlst['GDD-May']) if neglst['GDD-May'][i] != 0])\n",
    "    a8.set_title('H',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a8.spines['right'].set_visible(False)\n",
    "    a8.spines['top'].set_visible(False)\n",
    "    a8.yaxis.set_ticks_position('left')\n",
    "    a8.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a9 = plt.subplot(339)\n",
    "    a9.scatter([math.log(-1*x,10) for x in neglst['Lat'] if x != 0],[x for i,x in enumerate(distlst['Lat']) if neglst['Lat'][i] != 0])\n",
    "    a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a9.spines['right'].set_visible(False)\n",
    "    a9.spines['top'].set_visible(False)\n",
    "    a9.yaxis.set_ticks_position('left')\n",
    "    a9.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    fig.set_size_inches(13,10)\n",
    "    pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PdfPages('/home/lindb/wbp/figures/log_pos_dij_v_envdist_sameenv_nozeros_AWSO-Lat.pdf') as pdf:\n",
    "    plt.close('all')\n",
    "    fig, ((a1,a2,a3),(a4,a5,a6),(a7,a8,a9)) = plt.subplots(3, 3, figsize=(5,5),dpi=400)\n",
    "\n",
    "    a1 = plt.subplot(331)\n",
    "    a1.scatter([math.log(x,10) for x in poslst['AWS0-25'] if x != 0],[x for i,x in enumerate(distlst['AWS0-25']) if poslst['AWS0-25'][i] != 0])\n",
    "    a1.set_title('A',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a1.spines['right'].set_visible(False)\n",
    "    a1.spines['top'].set_visible(False)\n",
    "    a1.yaxis.set_ticks_position('left')\n",
    "    a1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a2 = plt.subplot(332)\n",
    "    a2.scatter([math.log(x,10) for x in poslst['AWS0-50'] if x != 0],[x for i,x in enumerate(distlst['AWS0-50']) if poslst['AWS0-50'][i] != 0])\n",
    "    a2.set_title('B',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a2.spines['right'].set_visible(False)\n",
    "    a2.spines['top'].set_visible(False)\n",
    "    a2.yaxis.set_ticks_position('left')\n",
    "    a2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a3 = plt.subplot(333)\n",
    "    a3.scatter([math.log(x,10) for x in poslst['Ann-ppt'] if x != 0],[x for i,x in enumerate(distlst['Ann-ppt']) if poslst['Ann-ppt'][i] != 0])\n",
    "    a3.set_title('C',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a3.spines['right'].set_visible(False)\n",
    "    a3.spines['top'].set_visible(False)\n",
    "    a3.yaxis.set_ticks_position('left')\n",
    "    a3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a4 = plt.subplot(334)\n",
    "    a4.scatter([math.log(x,10) for x in poslst['CEC'] if x != 0],[x for i,x in enumerate(distlst['CEC']) if poslst['CEC'][i] != 0])\n",
    "    a4.set_title('D*',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a4.spines['right'].set_visible(False)\n",
    "    a4.spines['top'].set_visible(False)\n",
    "    a4.yaxis.set_ticks_position('left')\n",
    "    a4.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a5 = plt.subplot(335)\n",
    "    a5.scatter([math.log(x,10) for x in poslst['Clay'] if x != 0],[x for i,x in enumerate(distlst['Clay']) if poslst['Clay'][i] != 0])\n",
    "    a5.set_title('E',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a5.spines['right'].set_visible(False)\n",
    "    a5.spines['top'].set_visible(False)\n",
    "    a5.yaxis.set_ticks_position('left')\n",
    "    a5.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a6 = plt.subplot(336)\n",
    "    a6.scatter([math.log(x,10) for x in poslst['Elev'] if x != 0],[x for i,x in enumerate(distlst['Elev']) if poslst['Elev'][i] != 0])\n",
    "    a6.set_title('F',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a6.spines['right'].set_visible(False)\n",
    "    a6.spines['top'].set_visible(False)\n",
    "    a6.yaxis.set_ticks_position('left')\n",
    "    a6.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a7 = plt.subplot(337)\n",
    "    a7.scatter([math.log(x,10) for x in poslst['GDD-Aug'] if x != 0],[x for i,x in enumerate(distlst['GDD-Aug']) if poslst['GDD-Aug'][i] != 0])\n",
    "    a7.set_title('G',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a7.spines['right'].set_visible(False)\n",
    "    a7.spines['top'].set_visible(False)\n",
    "    a7.yaxis.set_ticks_position('left')\n",
    "    a7.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a8 = plt.subplot(338)\n",
    "    a8.scatter([math.log(x,10) for x in poslst['GDD-May'] if x != 0],[x for i,x in enumerate(distlst['GDD-May']) if poslst['GDD-May'][i] != 0])\n",
    "    a8.set_title('H',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a8.spines['right'].set_visible(False)\n",
    "    a8.spines['top'].set_visible(False)\n",
    "    a8.yaxis.set_ticks_position('left')\n",
    "    a8.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    a9 = plt.subplot(339)\n",
    "    a9.scatter([math.log(x,10) for x in poslst['Lat'] if x != 0],[x for i,x in enumerate(distlst['Lat']) if poslst['Lat'][i] != 0])\n",
    "    a9.set_title('I',y=.9,loc='right',fontsize=20,fontweight='bold')\n",
    "    a9.spines['right'].set_visible(False)\n",
    "    a9.spines['top'].set_visible(False)\n",
    "    a9.yaxis.set_ticks_position('left')\n",
    "    a9.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    fig.set_size_inches(13,10)\n",
    "    pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for env in poslst.keys():\n",
    "    spear = spearmanr([math.log(x,10) for x in poslst[env] if x != 0],[x for i,x in enumerate(distlst[env]) if poslst[env][i] != 0])\n",
    "    if spear[1] <= 0.05:\n",
    "        print env,spear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# effect size distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file made in 07_hierfstat.ipynb\n",
    "filE = '/home/lindb/wbp/hierfstat/imputed/imputed_hierarchical_Fstats.txt'\n",
    "df = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get bayenv2 snps\n",
    "DIR = '/home/lindb/wbp/bayenv2/results/sigsnps'\n",
    "bayfs = [op.join(DIR,f) for f in ls(DIR)]\n",
    "baydict = {}\n",
    "for f in bayfs:\n",
    "    env = op.basename(f).split(\"_\")[0]\n",
    "    df = pd.read_csv(f,header=0,sep='\\t')\n",
    "    baydict[env] = df[env].tolist()\n",
    "    print env,len(baydict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for env in baydict:\n",
    "    with PdfPages('/home/lindb/wbp/figures/multilocus_fst_distribution_bayenv_%s_overlay.pdf' % env) as pdf:\n",
    "        plt.close('all')\n",
    "        fig  = plt.figure(figsize=(5,5),dpi=400)\n",
    "        a1 = plt.subplot(111)\n",
    "        a1.hist(df['plot_total'],bins = [x for x in np.linspace(-0.1,0.2,30)])\n",
    "        a1.spines['right'].set_visible(False)\n",
    "        a1.spines['top'].set_visible(False)\n",
    "        a1.yaxis.set_ticks_position('left')\n",
    "        a1.xaxis.set_ticks_position('bottom')\n",
    "        a1.set_xlabel(r'multilocus $F_{ST}$',fontsize=14)\n",
    "        a1.set_ylabel('Count',fontsize=14)\n",
    "\n",
    "        #[a1.axvline(x=dd[snp],c='red',linewidth=0.25,zorder=1) for snp in dd.keys()]\n",
    "        #a1.axvline(x=dd[dd.keys()[0]],c='red',linewidth=0.25,zorder=1)\n",
    "\n",
    "        fig.set_size_inches(4,4)\n",
    "        pdf.savefig(fig,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,envi in enumerate(envdf.index):\n",
    "    for j,envj in enumerate(envdf.index):\n",
    "        if i > j:\n",
    "            corr,p = spearmanr(envdf.loc[envi,:],envdf.loc[envj,:])\n",
    "            if p <= 0.05:\n",
    "                print envi,envj,corr,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,envi in enumerate(envdf.index):\n",
    "    for j,envj in enumerate(envdf.index):\n",
    "        if i > j:\n",
    "            corr,p = pearsonr(envdf.loc[envi,:],envdf.loc[envj,:])\n",
    "            if p <= 0.05:\n",
    "                print envi,envj,corr,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spearmanr(envdf.loc['Ann-ppt',:],envdf.loc['Elev',:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# see if correlations are driven by larger exp het"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file made in 09_OutFLANK.ipynb\n",
    "globmafs = pd.read_csv('/home/lindb/wbp/OutFLANK/global_mafs.txt',header=0,sep='\\t')\n",
    "globmafs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popmafs = pd.read_csv('/home/lindb/wbp/OutFLANK/imputed_MAF.txt',header=0,index_col=0,sep='\\t')\n",
    "popmafs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popmafs.loc['NODE_1000013_length_91_cov_1.802198_37',:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envdf = pd.read_csv('/home/lindb/wbp/bayenv2/ENVIRONFILE_headerIDX.txt',header=0,index_col=0,sep='\\t')\n",
    "envdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get env correlations for each snp\n",
    "#rows = snps, cols = envs\n",
    "snpDict = OrderedDict()\n",
    "snpcount = 0\n",
    "for snp in popmafs.index:\n",
    "    snpDict[snp] = OrderedDict()\n",
    "    freqs = popmafs.loc[snp,:].tolist()\n",
    "    for env in envdf.index:\n",
    "        envval = envdf.loc[env,:].tolist()\n",
    "        s = spearmanr(freqs,envval)\n",
    "        snpDict[snp][env] = s[0]\n",
    "    snpcount += 1\n",
    "    if snpcount % 1000 == 0:\n",
    "        print snpcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write out the file\n",
    "key0 = snpDict.keys()[0]\n",
    "filE = '/home/lindb/wbp/bayenv2/uncorrected_correlations.txt'\n",
    "with open(filE,'w') as o:\n",
    "    text = '\\t'.join(snpDict[key0].keys())+'\\n'\n",
    "    o.write(\"%s\" % text)\n",
    "    for snp in snpDict:\n",
    "        text = snp+'\\t'+'\\t'.join([str(x) for x in snpDict[snp].values()])+'\\n'\n",
    "        o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get number of bayenv sig SNPs\n",
    "DIR = '/home/lindb/wbp/bayenv2/results/sigsnps'\n",
    "bayDict = {}\n",
    "for f in [op.join(DIR,f) for f in ls(DIR)]:\n",
    "    env = op.basename(f).split(\"_\")[0]\n",
    "    df = pd.read_csv(f,header=0,sep='\\t')\n",
    "    bayDict[env] = len(df.index)\n",
    "    print env,len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get absolute rhos\n",
    "abscorr = pd.DataFrame(abs(corr))\n",
    "abscorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abscorr.sort_values(by='AWS0-25',inplace=True,ascending=0)\n",
    "abscorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abscorr.loc[abscorr.index[0:100],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqs = popmafs.loc['NODE_768610_length_47_cov_4.042553_36',:].tolist()\n",
    "envval = envdf.loc['AWS0-25',:].tolist()\n",
    "plt.scatter(freqs,envval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrdict = {}\n",
    "for env in abscorr:\n",
    "    abscorr.sort_values(by=env,inplace=True,ascending=0)\n",
    "    corrdict[env] = list(abscorr.index[0:bayDict[env]])\n",
    "    print len(corrdict[env]),bayDict[env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get expected heterozygosities\n",
    "filE = '/home/lindb/wbp/OutFLANK/Hexp_by_snp_withbins.txt'\n",
    "H = pd.read_csv(filE,header=0,index_col=0,sep='\\t')\n",
    "H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(H['bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Habscorr = pd.merge(pd.DataFrame(H['bin']),abscorr,left_index=True,right_index=True)\n",
    "Habscorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abscorr.sort_values(by='AWS0-25',ascending=1,inplace=True)\n",
    "abscorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make scatters \n",
    "for env in abscorr:\n",
    "    print env\n",
    "    abscorr.sort_values(by=env,ascending=0,inplace=True)\n",
    "    f00 = pd.DataFrame(abscorr[env][abscorr.index[0:500]])\n",
    "    H00 = pd.DataFrame(Habscorr['bin'][H.index.isin(f00.index)])\n",
    "    plt.scatter(f00[env].tolist(),H00['bin'].tolist())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make histograms of Hexp for SNPs correlated to env without correction for structure\n",
    "for env in corrdict:\n",
    "    df = pd.DataFrame(H[H.index.isin(corrdict[env])])\n",
    "    print env\n",
    "    plt.hist(df['bin'],bins=np.arange(0,51,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make box plots\n",
    "ulims = [10,20,30,40,50]\n",
    "llims = [0,10,20,30,40]\n",
    "for env in corrdict:\n",
    "    df = pd.DataFrame(H[H.index.isin(corrdict[env])]) #get bins\n",
    "    df1 = pd.DataFrame(abscorr[env]) #get rhos\n",
    "    df = pd.merge(df1,df,left_index=True,right_index=True)\n",
    "    boxes=[]\n",
    "    count = 0\n",
    "    for lim in ulims:\n",
    "        df2 = pd.DataFrame(df[df['bin']<ulims[count]])\n",
    "        df3 = pd.DataFrame(df2[df2['bin']>=llims[count]])\n",
    "        boxes.append(df3[env].tolist())\n",
    "        count += 1\n",
    "    print env,len(corrdict[env])\n",
    "    plt.boxplot(boxes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bf.environfile - get the sig SNPs - this was done with the first chain only (ignore this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a DF that contains the names for environmental variables\n",
    "envdf = pd.read_csv('/home/lindb/wbp/bayenv2/ENVIRONFILE_headerIDX.txt',header=0,index_col=0,sep='\\t')\n",
    "envdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(envdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign column value of the bf.environfile.ENVIRONFILE for each environmental variable\n",
    "envDict = OrderedDict()\n",
    "for i, env in enumerate(envdf.index):\n",
    "    #print i,env\n",
    "    envDict[env] = [(i*3),(i*3)+1,(i*3)+2]\n",
    "envDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a dictionary to name columns in bf_environfile.ENVIRONFILE\n",
    "orderDict = {}\n",
    "orderDict[0] = 'BF'\n",
    "orderDict[1] = 'rho'\n",
    "orderDict[2] = 'pearson'\n",
    "colDict = OrderedDict()\n",
    "for env,cols in envDict.items():\n",
    "    #print env,cols\n",
    "    colCount = 0\n",
    "    for col in cols:\n",
    "        sub = '_'.join([str(env), orderDict[colCount]]) \n",
    "        colDict[col] = sub\n",
    "        colCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform the bf_environfile to have indices and column names\n",
    "df = pd.read_csv('/home/lindb/wbp/bayenv2/bf_environfile.ENVIRONFILE.txt.bf',header=None,sep='\\t')s\n",
    "loci = []\n",
    "for row in df.index:\n",
    "    locus = df.loc[row,0].split(\"/\")[-1]\n",
    "    loci.append(locus)\n",
    "bayenv2 = df.loc[:,[x for x in df.columns[1:-1]]] #get rid of locus column and the 'blank' column at the end\n",
    "bayenv2.columns = [col for col in range(len(bayenv2.columns))] #rename columns from 0 to len(columns)\n",
    "bayenv2.columns = [colDict[col] for col in bayenv2.columns] #convert to BF, rho, pearson\n",
    "bayenv2.index = [locus for locus in loci]\n",
    "bayenv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(bayenv2.loc['NODE_335159_length_90_cov_1.000000_19',:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.unique(bayenv2.index).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a rho df\n",
    "rhos = [col for col in bayenv2.columns if 'rho' in col]\n",
    "rhodf = bayenv2.loc[:,[col for col in rhos]]\n",
    "filE = '/home/lindb/wbp/bayenv2/results/rho_all.txt'\n",
    "rhodf.to_csv(filE,header=True,index=True,sep='\\t')\n",
    "rhodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get absolute values of rhos to rank them\n",
    "max(abs(rhodf['AWS0-25_rho']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(rhodf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a dictionary with the 0.01% (1162) largest rhos for each env\n",
    "rho2 = pd.DataFrame(abs(rhodf))\n",
    "rhoDict = OrderedDict() #k = env, val = list(top_loci)\n",
    "for env in rho2.columns:\n",
    "    sorts = pd.DataFrame(rho2.sort_values(by=env,ascending=0))\n",
    "    rhoDict[env] = sorts.index[:1162] #top loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a BF df\n",
    "bfs = [col for col in bayenv2.columns if '_BF' in col]\n",
    "bfdf = bayenv2.loc[:,[col for col in bfs]]\n",
    "filE = '/home/lindb/wbp/bayenv2/results/BF_all.txt'\n",
    "bfdf.to_csv(filE,header=True,index=True,sep='\\t')\n",
    "bfdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bfdf = pd.read_csv('/home/lindb/wbp/bayenv2/results/BF_all.txt',header=0,index_col=0,sep='\\t')\n",
    "bfdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a dictionary with the 0.01% (1162) largest BFs for each env\n",
    "bf2 = pd.DataFrame(abs(bfdf))\n",
    "bfDict = OrderedDict()\n",
    "for env in bf2.columns:\n",
    "    sorts = pd.DataFrame(bf2.sort_values(by=env,ascending=0))\n",
    "    bfDict[env] = sorts.index[:1162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the intersection of loci between top rhos and top BFs\n",
    "intDict = OrderedDict()\n",
    "for env in envDict.keys():\n",
    "    bfkey = env+'_BF'\n",
    "    rhokey = env+'_rho'\n",
    "    intDict[env] = list(set(bfDict[bfkey]).intersection(set(rhoDict[rhokey])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see how many 'significant' SNPs for each env variable\n",
    "for env in intDict.keys():\n",
    "    print env,len(intDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min([len(intDict[env]) for env in intDict.keys()]),max([len(intDict[env]) for env in intDict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out files\n",
    "for env in intDict.keys():\n",
    "    filE = '/home/lindb/wbp/bayenv2/results/rhoBF_intersection_%s.txt' % env\n",
    "    df = pd.DataFrame(intDict[env])\n",
    "    df.columns = [env]\n",
    "    df.to_csv(filE,header=True,index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get BFs >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bfdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the loci to run bayenv2 null runs\n",
    "nullloci = [] #keep track of the loci\n",
    "best = []\n",
    "worst = []\n",
    "for envbf in bfdf.columns:\n",
    "    #get all BFs greater than or equal to 3\n",
    "    env = envbf.split(\"_\")[0]\n",
    "    data = pd.DataFrame(bfdf[envbf])\n",
    "    new = pd.DataFrame(data[data[envbf] >= 3] )\n",
    "    [best.append(locus) for locus in new.index if locus not in best]\n",
    "    \n",
    "    #get 10 of the worst BFs\n",
    "    bad    = pd.DataFrame(data[data[envbf]<=3])\n",
    "    badder = pd.DataFrame(bad.sort_values(by=envbf,ascending=1))\n",
    "    badder = badder[badder.index.isin(badder.index[:10])]\n",
    "    [worst.append(locus) for locus in badder.index if locus not in worst]\n",
    "    \n",
    "    #concat the two dataframes\n",
    "    catd = pd.concat([badder,new])\n",
    "    catd.sort_values(by=envbf,ascending=1,inplace=True)\n",
    "    \n",
    "    #add loci to nullloci list\n",
    "    [nullloci.append(locus) for locus in catd.index if locus not in nullloci]\n",
    "    \n",
    "    filE = '/home/lindb/wbp/bayenv2/results/%s_bfgreaterthan3and10worst.txt' % env\n",
    "    catd.to_csv(filE,header=True,index=True,sep='\\t')\n",
    "    \n",
    "    \n",
    "    print env,len(catd.index),len(new.index),len(badder.index),len(bad.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.sort_values(by='WC3rdbar_BF',ascending=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(new.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(best),len(worst),len(nullloci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulls = pd.DataFrame(nullloci)\n",
    "nulls.columns = ['topandlowestBFs']\n",
    "filE = '/home/lindb/wbp/bayenv2/results/uniq_loci_bfgreaterthan3and10worst.txt'\n",
    "nulls.to_csv(filE,header=True,index=False,sep='\\t')\n",
    "nulls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = pd.DataFrame(best)\n",
    "best.columns = ['BF>=3']\n",
    "filE = '/home/lindb/wbp/bayenv2/results/best_loci_bfgreaterthan3without10worst.txt'\n",
    "best.to_csv(filE,header=True,index=False,sep='\\t')\n",
    "best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst = pd.DataFrame(worst)\n",
    "worst.columns = ['worstBF']\n",
    "filE = '/home/lindb/wbp/bayenv2/results/worst_loci_bfgreaterthan3without10worst.txt'\n",
    "worst.to_csv(filE,header=True,index=False,sep='\\t')\n",
    "worst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
