{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys,time\n",
    "import vcf\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "from collections import OrderedDict, Counter\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcftools = \"/home/lindb/g/src/vcftools_0.1.13/bin/vcftools\"\n",
    "bcftools = \"/home/lindb/g/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/lindb/g/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/lindb/g/src/htslib-1.3/bgzip\"\n",
    "plink = \"/home/lindb/g/src/plink-1.07-x86_64/plink --noweb\"\n",
    "java  = \"/home/lindb/g/src/jre1.8.0_73/bin/java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snp_dir = '/home/lindb/wbp/concatenated/snps/'\n",
    "vcf_file = os.path.join(snp_dir,'samtools_1.3.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(vcf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcftools --remove-indels \\\n",
    "--max-missing 0.5 \\\n",
    "--min-alleles 2 \\\n",
    "--max-alleles 2 \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--gzvcf \\\n",
    "$vcf_file \\\n",
    "--out $vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcf_filtered = \"%s.recode.vcf\" % vcf_file\n",
    "vcf_filtered_gz = \"%s.gz\" % vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$bgzip -c $vcf_filtered > {vcf_filtered_gz}\n",
    "!$tabix {vcf_filtered_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vcf_stats(vcf_gz):\n",
    "    \n",
    "    stats = ['depth',\n",
    "            'site-depth',\n",
    "            'site-mean-depth',\n",
    "            'site-quality',\n",
    "            'missing-indv',\n",
    "            'missing-site',\n",
    "            'freq',\n",
    "            'counts',\n",
    "            'hardy',\n",
    "            'het']\n",
    "    \n",
    "    for stat in stats:\n",
    "        !$vcftools --gzvcf $vcf_gz \\\n",
    "        --out $vcf_gz \\\n",
    "        {\"--%s\" % stat} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_vcf_stats(vcf_filtered_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(snp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[os.path.join(snp_dir,f) for f in files if '.l' in f and 'log' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "def get_MAF(row):\n",
    "    try:\n",
    "        return np.min([row.A1_freq, row.A2_freq])\n",
    "    except:\n",
    "        print(row)\n",
    "        \n",
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def calculate_Fis(vals):\n",
    "    try:\n",
    "        data = [float(x) for x in vals.split(\"/\")]\n",
    "        assert len(data) == 3\n",
    "        num_individuals = np.sum(data)\n",
    "        total_alleles = 2*num_individuals\n",
    "        a1_count = 2*data[0]\n",
    "        a2_count = 2*data[2]\n",
    "        het_count = data[1]\n",
    "        a1_count += het_count\n",
    "        a2_count += het_count\n",
    "        a1_freq = a1_count/total_alleles\n",
    "        a2_freq = a2_count/total_alleles\n",
    "        assert a1_freq + a2_freq == 1.0\n",
    "        He = 2 * a1_freq * a2_freq * get_correction(num_individuals)\n",
    "        Ho = het_count/num_individuals\n",
    "        Fis = 1 - (Ho/He)\n",
    "        return Fis\n",
    "    except:\n",
    "        return -9\n",
    "\n",
    "def combine_vcf_stats(filedir, prefix):\n",
    "    #hardy_files = !ls {filedir}/{prefix}*.hwe\n",
    "    print \"hardy files\"\n",
    "    files = os.listdir(filedir)\n",
    "    hardy_files = [os.path.join(filedir,f) for f in files if f.endswith('hwe')]\n",
    "    hardy = pd.read_csv(hardy_files[0], sep=\"\\t\")\n",
    "\n",
    "    hardy.columns = ['CHROM', 'POS', 'OBS(HOM1/HET/HOM2)', 'E(HOM1/HET/HOM2)', 'ChiSq_HWE',\n",
    "       'P_HWE', 'P_HET_DEFICIT', 'P_HET_EXCESS']\n",
    "    hardy.index = hardy.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    print \"loci files\"\n",
    "    #loci_files = !ls {filedir}/{prefix}*.l* | grep -v log\n",
    "    loci_files = [os.path.join(filedir,f) for f in files if '.l' in f and 'log' not in f]\n",
    "    loci_df = pd.concat([pd.read_csv(x, sep=\"\\t\", skiprows=0) for x in loci_files], axis=1)\n",
    "    chrom_pos = loci_df.ix[:,0:2]\n",
    "    \n",
    "    print \"frq files\"\n",
    "    #frq_files = !ls {filedir}/{prefix}*.frq* | grep -v count\n",
    "    frq_files = [os.path.join(filedir,f) for f in files if f.endswith('frq')]\n",
    "    frq_data = []\n",
    "    h = open(frq_files[0])\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        frq_data.append(line.strip().split('\\t'))\n",
    "\n",
    "    header = ['CHROM', 'POS', 'N_ALLELES', 'N_CHR', 'A1_FREQ', \"A2_FREQ\"]\n",
    "    frq_df = pd.DataFrame(frq_data)\n",
    "    print(frq_df.columns)\n",
    "    #frq_df = frq_df.drop([6,7],axis=1)\n",
    "    frq_df.columns = header\n",
    "    frq_df.index = frq_df.apply(lambda x: \"%s-%s\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    print \"loci df\"\n",
    "    loci_df = loci_df.drop(['CHROM','CHR','POS'], axis=1)\n",
    "    loci_df = pd.concat([chrom_pos, loci_df], axis=1)\n",
    "    loci_df.index = loci_df.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    print \"identifying alleles\"\n",
    "    loci_df = pd.concat([loci_df, frq_df, hardy], axis=1)\n",
    "    loci_df[\"A1_allele\"] = loci_df.apply(lambda row: row.A1_FREQ.split(\":\")[0], axis=1)\n",
    "    loci_df[\"A2_allele\"] = loci_df.apply(lambda row: row.A2_FREQ.split(\":\")[0], axis=1)\n",
    "    \n",
    "    print \"calculating allele freqs\"\n",
    "    loci_df[\"A1_freq\"] = loci_df.apply(lambda row: float(row.A1_FREQ.split(\":\")[1]), axis=1)\n",
    "    loci_df[\"A2_freq\"] = loci_df.apply(lambda row: float(row.A2_FREQ.split(\":\")[1]), axis=1)\n",
    "    \n",
    "    print \"getting MAF\"\n",
    "    loci_df['MAF'] = loci_df.apply(get_MAF, axis=1)\n",
    "    loci_df = loci_df.drop(['CHROM', 'POS'], axis=1)\n",
    "    \n",
    "    print \"calculating FIS\"\n",
    "    loci_df['Fis'] = loci_df['OBS(HOM1/HET/HOM2)'].apply(calculate_Fis)\n",
    "    \n",
    "    print 'done'\n",
    "    return loci_df, frq_df, hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df, frq_df, hardy = combine_vcf_stats(snp_dir, \"samtools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_file = '/home/lindb/wbp/concatenated/snps/loci_vcf_stats.txt'\n",
    "loci_df.to_csv(loci_file,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frq_file = '/home/lindb/wbp/concatenated/snps/frq_vcf_stats.txt'\n",
    "frq_df.to_csv(frq_file,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hardy_file = '/home/lindb/wbp/concatenated/snps/hwe_vcf_stats.txt'\n",
    "hardy.to_csv(hardy_file,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute with Beagle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    cd /home/lindb/wbp/concatenated/snps/beagle40\n",
    "    ln -s ../samtools_1.3.vcf.gz.recode.vcf.gz\n",
    "    /home/lindb/g/src/jdk1.8.0_73/bin/java -jar ~/g/src/BEAGLE4/beagle.r1399.jar \\\n",
    "    gl=samtools_1.3.vcf.gz.recode.vcf.gz \\\n",
    "    out=beagle40 \\\n",
    "    nthreads=32 \\\n",
    "    phase-its=20 \\\n",
    "    burnin-its=20 \\\n",
    "    impute-its=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_dir = os.path.join(snp_dir, \"beagle40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_vcf_gz = os.path.join(beagle_dir, \"beagle40.vcf.gz\")\n",
    "assert os.path.exists(beagle_vcf_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_vcf_stats(beagle_vcf_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loci_df_beagle, freq_df_beagle, hardy_beagle = combine_vcf_stats(beagle_dir, \"beagle40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df_beagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_df_beagle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hardy_beagle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_beagle_file = os.path.join(beagle_dir,'loci_beagle_vcf_stats.txt')\n",
    "loci_df_beagle.to_csv(loci_beagle_file,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_beagle = os.path.join(beagle_dir,'frq_beagle_vcf_stats.txt')\n",
    "freq_df_beagle.to_csv(freq_beagle,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hardy_beagle_file = os.path.join(beagle_dir,'hwe_beagle_vcf_stats.txt')\n",
    "hardy_beagle.to_csv(hardy_beagle_file,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chroms = sorted(set([x.split(\"-\")[0] for x in loci_df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(snp_dir, \"chrom_map.txt\"), \"w\") as o:\n",
    "    for i, c in enumerate(chroms):\n",
    "        o.write(\"%s\\t%d\\n\" % (c, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_plink_files(vcf_gz):\n",
    "    !$vcftools --gzvcf {vcf_gz} \\\n",
    "    --out {vcf_gz} \\\n",
    "    --plink \\\n",
    "    --chrom-map {os.path.join(snp_dir, \"chrom_map.txt\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_filtered_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_plink_files(vcf_filtered_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_plink_recode(vcf_gz):\n",
    "    !$plink --recodeA --tab --file {vcf_gz} --out {vcf_gz}_recodeA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_plink_recode(vcf_filtered_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df.SUM_DEPTH.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_df.QUAL.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.Fis == -9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.QUAL >= 10]) - len(loci_df[loci_df.QUAL >= 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.QUAL < 20]), len(loci_df[loci_df.QUAL < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.Fis >= 0.5]), len(loci_df[loci_df.Fis <= -0.5]), len(loci_df[loci_df.MAF < 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_snps(df, imputed=False):\n",
    "    if imputed:\n",
    "        return df[(df.MAF >= 0.01) & \n",
    "                  (df.Fis < 0.5) & \n",
    "                  (df.Fis > -0.5)]\n",
    "    else:\n",
    "        return df[(df.SUM_DEPTH >= 100) & \n",
    "                  (df.SUM_DEPTH < 1500) & \n",
    "                  (df.QUAL >= 20) & \n",
    "                  (df.MAF >= 0.01) & \n",
    "                  (df.Fis < 0.5) & \n",
    "                  (df.Fis > -0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_stage1 = filter_snps(loci_df)\n",
    "loci_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_stage1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_stage1 = filter_snps(loci_df_beagle, imputed=True)\n",
    "beagle_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(snp_dir, \"stage1_positions.txt\"), \"w\") as o:\n",
    "    for elem in loci_stage1.index:\n",
    "        o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))\n",
    "        \n",
    "with open(os.path.join(beagle_dir, \"stage1_positions.txt\"), \"w\") as o:\n",
    "    for elem in beagle_stage1.index:\n",
    "        o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d, vcf_gz in zip([snp_dir, beagle_dir], [vcf_filtered_gz, beagle_vcf_gz]):\n",
    "    !$vcftools --gzvcf $vcf_gz \\\n",
    "    --remove-indels  \\\n",
    "    --remove-filtered-all \\\n",
    "    --recode \\\n",
    "    --recode-INFO-all \\\n",
    "    --positions {os.path.join(d, \"stage1_positions.txt\")} \\\n",
    "    --out {os.path.join(d, \"good_snps\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [snp_dir, beagle_dir]:\n",
    "    snps = os.path.join(d, \"good_snps.recode.vcf\")\n",
    "    snps_gz = snps + \".gz\"\n",
    "    !$bgzip -c {snps} > {snps_gz}\n",
    "    !$tabix {snps_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersection(imp, ni):\n",
    "    return set.intersection(set(ni.index), set(imp.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isect = get_intersection(beagle_stage1, loci_stage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isect = sorted(isect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_stage1.index), len(beagle_stage1.index), len(isect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in [snp_dir, beagle_dir]:\n",
    "    with open(os.path.join(d, \"isect_positions.txt\"), \"w\") as o:\n",
    "        for elem in isect:\n",
    "            o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d, vcf_gz in zip([snp_dir, beagle_dir], [vcf_filtered_gz, beagle_vcf_gz]):\n",
    "    !$vcftools --gzvcf $vcf_gz \\\n",
    "    --remove-indels  \\\n",
    "    --remove-filtered-all \\\n",
    "    --recode \\\n",
    "    --recode-INFO-all \\\n",
    "    --positions {os.path.join(d, \"isect_positions.txt\")} \\\n",
    "    --out {os.path.join(d, \"isect_snps\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcfsort = '/home/lindb/g/src/vcftools_0.1.13/perl/vcf-sort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [snp_dir, beagle_dir]:\n",
    "    snps = os.path.join(d, \"isect_snps.recode.vcf\")\n",
    "    snps_gz = snps + \".gz\"\n",
    "    !$bgzip -c {snps} > {snps_gz}\n",
    "    !$tabix {snps_gz}\n",
    "    \n",
    "    srted = snps_gz + \"_sorted.vcf\"\n",
    "    srted_gz = srted + \".gz\"\n",
    "    !$vcfsort {snps_gz} > {srted}\n",
    "    !$bgzip -c {srted} > {srted_gz}\n",
    "    !$tabix {srted_gz}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose one snp per contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_dir,beagle_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#because I want to go to bed and this will take a while with 713K recs in vcf:\n",
    "pytext = '''from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys,time\n",
    "import vcf\n",
    "from collections import OrderedDict, Counter\n",
    "import random\n",
    "\n",
    "VCFmissing = '/home/lindb/wbp/concatenated/snps/isect_snps.recode.vcf'\n",
    "missing_reader = vcf.Reader(open(VCFmissing),'r')\n",
    "\n",
    "filE1 = '/home/lindb/wbp/concatenated/snps/update.txt'\n",
    "if os.path.exists(filE1):\n",
    "    os.remove(filE1)\n",
    "with open(filE1,'w') as o:\n",
    "    text = 'starting recs \\\\n'\n",
    "    o.write(\"%s\" % text)\n",
    "\n",
    "\n",
    "locDict = OrderedDict()\n",
    "loccount = 0\n",
    "for rec in missing_reader:\n",
    "    contig = rec.CHROM\n",
    "    locus = rec.POS\n",
    "    if contig not in locDict.keys():\n",
    "        locDict[contig] = Counter()\n",
    "\n",
    "    womp = 0\n",
    "    for samp in rec.samples:\n",
    "        gt = samp['GT']\n",
    "\n",
    "        if '.' in gt:\n",
    "            try:\n",
    "                assert gt == './.'\n",
    "                womp += 1 #womp womp\n",
    "            except Exception as E:\n",
    "                print gt,E\n",
    "        else: #add count for a sample without missing data\n",
    "            locDict[contig][str(locus)] += 1\n",
    "\n",
    "    assert womp + locDict[contig][str(locus)] == len(rec.samples)\n",
    "    loccount += 1\n",
    "    if loccount % 1000 == 0:\n",
    "        with open(filE1,'a') as o:\n",
    "            o.write(\"%s\\\\n\" % str(loccount))\n",
    "    #break\n",
    "\n",
    "with open(filE1,'a') as o:\n",
    "    o.write(\"choosing snps \\\\n\")\n",
    "\n",
    "keep = OrderedDict()\n",
    "contcount = 0\n",
    "for contig in locDict.keys():\n",
    "    #print contig\n",
    "    #print len(locDict[contig].keys())\n",
    "\n",
    "    #find SNP with least missing data\n",
    "    mx = 0\n",
    "    mxloc = ['Hello How Are You?']\n",
    "    for locus in locDict[contig].keys():\n",
    "        #print locus,locDict[contig][locus]\n",
    "\n",
    "        if locDict[contig][locus] > mx: #if > max count\n",
    "            mx = locDict[contig][locus]\n",
    "            mxloc = [str(locus)]\n",
    "            #print mxloc\n",
    "        elif locDict[contig][locus] == mx: #if = max count\n",
    "            mxloc.append(str(locus))\n",
    "            #print mxloc\n",
    "\n",
    "    assert mxloc != ['Hello How Are You?']\n",
    "    if len(mxloc) > 1:\n",
    "        x = random.random()\n",
    "\n",
    "        bins = []\n",
    "        for i in range(len(mxloc)):\n",
    "            if i == 0:\n",
    "                bins.append(0)\n",
    "            else:\n",
    "                bins.append(i/len(mxloc))\n",
    "        bins.append(1)\n",
    "\n",
    "        for b in range(len(bins)):\n",
    "            if (x > bins[b]) and (x <= bins[b+1]):\n",
    "                lowcuss = mxloc[b]\n",
    "                #print \"b=\",b\n",
    "                try:\n",
    "                    print snp\n",
    "                    sys.exit(\"snp already exists. WTF?\")\n",
    "                except:\n",
    "                    pass\n",
    "                snp = \"-\".join([contig,str(lowcuss)])\n",
    "                break #keep\n",
    "    else:\n",
    "        snp = \"-\".join([contig,str(mxloc[0])])\n",
    "    #print snp\n",
    "\n",
    "    assert contig not in keep.keys()\n",
    "    keep[contig] = snp\n",
    "    \n",
    "    #delete just in case\n",
    "    del snp, locus\n",
    "    try:\n",
    "        del lowcuss\n",
    "    except:\n",
    "        pass\n",
    "    contcount += 1\n",
    "    if contcount % 1000 == 0:\n",
    "        with open(filE1,'a') as o:\n",
    "            o.write(\"%s\" % str(contcount))\n",
    "\n",
    "with open(filE1,'a') as o:\n",
    "    o.write(\"writing file\\\\n\")\n",
    "\n",
    "filE = '/home/lindb/wbp/concatenated/snps/one_snp_per_contig.txt'\n",
    "if os.path.exists(filE):\n",
    "    os.remove(filE)\n",
    "with open(filE,'w') as o:\n",
    "    for k in keep.keys():\n",
    "        text = '\\\\t'.join(keep[k].split(\"-\")) + '\\\\n'\n",
    "        o.write(\"%s\\\\n\" % text)\n",
    "\n",
    "'''\n",
    "filE = '/home/lindb/wbp/concatenated/snps/get_one_snp_per_contig.py'\n",
    "with open(filE,'w') as o:\n",
    "    o.write(\"%s\" % pytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shtext = '''#!/bin/bash\n",
    "#$ -N contigs\n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd /home/lindb/wbp/concatenated/snps/\n",
    "python get_one_snp_per_contig.py\n",
    "\n",
    "'''\n",
    "filE = '/home/lindb/wbp/concatenated/snps/run_get_one_snp_per_contig.sh'\n",
    "with open(filE,'w') as o:\n",
    "    o.write(\"%s\" % shtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/wbp/concatenated/snps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!qsub $filE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.copy('/home/lindb/wbp/concatenated/snps/one_snp_per_contig.txt',\n",
    "            '/home/lindb/wbp/concatenated/snps/beagle40/one_snp_per_contig.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/lindb/wbp/concatenated/snps/one_snp_per_contig.txt',header=None,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.unique(df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[vcf_filtered_gz, beagle_vcf_gz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcf_filtered_gz_safe = '/home/lindb/wbp/concatenated/snps/onepcontig/samtools_1.3.vcf.gz.recode.vcf.gz'\n",
    "beagle_vcf_gz_safe = '/home/lindb/wbp/concatenated/snps/onepcontig/beagle40.vcf.gz'\n",
    "assert os.path.exists(vcf_filtered_gz_safe)\n",
    "assert os.path.exists(beagle_vcf_gz_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write files\n",
    "for d, vcf_gz in zip([snp_dir, beagle_dir], [vcf_filtered_gz_safe, beagle_vcf_gz_safe]):\n",
    "    !$vcftools --gzvcf $vcf_gz \\\n",
    "    --remove-indels  \\\n",
    "    --remove-filtered-all \\\n",
    "    --recode \\\n",
    "    --recode-INFO-all \\\n",
    "    --positions {os.path.join(d, \"one_snp_per_contig.txt\")} \\\n",
    "    --out {os.path.join(d, \"isect_one_per_contig\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zip files\n",
    "for d in [snp_dir, beagle_dir]:\n",
    "    snps = os.path.join(d, \"isect_one_per_contig.recode.vcf\")\n",
    "    snps_gz = snps + \".gz\"\n",
    "    !$bgzip -c {snps} > {snps_gz}\n",
    "    !$tabix {snps_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.exists(snps_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcfsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [snp_dir, beagle_dir]:\n",
    "    snps = os.path.join(d, \"isect_one_per_contig.recode.vcf\")\n",
    "    snps_gz = snps + \".gz\"\n",
    "    srted = snps_gz + \"_sorted.vcf\"\n",
    "    srted_gz = srted + \".gz\"\n",
    "\n",
    "    !$vcfsort {snps_gz} > {srted}\n",
    "    !$bgzip -c {srted} > {srted_gz}\n",
    "    !$tabix {srted_gz}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [snp_dir, beagle_dir]:\n",
    "    f = os.path.join(d, \"isect_one_per_contig.recode.vcf.gz_sorted.vcf.gz\")\n",
    "    assert os.path.exists(f)\n",
    "    write_plink_files(f)\n",
    "    write_plink_recode(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [snp_dir, beagle_dir]:\n",
    "    f = os.path.join(d, \"isect_one_per_contig.recode.vcf.gz_sorted.vcf.gz\")\n",
    "    assert os.path.exists(f)\n",
    "    !$vcftools --gzvcf {f} \\\n",
    "    --out {f} \\\n",
    "    --012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VCFmissing = os.path.join(snp_dir,'isect_snps.recode.vcf')\n",
    "missing_reader = vcf.Reader(open(VCFmissing),'r')\n",
    "\n",
    "locDict = OrderedDict()\n",
    "for rec in missing_reader:\n",
    "    print rec\n",
    "    contig = rec.CHROM\n",
    "    locus = rec.POS\n",
    "    if contig not in locDict.keys():\n",
    "        locDict[contig] = Counter()\n",
    "\n",
    "    womp = 0\n",
    "    for i,samp in enumerate(rec.samples): \n",
    "        gt = samp['GT']\n",
    "\n",
    "        if '.' in gt:\n",
    "            try:\n",
    "                assert gt == './.'\n",
    "                womp += 1 #womp womp\n",
    "            except Exception as E:\n",
    "                print gt,E\n",
    "        else: #add count for a sample without missing data\n",
    "            locDict[contig][str(locus)] += 1\n",
    "\n",
    "    assert womp + locDict[contig][str(locus)] == len(rec.samples)\n",
    "    break\n",
    "\n",
    "keep = OrderedDict()\n",
    "for contig in locDict.keys():\n",
    "    #print contig\n",
    "    #print len(locDict[contig].keys())\n",
    "\n",
    "    #find SNP with least missing data\n",
    "    mx = 0\n",
    "    mxloc = ['Hello How Are You?']\n",
    "    for locus in locDict[contig].keys():\n",
    "        #print locus,locDict[contig][locus]\n",
    "\n",
    "        if locDict[contig][locus] > mx: #if > max count\n",
    "            mx = locDict[contig][locus]\n",
    "            mxloc = [str(locus)]\n",
    "            #print mxloc\n",
    "        elif locDict[contig][locus] == mx: #if = max count\n",
    "            mxloc.append(str(locus))\n",
    "            #print mxloc\n",
    "\n",
    "    assert mxloc != ['Hello How Are You?']\n",
    "    if len(mxloc) > 1:\n",
    "        x = random.random()\n",
    "\n",
    "        bins = []\n",
    "        for i in range(len(mxloc)):\n",
    "            if i == 0:\n",
    "                bins.append(0)\n",
    "            else:\n",
    "                bins.append(i/len(mxloc))\n",
    "        bins.append(1)\n",
    "\n",
    "        for b in range(len(bins)):\n",
    "            if (x > bins[b]) and (x <= bins[b+1]):\n",
    "                lowcuss = mxloc[b]\n",
    "                #print \"b=\",b\n",
    "                try:\n",
    "                    print snp\n",
    "                    sys.exit(\"snp already exists. WTF?\")\n",
    "                except:\n",
    "                    pass\n",
    "                snp = \"-\".join([contig,str(lowcuss)])\n",
    "                break #keep\n",
    "    else:\n",
    "        snp = \"-\".join([contig,str(mxloc[0])])\n",
    "    #print snp\n",
    "\n",
    "    assert contig not in keep.keys()\n",
    "    keep[contig] = snp\n",
    "    \n",
    "    #delete just in case\n",
    "    del snp, locus\n",
    "    try:\n",
    "        del lowcuss\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "filE = '/home/lindb/wbp/concatenated/snps/one_snp_per_contig.txt'\n",
    "if os.path.exists(filE):\n",
    "    os.remove(filE)\n",
    "with open(filE,'w') as o:\n",
    "    for k in keep.keys():\n",
    "        text = '\\t'.join(keep[k].split(\"-\")) + '\\n'\n",
    "        o.write(\"%s\" % text)\n",
    "        \n",
    "df = pd.read_csv(filE,sep=\"\\t\",header=None)\n",
    "df    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
