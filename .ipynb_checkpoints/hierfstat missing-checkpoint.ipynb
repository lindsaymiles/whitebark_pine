{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict,Counter\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#assign samps to pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/sampsTOpop.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filE,sep=\"\\t\",header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stpDict = OrderedDict()\n",
    "for row in df.index:\n",
    "    samp = df.loc[row,'samp']\n",
    "    plot = df.loc[row,'plot']\n",
    "    pop = df.loc[row,'pop']\n",
    "    stpDict[samp] = OrderedDict()\n",
    "    stpDict[samp]['pop'] = pop\n",
    "    stpDict[samp]['plot'] = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stpDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir'\n",
    "VCFmissing = os.path.join(file_dir,'good_snps_good_samples_missing.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "miss_reader = vcf.Reader(open(VCFmissing),'r') #must reset after this is sourced\n",
    "for rec in miss_reader: \n",
    "    for sample in rec:\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a key so we can sample each rec in order of sampleID\n",
    "smpLST = [rec.samples[i].sample for i,x in enumerate(rec.samples)]\n",
    "sortSMPLST = sorted(smpLST)\n",
    "sampKey = []\n",
    "for i,smp in enumerate(sortSMPLST):\n",
    "    sampKey.append(smpLST.index(sortSMPLST[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smpLST[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampKey[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sampKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pops = ['Dicks_Pass',\n",
    " 'Freel_Peak',\n",
    " 'Heavenly',\n",
    " 'Little_Round_Top',\n",
    " 'Mt_Rose_Ophir',\n",
    " 'Rifle_Peak',\n",
    " 'Snow_Valley_Peak',\n",
    " 'West_Shore_Peaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampDict = OrderedDict()\n",
    "for pop in pops:\n",
    "    print pop\n",
    "    sampDict[pop] = []\n",
    "for i,smp in enumerate(smpLST):\n",
    "    if smp in stpDict.keys():\n",
    "        if len(stpDict[smp].keys()) > 0:\n",
    "            sampDict[stpDict[smp]['pop']].append(i)\n",
    "    else:\n",
    "        print smp\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sampDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k,v in stpDict.items():\n",
    "    if len(stpDict[k].items()) > 0:\n",
    "        1+1\n",
    "        #print k,stpDict[k]['pop'],stpDict[k]['plot']\n",
    "    else:\n",
    "        print 'crap'\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miss_reader = vcf.Reader(open(VCFmissing),'r') #must reset after this is sourced\n",
    "for rec in miss_reader: \n",
    "    for sample in rec:\n",
    "        if sample.sample not in stpDict.keys():\n",
    "            print sample.sample\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/IntersectionRowNames.txt',sep=\"\\t\",header=None)\n",
    "intset = set(intersection[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hierf_trans = {0:'11', 1:'12', 2:'22', -1:'NA'}\n",
    "transDict = { \"0/0\":11,   #k = gt , v = hierftrans\n",
    "              \"0/1\":12,\n",
    "              \"1/0\":12,\n",
    "              \"1/1\":22  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miss_reader = vcf.Reader(open(VCFmissing),'r') #reset or waste time\n",
    "for rec in miss_reader:\n",
    "    if len(rec.samples) != 224:\n",
    "        print rec\n",
    "    else:\n",
    "        print len(rec.samples)\n",
    "    recCount += 1\n",
    "    if recCount % 100 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(rec.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stpDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recset = set([sample.sample for sample in rec])\n",
    "stpset = set(stpDict.keys())\n",
    "intersect = recset.intersection(stpset)\n",
    "len(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in sampKey:\n",
    "    sample = rec.samples[i]\n",
    "    if len(stpDict[sample.sample].items()) > 0:\n",
    "        print sample.sample,stpDict[sample.sample].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "miss_reader = vcf.Reader(open(VCFmissing),'r') #reset or waste time\n",
    "\n",
    "recCount = 0\n",
    "hierDict = OrderedDict()      #key = locus, value = lineDict[sampleID] = hierfTrans\n",
    "#for rec in miss_reader:   #for each locus\n",
    "for rec in miss_reader:   #for each locus\n",
    "    locus = \"_\".join([str(rec.CHROM),str(rec.POS)])\n",
    "    #print locus\n",
    "    \n",
    "    if locus in intset: #if it's a locus we're interested in\n",
    "        \n",
    "        hierDict[locus] = OrderedDict()\n",
    "        for i in sampKey:\n",
    "            sample = rec.samples[i]\n",
    "            if len(stpDict[sample.sample].items()) > 0: #if there's a pop and plot for the sample.sample\n",
    "                gt = sample['GT'].split('/')\n",
    "                if '.' not in gt:\n",
    "                    hierDict[locus][sample.sample] = transDict[sample['GT']]\n",
    "                else:\n",
    "                    hierDict[locus][sample.sample] = 'NA'\n",
    "\n",
    "    recCount += 1\n",
    "    if recCount % 1000 == 0:\n",
    "        print recCount\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(hierDict.keys()) #hopefully 159803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(hierDict[hierDict.keys()[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptnDict = OrderedDict()\n",
    "for i,pop in enumerate(pops):\n",
    "    ptnDict[pop] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popDict = OrderedDict()\n",
    "for samp in hierDict[locus].keys():\n",
    "    if len(stpDict[samp].items())>0:\n",
    "        popDict[samp] = str(ptnDict[stpDict[samp]['pop']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(popDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotDict = OrderedDict()\n",
    "for samp in hierDict[locus].keys():\n",
    "    if len(stpDict[samp].items())>0:\n",
    "        plotDict[samp] = str(stpDict[samp]['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(hierDict[locus].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(popDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(plotDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([str(x) for x in hierDict[locus].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertrans_missing.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(filE,'w') as o:\n",
    "    line = '\\t'.join(hierDict[locus].keys()) + str('\\n') #columns\n",
    "    o.write(\"%s\" % line)\n",
    "    line = '\\t'.join(popDict.values()) + str('\\n') #popid\n",
    "    o.write(\"%s\" % line)\n",
    "    line = '\\t'.join(plotDict.values()) + str('\\n') #plotid\n",
    "    o.write(\"%s\" % line)\n",
    "    for locus in hierDict.keys():\n",
    "        line = '\\t'.join([str(x) for x in hierDict[locus].values()]) + str('\\n')\n",
    "        o.write(\"%s\" % line)    \n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filE,header=0,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = ['popid','plotid'] + hierDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df.T\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.replace(np.nan,\"NA\",inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(df2['popid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(df2['plotid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.sort_values([\"popid\", \"plotid\"])\n",
    "df2.loc[df2.index[7:25],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertransIDXHEADER_missing.txt'\n",
    "filE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv(filE,sep='\\t',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertransHEADERnoIDX_missing.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv(filE,sep='\\t',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put into R (because it's slow)\n",
    "\n",
    "```R\n",
    "\n",
    "setwd(\"/home/lindb/eckertlab/wbp/hierfstat/\")\n",
    "get_varcomp = function(x) \n",
    "{\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) \n",
    "{\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels - 1))\n",
    "    for (i in 1:(nblevels - 1)) \n",
    "    {\n",
    "        for (j in i:(nblevels - 1)) \n",
    "        {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "data = data.frame(fread(\"hiertransHEADERnoIDX_missing.txt\", header=T, sep=\"\\t\"))\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstatRUN_missing.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_hierfstatRUN_missing.rds\")\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_r(): ####/gpfs_fs/home/lindb/anaconda/envs/conda/lib/R ####/home/lindb/g/R3/lib64/R/\n",
    "    os.environ['R_HOME'] = '/home/lindb/g/R3/lib64/R/' \n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], ####/home/lindb/g/R3/lib64/R/bin/R\n",
    "                                                   os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri as pd2ri\n",
    "pd2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res = readRDS(\"/gpfs_fs/home/eckertlab/wbp/hierfstat/hierfstatRUN_missing.rds\")\n",
    "#bs = readRDS(\"/gpfs_fs/home/eckertlab/wbp/hierfstat/bs_hierfstatRUN_missing.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "names(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "dim(res$loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "hey2 = matrix(1:12,ncol=3,byrow=T)\n",
    "hey2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataF2 = pd.DataFrame(index=[\"hey\",\"you\",\"jerk\",\"pile\"],columns=[\"here\",\"i\",\"am\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in dataF2.index:\n",
    "    for col in dataF.columns:\n",
    "        count += 1\n",
    "        dataF2.loc[row,col] = count\n",
    "dataF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in dataF.index:\n",
    "    for col in dataF.columns:\n",
    "        count += 1\n",
    "        dataF.loc[row,col] = count\n",
    "dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Hs = series[0]+series[1]\n",
    "    Ht = sum(series)\n",
    "    return Hs/Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(snow)\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "compute_fst = function(vectr)\n",
    "{\n",
    "    print(vectr)\n",
    "    Hs = vectr[1] + vectr[2]\n",
    "    Ht = sum (vectr)\n",
    "    return (Hs/Ht)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst = dataF.apply(compute_fst, axis=1)\n",
    "loci_fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst2 = dataF2.apply(compute_fst, axis=1)\n",
    "loci_fst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "outmat = matrix(parCapply(cl,t(hey),compute_fst),nrow=nrow(hey),byrow=T)\n",
    "head(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "?parCapply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "outmat2 = matrix(parCapply(cl,t(hey2),compute_fst),nrow=nrow(hey2),byrow=T)\n",
    "head(outmat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "outmat = matrix(parCapply(cl, t(res$loc), compute_fst), nrow=nrow(res$loc),byrow=T)\n",
    "head(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "dim(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "hist(outmat,main=paste(\"n=\",length(outmat),\n",
    "                       \" mean=\",round(mean(outmat),digits = 3),\n",
    "                       \" +/- \",round(sd(outmat),digits=2),\n",
    "                       \" [\",round(min(outmat),digits = 2),\",\",round(max(outmat),digits = 2),\"]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "print (c(quantile(outmat),min(outmat),max(outmat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "row.names(outmat) = row.names(res$loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "colnames(outmat) = c(\"FST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "row.names(outmat)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "head(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "write.table(outmat,file=\"/home/lindb/eckertlab/wbp/hierfstat/loci_FST_missingHEADERIDX.txt\",sep=\"\\t\",eol=\"\\n\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = \"/home/lindb/eckertlab/wbp/hierfstat/loci_FST_missingHEADERIDX.txt\"\n",
    "frame = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#get the bayenv shiznit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a df with BF, rho, pearson's R output by bayenv for each environmental variable\n",
    "filE = '/home/lindb/eckertlab/wbp/bayenv2/Final/missing_bayenv2_outputSNPbyENV.txt'\n",
    "misEnvsBFs = pd.DataFrame(pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\"))\n",
    "misEnvsBFs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add on FST column\n",
    "misSNPfstBF = pd.merge(misEnvsBFs,frame,left_index=True,right_index=True)\n",
    "misSNPfstBF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misSNPfstBF.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misSNPfstBF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/misSNP_by_BAYENV2andFST_IDXHEADER.txt'\n",
    "misSNPfstBF.to_csv(filE,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misSNPfstBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/misSNP_by_BAYENV2andFST_IDXHEADER.txt'\n",
    "missnpfstbf = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "missnpfstbf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missnpfstbf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#run hierfstat for snps IDed by bayenv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the hierftrans for all SNPS, created above as the infile for multilocus FST\n",
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertransIDXHEADER_missing.txt'\n",
    "imptrans = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "imptrans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get bayenv2 SNPs\n",
    "files = os.listdir('/home/lindb/wbp/bayenv2/Final/missing')\n",
    "files = [os.path.join('/home/lindb/wbp/bayenv2/Final/missing',f) for f in files if not f.startswith('missing')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get list of environmental variables\n",
    "envs = []\n",
    "for f in files:\n",
    "    env = os.path.basename(f).split(\"_\")[0]\n",
    "    if not env in envs:\n",
    "        envs.append(env)\n",
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make some dirs\n",
    "DIR = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing'\n",
    "for env in envs:\n",
    "    d = os.path.join(DIR,env)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dictionary with list of SNPs IDed by bayenv2\n",
    "snpDict = OrderedDict()\n",
    "for f in files:\n",
    "    env = os.path.basename(f).split(\"_\")[0]\n",
    "    df = pd.read_csv(f,header=0,sep=\"\\t\")\n",
    "    snpDict[env] = df[env].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a hierftrans df for each environmental variable\n",
    "for env in snpDict.keys():\n",
    "    snps = snpDict[env]\n",
    "    cols = ['popid','plotid'] + snps\n",
    "    df = imptrans[cols]\n",
    "    filE1 = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/bayenv2_%s_hiertrans_HEADERIDX.txt' % (env,env)\n",
    "    filE2 = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/bayenv2_%s_hiertrans_HEADERnoIDX.txt' % (env,env)\n",
    "    df.to_csv(filE1,header=True,index=True,sep=\"\\t\") #make a file so I know what's what\n",
    "    df.to_csv(filE2,header=True,index=False,sep=\"\\t\") #make hiertrans infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make R files\n",
    "for env in snpDict.keys():\n",
    "    text ='''\n",
    "setwd(\"%s\")\n",
    "get_varcomp = function(x) \n",
    "{\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) \n",
    "{\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels - 1))\n",
    "    for (i in 1:(nblevels - 1)) \n",
    "    {\n",
    "        for (j in i:(nblevels - 1)) \n",
    "        {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "\n",
    "print(\"reading data\")\n",
    "data = data.frame(fread(\"%s\", header=T, sep=\"\\\\t\"))\n",
    "print(\"done reading\")\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "print(\"getting varcomp\")\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstatRUN_%s_missing.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_hierfstatRUN_%s_missing.rds\")\n",
    "\n",
    "print(\"computing fst\")\n",
    "compute_fst = function(vectr)\n",
    "{\n",
    "    print(vectr)\n",
    "    Hs = vectr[1] + vectr[2]\n",
    "    Ht = sum (vectr)\n",
    "    return (Hs/Ht)\n",
    "}\n",
    "\n",
    "outmat = matrix(parCapply(cl, t(res$loc), compute_fst), nrow=nrow(res$loc),byrow=T)\n",
    "row.names(outmat) = row.names(res$loc)\n",
    "colnames(outmat) = c(\"FST\")\n",
    "\n",
    "print(\"writing table\")\n",
    "write.table(outmat,file=\"/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/loci_FST_%s_missingHEADERIDX.txt\",sep=\"\\\\t\",eol=\"\\\\n\")\n",
    "\n",
    "\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "''' % ('/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/' % env,\n",
    "       'bayenv2_%s_hiertrans_HEADERnoIDX.txt' % env,\n",
    "       env,\n",
    "       env,\n",
    "       env,env\n",
    "      )\n",
    "    filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/%s_runfile.R' % (env,env)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check to make sure everything was made, and that each outfile is the correct length\n",
    "for env in envs:\n",
    "    filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/loci_FST_%s_missingHEADERIDX.txt' % (env,env)\n",
    "    if not os.path.exists(filE):\n",
    "        print filE\n",
    "    else:\n",
    "        df = pd.read_csv(filE,header=0,sep=\"\\t\")\n",
    "        print env,len(snpDict[env]),len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#take a look\n",
    "frame = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "filE,frame.shape,frame.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######                                                                                                          ######\n",
    "###### for each env, run hierfstat for 100 sets of random snps, each set equal in size to those IDed by bayenv2 ######\n",
    "######                                                                                                          ######\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check number of snps IDed by bayenv2\n",
    "for env in snpDict.keys():\n",
    "    print env, len(snpDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection = [snp for snp in imptrans.columns if 'NODE' in snp]\n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each env, get a list of SNPs not IDed by bayenv\n",
    "buckets = OrderedDict()\n",
    "for env in envs:\n",
    "    #filE was made in 'bayenv2 covariances missing.ipynb'    \n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/missing/drawbuckets/%s_bucket.txt' % env\n",
    "    df = pd.read_csv(filE,header=None,sep=\"\\t\")\n",
    "    df = pd.DataFrame(df[1])\n",
    "    df.columns = [env]\n",
    "    buckets[env] = df[env].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure snps IDed + not IDed = total snps (159803)\n",
    "for env in sorted(envs):\n",
    "    print env,len(snpDict[env]),len(buckets[env]),len(snpDict[env])+len(buckets[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get 100 hierftrans files for each env made with random snps\n",
    "for env in envs:\n",
    "    print env\n",
    "    DIR = '/home/lindb/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs' % env\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    for i in range(100):\n",
    "        snps = random.sample(buckets[env],len(snpDict[env]))\n",
    "        cols = ['popid','plotid'] + snps\n",
    "        df = imptrans[cols]\n",
    "        filE1 = os.path.join(DIR,'%s_%s_hiertrans_HEADERIDX.txt' % (env,str(i).zfill(2)))\n",
    "        filE2 = os.path.join(DIR,'%s_%s_hiertrans_HEADERnoIDX.txt' % (env,str(i).zfill(2)))\n",
    "        df.to_csv(filE1,header=True,index=True,sep=\"\\t\") #make a file so I know what's what\n",
    "        df.to_csv(filE2,header=True,index=False,sep=\"\\t\") #make hiertrans infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write scripts for 100 null fst per env\n",
    "for env in envs:\n",
    "    for i in range(100):\n",
    "        newtext ='''\n",
    "setwd(\"%s\")\n",
    "get_varcomp = function(x) \n",
    "{\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) \n",
    "{\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels - 1))\n",
    "    for (i in 1:(nblevels - 1)) \n",
    "    {\n",
    "        for (j in i:(nblevels - 1)) \n",
    "        {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "\n",
    "print(\"reading data\")\n",
    "data = data.frame(fread(\"%s\", header=T, sep=\"\\\\t\"))\n",
    "print(\"done reading\")\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "print(\"getting varcomp\")\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstatRUN_%s_%s_missing.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_hierfstatRUN_%s_%s_missing.rds\")\n",
    "\n",
    "print(\"computing fst\")\n",
    "compute_fst = function(vectr)\n",
    "{\n",
    "    print(vectr)\n",
    "    Hs = vectr[1] + vectr[2]\n",
    "    Ht = sum (vectr)\n",
    "    return (Hs/Ht)\n",
    "}\n",
    "\n",
    "outmat = matrix(parCapply(cl, t(res$loc), compute_fst), nrow=nrow(res$loc),byrow=T)\n",
    "row.names(outmat) = row.names(res$loc)\n",
    "colnames(outmat) = c(\"FST\")\n",
    "\n",
    "print(\"writing table\")\n",
    "write.table(outmat,file=\"/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs/loci_FST_%s_%s_missingHEADERIDX.txt\",sep=\"\\\\t\",eol=\"\\\\n\")\n",
    "\n",
    "\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "''' % ('/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs' % env, #working dir\n",
    "       '%s_%s_hiertrans_HEADERnoIDX.txt' % (env,str(i).zfill(2)), #infile\n",
    "       env,str(i).zfill(2), #res file\n",
    "       env,str(i).zfill(2), #bs file\n",
    "       env,env,str(i).zfill(2)) #write.table file\n",
    "        if i == 0:\n",
    "            text = newtext\n",
    "        else:\n",
    "            text = text + newtext\n",
    "    filE = '/home/lindb/wbp/hierfstat/Final/bayenv2/missing/%s/make_rand.R' % env\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#copy/paste these printouts into a linux R window - I'm runing these on 4 different nodes\n",
    "envcount = 0\n",
    "gcount = 0\n",
    "tcount = 0\n",
    "godel = ['06','11','16','24']\n",
    "for env in envs:\n",
    "    if envcount == 0:\n",
    "        print '\\ngodel%s\\n' % str(godel[gcount])\n",
    "        gcount += 1\n",
    "    print \"source('/home/lindb/wbp/hierfstat/Final/bayenv2/missing/%s/make_rand.R')\" % env\n",
    "    envcount += 1\n",
    "    tcount += 1\n",
    "    if envcount == 4:\n",
    "        envcount = 0\n",
    "        if tcount == 16:\n",
    "            print ' ' #returns are good to copy for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs/loci_FST_%s_%s_missingHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs/loci_FST_%s_%s_missingHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs/loci_FST_%s_%s_missingHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs/loci_FST_%s_%s_missingHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of 100 fst for each env, make sure there're nenv*100 files total\n",
    "fstDict = OrderedDict()\n",
    "for i,env in enumerate(envs):\n",
    "    fstDict[env] = []\n",
    "    \n",
    "    DIR = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s/0randSNPs/' % env\n",
    "    newfiles = os.listdir(DIR)\n",
    "    newfiles = [os.path.join(DIR,f) for f in newfiles if 'loci' in f]\n",
    "    \n",
    "    for f in newfiles:\n",
    "        df = pd.read_csv(f,header=0,index_col=0,sep=\"\\t\")\n",
    "        fsts = df['FST'].tolist()\n",
    "        fstDict[env] = fstDict[env] + fsts\n",
    "    \n",
    "    #add all files to a list\n",
    "    if i == 0:\n",
    "        files = newfiles\n",
    "    else:\n",
    "        files = files + newfiles\n",
    "print len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check for coherence with snps IDed by bayenv2\n",
    "for env in envs:\n",
    "    print env,len(snpDict[env]),len(fstDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the empiriacal fst distributions\n",
    "empfst = OrderedDict()\n",
    "for env in envs:\n",
    "    DIR = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/missing/%s' % env\n",
    "    files = os.listdir(DIR)\n",
    "    for f in files:\n",
    "        if 'loci' in f:\n",
    "            df = pd.read_csv(os.path.join(DIR,f),header=0,index_col=0,sep=\"\\t\")\n",
    "            fsts = df['FST'].tolist()\n",
    "            empfst[env] = fsts\n",
    "            break\n",
    "    print env, len(snpDict[env]),len(empfst[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(fstDict['Ann-ppt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(empfst['Ann-ppt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
