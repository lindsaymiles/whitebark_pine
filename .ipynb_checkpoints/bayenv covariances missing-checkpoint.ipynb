{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#misMAF made in 'pimass covariances missing.ipynb'\n",
    "filE = '/home/lindb/wbp/covariances/pimass/missing/MAF/combined_missing_MAF.txt'\n",
    "misMAF = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "misMAF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/wbp/bayenv2/Final/missing/'\n",
    "files = os.listdir(DIR)\n",
    "files = [f for f in files if not f.startswith('missing')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get sig snps (with BF >= 5)\n",
    "snpDict = OrderedDict()\n",
    "for f in files:\n",
    "    df = pd.read_csv(os.path.join(DIR,f),header=0,sep=\"\\t\")\n",
    "    env = f.split(\"_\")[0]\n",
    "    snpDict[env] = df[env].tolist()\n",
    "    print env, len(snpDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#do pairwise to get D\n",
    "dDict = OrderedDict()\n",
    "for env in snpDict.keys():\n",
    "    icount = 0\n",
    "    dDict[env] = OrderedDict()\n",
    "    for i,locusi in enumerate(snpDict[env]):\n",
    "        dDict[env][locusi] = OrderedDict()\n",
    "        for j,locusj in enumerate(snpDict[env]):\n",
    "            if i > j: #i=row, j=col : lower triangle\n",
    "                asums = 0\n",
    "                bsums = 0\n",
    "                csums = 0\n",
    "                for pop in misMAF.columns:\n",
    "                    p_i = misMAF.loc[locusi,pop]\n",
    "                    p_j = misMAF.loc[locusj,pop]\n",
    "                    \n",
    "                    #calc \"a\"\n",
    "                    product = p_i*p_j\n",
    "                    asums = asums + product\n",
    "                    \n",
    "                    #calc \"b\"\n",
    "                    bsums = bsums + p_i\n",
    "                    \n",
    "                    #calc \"c\" \n",
    "                    csums = csums + p_j\n",
    "                    \n",
    "                a = asums/len(misMAF.columns)\n",
    "                b = bsums/len(misMAF.columns)\n",
    "                c = csums/len(misMAF.columns)\n",
    "                \n",
    "                d = a - (b*c)\n",
    "                dDict[env][locusi][locusj] = d\n",
    "            else:\n",
    "                dDict[env][locusi][locusj] = np.nan\n",
    "        icount += 1\n",
    "        if icount % 10 == 0:\n",
    "            print env,icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out dval files for each env\n",
    "for env in dDict.keys():\n",
    "    rowcount = 0\n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/missing/dvals/%s_missing_dvals.txt' % env\n",
    "    with open(filE,'w') as o:\n",
    "        key0 = dDict[env].keys()[0]\n",
    "        line = '\\t'.join(dDict[env][key0].keys()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        for locusi in dDict[env].keys():\n",
    "            line = str(locusi)+'\\t'+'\\t'.join([str(x) for x in dDict[env][locusi].values()]) + str('\\n')\n",
    "            o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check one of the files\n",
    "df = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random set of SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/wbp/piMASS/IntersectionRowNames.txt'\n",
    "intersection = pd.read_csv(filE,header=None,sep=\"\\t\")\n",
    "intersection = [x for x in intersection[1]]\n",
    "intersection[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of SNPs that aren't significant\n",
    "bDict = OrderedDict()\n",
    "for env in snpDict.keys():\n",
    "    bDict[env] = list(set(intersection) - set(snpDict[env]))\n",
    "    df = pd.DataFrame(bDict[env])\n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/missing/drawbuckets/%s_bucket.txt' % env\n",
    "    df.to_csv(filE,header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#in case I have to restart my notebook\n",
    "bDict = OrderedDict()\n",
    "files = os.listdir('/home/lindb/wbp/covariances/bayenv2/missing/drawbuckets/')\n",
    "for f in files:\n",
    "    env = f.split(\"_\")[0]\n",
    "    print env\n",
    "    df = pd.read_csv(os.path.join('/home/lindb/wbp/covariances/bayenv2/missing/drawbuckets/',f),header=None,sep=\"\\t\")\n",
    "    bDict[env] = pd.DataFrame(df[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for env in bDict.keys():\n",
    "    print env, len(snpDict[env]),len(bDict[env]), len(snpDict[env])+len(bDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make 1000 matrices of d-values for random SNPs to compare with sig set\n",
    "for env in snpDict.keys():                                     #each phenotype gets 20 .py files (200 .sh files total)\n",
    "    print env\n",
    "    snpBucket = bDict[env]                             #the snps that can be drawn\n",
    "    for i in range(20):                                  #make 20 .py files\n",
    "        for j in range(50):                              #each .py file makes 50 matrices\n",
    "            snps = random.sample(snpBucket,len(snpDict[env]))           #select random snps\n",
    "\n",
    "            DIR = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/%s' % env\n",
    "            if not os.path.exists(DIR):\n",
    "                os.makedirs(DIR)\n",
    "            filE = os.path.join(DIR,\"%s_%s_%s_missing.txt\" % (env,str(i).zfill(2),str(j).zfill(2)))\n",
    "            df = pd.DataFrame(snps)\n",
    "            df.to_csv(filE,header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs = os.listdir('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in dirs:\n",
    "    files = os.listdir(os.path.join('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices',d))\n",
    "    print d,len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make .py files\n",
    "for env in snpDict.keys():\n",
    "    for i in range(20):\n",
    "        for j in range(50):\n",
    "            text = '''from __future__ import division\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "filE= '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/%s/%s_%s_%s_missing.txt'\n",
    "df = pd.read_csv(filE,header=None,sep=\"\\\\t\")\n",
    "snps = df[1].tolist()\n",
    "\n",
    "newdf = pd.read_csv('/home/lindb/wbp/covariances/pimass/missing/MAF/combined_missing_MAF.txt',header=0,index_col=0,sep=\"\\\\t\")\n",
    "\n",
    "icount = 0\n",
    "rDict = OrderedDict()\n",
    "for i,locusi in enumerate(snps):\n",
    "    rDict[locusi] = OrderedDict()\n",
    "    for j,locusj in enumerate(snps):\n",
    "        if i > j: #i=row, j=col : lower tri\n",
    "            asums = 0\n",
    "            bsums = 0\n",
    "            csums = 0\n",
    "            for pop in newdf.columns:\n",
    "                p_i = newdf.loc[locusi,pop]\n",
    "                p_j = newdf.loc[locusj,pop]\n",
    "                \n",
    "                #calc \"a\"\n",
    "                product = p_i*p_j\n",
    "                asums = asums + product\n",
    "                \n",
    "                #calc \"b\"\n",
    "                bsums = bsums + p_i\n",
    "                \n",
    "                #calc \"c\"\n",
    "                csums = csums + p_j\n",
    "            \n",
    "            a = asums/len(newdf.columns)\n",
    "            b = bsums/len(newdf.columns)\n",
    "            c = csums/len(newdf.columns)\n",
    "            \n",
    "            d = a - (b*c)\n",
    "            rDict[locusi][locusj] = d\n",
    "        else:\n",
    "            rDict[locusi][locusj] = np.nan\n",
    "    icount += 1\n",
    "    if icount %% 10 == 0:\n",
    "        print icount\n",
    "\n",
    "filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/0outfiles/%s_%s_%s_missingDVALS.txt'\n",
    "with open(filE,'w') as o:\n",
    "    line = '\\\\t'.join(snps) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locusi in rDict.keys():\n",
    "        line = str(locusi) + '\\\\t' + '\\\\t'.join([str(x) for x in rDict[locusi].values()]) + str('\\\\n')\n",
    "        o.write(\"%%s\" %% line)\n",
    "    \n",
    "''' % (env,env,str(i).zfill(2),str(j).zfill(2), \n",
    "      env,str(i).zfill(2),str(j).zfill(2))\n",
    "            filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/0pyfiles/%s_%s_%s_missing.py' % (env,\n",
    "                                                                                                      str(i).zfill(2),\n",
    "                                                                                                      str(j).zfill(2))\n",
    "            with open(filE,'w') as o:\n",
    "                o.write(text)\n",
    "            o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of all 32000 (16*100*2) py files combined between missing and imputed\n",
    "files = os.listdir('/gpfs_fs/home/eckertlab/wbp/covariances/bayenv2/missing/randmatrices/0pyfiles')\n",
    "files = [os.path.join('/gpfs_fs/home/eckertlab/wbp/covariances/bayenv2/missing/randmatrices/0pyfiles',f) for f in files]\n",
    "FILES = os.listdir('/home/lindb/wbp/covariances/bayenv2/imputed/randmatrices/0pyfiles')\n",
    "FILES = [os.path.join('/home/lindb/wbp/covariances/bayenv2/imputed/randmatrices/0pyfiles',f) for f in FILES]\n",
    "Files = files + FILES\n",
    "len(Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make 195 sh files to include imputed py files too\n",
    "fcount =0\n",
    "shcount =0\n",
    "tcount =0\n",
    "newsh = True\n",
    "for f in sorted(Files):\n",
    "    if newsh == True:\n",
    "        text = '''#!/bin/bash\n",
    "#$ -N run%s \n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "''' % str(shcount).zfill(3)\n",
    "    newtext = '''\n",
    "cd %s\n",
    "python %s\n",
    "''' % (os.path.dirname(f),f.split(\"/\")[-1])\n",
    "    text = text + newtext\n",
    "    \n",
    "    fcount += 1\n",
    "    tcount += 1\n",
    "    newsh = False\n",
    "    if (fcount == 165) or (tcount == 32000):\n",
    "        newsh = True\n",
    "        fcount =0\n",
    "        filE = '/gpfs_fs/home/eckertlab/wbp/covariances/bayenv2/missing/randmatrices/0runfiles/%s_run.sh' % str(shcount).zfill(3)\n",
    "        with open(filE,'w') as o:\n",
    "            o.write(text)\n",
    "        o.close()\n",
    "        \n",
    "        shcount += 1\n",
    "    if '%max-rad-input_00_00_imputed.py' in f:\n",
    "        print \"shcount\",shcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(Files)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KS tests - true SNPs vs rand SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/0outfiles/')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envs = []\n",
    "for f in sorted(files):\n",
    "    env = f.split(\"_\")[0]\n",
    "    if env not in envs:\n",
    "        envs.append(env)\n",
    "for env in envs:\n",
    "    print env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for env in envs:\n",
    "    text = '''from __future__ import division\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import anderson_ksamp\n",
    "\n",
    "#get observed dvals\n",
    "DF = pd.read_csv('/home/lindb/wbp/covariances/bayenv2/missing/dvals/%s_missing_dvals.txt',header=0,index_col=0,sep=\"\\\\t\")\n",
    "dvals = []\n",
    "for lst in DF.values.tolist():\n",
    "    for x in lst:\n",
    "        if math.isnan(x) == False:\n",
    "            dvals.append(x)\n",
    "            \n",
    "DIR = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/0outfiles'\n",
    "files = os.listdir(DIR)\n",
    "files = [f for f in files if f.startswith('%s')]\n",
    "\n",
    "pvals = []\n",
    "fcount = 0\n",
    "for f in files:\n",
    "    df = pd.read_csv(os.path.join(DIR,f),header=0,index_col=0,sep=\"\\\\t\")\n",
    "    rvals = []\n",
    "    for lst in df.values.tolist():\n",
    "        for x in lst:\n",
    "            if math.isnan(x) == False:\n",
    "                rvals.append(x)\n",
    "    \n",
    "    pvals.append(ks_2samp(rvals,dvals)[1])\n",
    "    fcount += 1\n",
    "    if fcount %% 10 == 0:\n",
    "        print fcount\n",
    "\n",
    "filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/0OBSpvals/%s_missing_observedpvalues.txt'\n",
    "pvals = pd.DataFrame(pvals)\n",
    "pvals.to_csv(filE,header=None,index=False,sep=\"\\\\t\")\n",
    "\n",
    "''' % (env,env,env)\n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/1OBSpvalrunfiles/%s_missing_pvalscript.py' % env\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Files = os.listdir('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/1OBSpvalrunfiles/')\n",
    "Files = [os.path.join('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/1OBSpvalrunfiles/',F) for F in Files]\n",
    "FILES = os.listdir('/home/lindb/wbp/covariances/bayenv2/imputed/randmatrices/1OBSpvalrunfiles/')\n",
    "FILES = [os.path.join('/home/lindb/wbp/covariances/bayenv2/imputed/randmatrices/1OBSpvalrunfiles/',F) for F in FILES]\n",
    "\n",
    "files = Files + FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    DIR = os.path.dirname(f)\n",
    "    fname = os.path.basename(f)\n",
    "    env = fname.split(\"_\")[0]\n",
    "    dset = DIR.split(\"/\")[6]\n",
    "    \n",
    "    text = '''#!/bin/bash\n",
    "#$ -N %s%s \n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd %s\n",
    "python %s\n",
    "''' % (dset[:3],env,DIR,fname)\n",
    "    \n",
    "\n",
    "    \n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/1OBSpvalshfiles/%s_%s.sh' % (env,dset)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KS tests - rand SNPs vs rand SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for env in snpDict.keys():\n",
    "    print env,len(snpDict[env]),len(bDict[env]),len(snpDict[env])+len(bDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make 1000 snp sets of random SNPs to compare with 1000 rand below\n",
    "for env in envs:                                     #each phenotype gets 20 .py files (200 .sh files total)\n",
    "    snpBucket = bDict[env]                             #the snps that can be drawn\n",
    "    for i in range(20):                                  #make 20 .py files\n",
    "        for j in range(50):                              #each .py file makes 50 matrices\n",
    "            snps = random.sample(snpBucket,len(snpDict[env]))           #select random snps\n",
    "\n",
    "            DIR = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/%s' % env\n",
    "            if not os.path.exists(DIR):\n",
    "                os.makedirs(DIR)\n",
    "            filE = os.path.join(DIR,\"%s_%s_%s_missing.txt\" % (env,str(i).zfill(2),str(j).zfill(2)))\n",
    "            df = pd.DataFrame(snps)\n",
    "            df.to_csv(filE,header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a second set of 1000 snp sets of random SNPs to compare with first random 1000 above\n",
    "for env in envs:                                     #each phenotype gets 20 .py files (200 .sh files total)\n",
    "    snpBucket = bDict[env]                             #the snps that can be drawn\n",
    "    for i in range(20):                                  #make 20 .py files\n",
    "        for j in range(50):                              #each .py file makes 50 matrices\n",
    "            snps = random.sample(snpBucket,len(snpDict[env]))           #select random snps\n",
    "\n",
    "            DIR = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/%s2' % env\n",
    "            if not os.path.exists(DIR):\n",
    "                os.makedirs(DIR)\n",
    "            filE = os.path.join(DIR,\"%s_%s_%s_missing.txt\" % (env,str(i).zfill(2),str(j).zfill(2)))\n",
    "            df = pd.DataFrame(snps)\n",
    "            df.to_csv(filE,header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make .py files to get dvals from both sets of 1000 snps created above\n",
    "for env in envs:\n",
    "    for i in range(20):\n",
    "        for j in range(50):\n",
    "            text = '''from __future__ import division\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "filE= '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/%s/%s_%s_%s_missing.txt'\n",
    "df = pd.read_csv(filE,header=None,sep=\"\\\\t\")\n",
    "snps = df[1].tolist()\n",
    "\n",
    "newdf = pd.read_csv('/home/lindb/wbp/covariances/pimass/missing/MAF/combined_missing_MAF.txt',header=0,index_col=0,sep=\"\\\\t\")\n",
    "\n",
    "icount = 0\n",
    "rDict = OrderedDict()\n",
    "for i,locusi in enumerate(snps):\n",
    "    rDict[locusi] = OrderedDict()\n",
    "    for j,locusj in enumerate(snps):\n",
    "        if i > j: #i=row, j=col : lower tri\n",
    "            asums = 0\n",
    "            bsums = 0\n",
    "            csums = 0\n",
    "            for pop in newdf.columns:\n",
    "                p_i = newdf.loc[locusi,pop]\n",
    "                p_j = newdf.loc[locusj,pop]\n",
    "                \n",
    "                #calc \"a\"\n",
    "                product = p_i*p_j\n",
    "                asums = asums + product\n",
    "                \n",
    "                #calc \"b\"\n",
    "                bsums = bsums + p_i\n",
    "                \n",
    "                #calc \"c\"\n",
    "                csums = csums + p_j\n",
    "            \n",
    "            a = asums/len(newdf.columns)\n",
    "            b = bsums/len(newdf.columns)\n",
    "            c = csums/len(newdf.columns)\n",
    "            \n",
    "            d = a - (b*c)\n",
    "            rDict[locusi][locusj] = d\n",
    "        else:\n",
    "            rDict[locusi][locusj] = np.nan\n",
    "    icount += 1\n",
    "    if icount %% 10 == 0:\n",
    "        print icount\n",
    "\n",
    "filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0outfiles/%s_%s_%s_missingDVALS.txt'\n",
    "with open(filE,'w') as o:\n",
    "    line = '\\\\t'.join(snps) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locusi in rDict.keys():\n",
    "        line = str(locusi) + '\\\\t' + '\\\\t'.join([str(x) for x in rDict[locusi].values()]) + str('\\\\n')\n",
    "        o.write(\"%%s\" %% line)\n",
    "\n",
    "#get dvals for second set\n",
    "filE= '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/%s2/%s_%s_%s_missing.txt'\n",
    "df = pd.read_csv(filE,header=None,sep=\"\\\\t\")\n",
    "snps = df[1].tolist()\n",
    "\n",
    "icount = 0\n",
    "rDict = OrderedDict()\n",
    "for i,locusi in enumerate(snps):\n",
    "    rDict[locusi] = OrderedDict()\n",
    "    for j,locusj in enumerate(snps):\n",
    "        if i > j: #i=row, j=col : lower tri\n",
    "            asums = 0\n",
    "            bsums = 0\n",
    "            csums = 0\n",
    "            for pop in newdf.columns:\n",
    "                p_i = newdf.loc[locusi,pop]\n",
    "                p_j = newdf.loc[locusj,pop]\n",
    "                \n",
    "                #calc \"a\"\n",
    "                product = p_i*p_j\n",
    "                asums = asums + product\n",
    "                \n",
    "                #calc \"b\"\n",
    "                bsums = bsums + p_i\n",
    "                \n",
    "                #calc \"c\"\n",
    "                csums = csums + p_j\n",
    "            \n",
    "            a = asums/len(newdf.columns)\n",
    "            b = bsums/len(newdf.columns)\n",
    "            c = csums/len(newdf.columns)\n",
    "            \n",
    "            d = a - (b*c)\n",
    "            rDict[locusi][locusj] = d\n",
    "        else:\n",
    "            rDict[locusi][locusj] = np.nan\n",
    "    icount += 1\n",
    "    if icount %% 10 == 0:\n",
    "        print icount\n",
    "\n",
    "filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0outfiles2/%s_%s_%s_missingDVALS.txt'\n",
    "with open(filE,'w') as o:\n",
    "    line = '\\\\t'.join(snps) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locusi in rDict.keys():\n",
    "        line = str(locusi) + '\\\\t' + '\\\\t'.join([str(x) for x in rDict[locusi].values()]) + str('\\\\n')\n",
    "        o.write(\"%%s\" %% line)\n",
    "    \n",
    "''' % (env,env,str(i).zfill(2),str(j).zfill(2), \n",
    "       env,str(i).zfill(2),str(j).zfill(2),\n",
    "       env,env,str(i).zfill(2),str(j).zfill(2),\n",
    "       env,str(i).zfill(2),str(j).zfill(2))\n",
    "            filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0pyfiles/%s_%s_%s_missing.py' % (env,\n",
    "                                                                                                      str(i).zfill(2),\n",
    "                                                                                                      str(j).zfill(2))\n",
    "            with open(filE,'w') as o:\n",
    "                o.write(text)\n",
    "            o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of all 32000 py files combined between missing and imputed\n",
    "files = os.listdir('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0pyfiles/')\n",
    "files = [os.path.join('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0pyfiles/',f) for f in files]\n",
    "FILES = os.listdir('/home/lindb/wbp/covariances/bayenv2/imputed/randmatrices/rand/0pyfiles/')\n",
    "FILES = [os.path.join('/home/lindb/wbp/covariances/bayenv2/imputed/randmatrices/rand/0pyfiles/',f) for f in FILES]\n",
    "Files = files + FILES\n",
    "len(Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#when to stop in the next frame\n",
    "tcount = 0\n",
    "for f in Files:\n",
    "    tcount += 1\n",
    "tcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make 195 sh files to include imputed py files too\n",
    "fcount  = 0\n",
    "shcount = 0\n",
    "tcount  = 0\n",
    "newsh   = True\n",
    "for f in sorted(Files):\n",
    "    if newsh == True:\n",
    "        text = '''#!/bin/bash\n",
    "#$ -N run%s \n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "''' % str(shcount).zfill(3)\n",
    "    newtext = '''\n",
    "cd %s\n",
    "python %s\n",
    "''' % (os.path.dirname(f),f.split(\"/\")[-1])\n",
    "    text = text + newtext\n",
    "    \n",
    "    fcount += 1\n",
    "    tcount += 1\n",
    "    newsh = False\n",
    "    if (fcount == 165) or (tcount == 32000):\n",
    "        newsh = True\n",
    "        fcount = 0\n",
    "        filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0runfiles/%s_run.sh' % str(shcount).zfill(3)\n",
    "        with open(filE,'w') as o:\n",
    "            o.write(text)\n",
    "        o.close()\n",
    "        \n",
    "        shcount += 1\n",
    "    \n",
    "    if '%max-rad-input_00_00_missing.py' in f: #to see (vim the file) where it transitions from imputed to missing\n",
    "        print \"shcount\",shcount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get pvals\n",
    "for env in envs:\n",
    "    text = '''from __future__ import division\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import anderson_ksamp\n",
    "\n",
    "pvals = []\n",
    "for i in range(20):\n",
    "    for j in range(50):\n",
    "\n",
    "        F1 = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0outfiles/%s_%%s_%%s_missingDVALS.txt' %% (str(i).zfill(2),str(j).zfill(2))\n",
    "        F2 = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0outfiles2/%s_%%s_%%s_missingDVALS.txt' %% (str(i).zfill(2),str(j).zfill(2))\n",
    "\n",
    "        df1 = pd.read_csv(F1, header=0,index_col=0,sep=\"\\\\t\")\n",
    "        df2 = pd.read_csv(F2, header=0,index_col=0,sep=\"\\\\t\")\n",
    "\n",
    "        dvals1 = []\n",
    "        for lst in df1.values.tolist():\n",
    "            for x in lst:\n",
    "                if math.isnan(x) == False:\n",
    "                    dvals1.append(x)\n",
    "        dvals2 = []\n",
    "        for lst in df2.values.tolist():\n",
    "            for x in lst:\n",
    "                if math.isnan(x) == False:\n",
    "                    dvals2.append(x)\n",
    "\n",
    "        pvals.append(ks_2samp(dvals1,dvals2)[1])\n",
    "\n",
    "filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0randpvals/%s_randpvalues.txt'\n",
    "pvals = pd.DataFrame(pvals)\n",
    "pvals.to_csv(filE,header=None,index=False,sep=\"\\\\t\")\n",
    "\n",
    "''' % (env,\n",
    "       env,\n",
    "       env)\n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/1RANDpvalrunfiles/%s_pvalscript.py' % env\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/1RANDpvalrunfiles/')\n",
    "files = [os.path.join('/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/1RANDpvalrunfiles/',f) for f in files]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    dset = f.split(\"/\")[6]\n",
    "    DIR = os.path.dirname(f)\n",
    "    fname = os.path.basename(f)\n",
    "    env = fname.split(\"_\")[0]\n",
    "    \n",
    "    text = '''#!/bin/bash\n",
    "#$ -N %s%s \n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd %s\n",
    "python %s\n",
    "''' % (dset,env,DIR,fname)\n",
    "    Dir = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/1RANDpvalshfiles'\n",
    "    filE = os.path.join(Dir,env+'_%s.sh' % dset)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Mann Whitney U tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for env in envs:\n",
    "    filE1 = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/rand/0randpvals/%s_randpvalues.txt' % env\n",
    "    filE2 = '/home/lindb/wbp/covariances/bayenv2/missing/randmatrices/0OBSpvals/%s_missing_observedpvalues.txt' % env\n",
    "    \n",
    "    obs = pd.read_csv(filE2,header=None,sep=\"\\t\")\n",
    "    rand = pd.read_csv(filE1,header=None,sep=\"\\t\")\n",
    "    \n",
    "    pval = mannwhitneyu(obs,rand)\n",
    "    print pval\n",
    "    \n",
    "    newtext = \"%s\\t%s\\n\" % (env,pval)\n",
    "    text = text + newtext\n",
    "filE = '/home/lindb/wbp/covariances/bayenv2/results/missing.txt'\n",
    "with open(filE,'w') as o:\n",
    "    o.write('env\\t(statistic,p-val)\\n')\n",
    "    o.write(text)\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
