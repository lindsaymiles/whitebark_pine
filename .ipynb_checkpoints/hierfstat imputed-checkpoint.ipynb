{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict,Counter\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VCFmissing = os.path.join(file_dir,'good_snps_good_samples_missing.vcf')\n",
    "VCFimputed = os.path.join(file_dir,'good_snps_good_samples.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/IntersectionRowNames.txt',sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intset = set(intersection[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#assigning samps to pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ucids = pd.read_csv('/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/WBP_IDS_MATCHED_POP_FINAL_05182015_canonical.csv',sep=\",\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ucids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops = np.unique(ucids['Population_ID']).tolist()\n",
    "pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ucDict = OrderedDict()\n",
    "count = 0\n",
    "for row in ucids.index:\n",
    "    ucdid = ucids.loc[row,'UCD_ID']\n",
    "    if ucdid not in ucDict.keys():\n",
    "        ucDict[ucdid] = OrderedDict()\n",
    "        if ucids.loc[row,'Population_ID'] in pops:\n",
    "            ucDict[ucdid]['pop'] = ucids.loc[row,'Population_ID']\n",
    "            ucDict[ucdid]['plot'] = ucids.loc[row,'Plot_id']\n",
    "        else:\n",
    "            #print ucids.loc[row,'Population_ID']\n",
    "            count += 1\n",
    "count       #should be 49 (224-175 = 49)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ucDict['WBP0015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ucDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/WBP_IDS_MATCHED_POP_FINAL_110915.xlsx\")\n",
    "for idx, row in test.iterrows():\n",
    "    sample = str(row['ID'])\n",
    "    if len(sample) == 1:\n",
    "        test.loc[idx,'ID'] = ''.join(['0','0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 2:\n",
    "        test.loc[idx,'ID'] = ''.join(['0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 3:\n",
    "        test.loc[idx,'ID'] = ''.join([sample,'compiled_sorted'])\n",
    "idxlst = []\n",
    "samplst = []\n",
    "for idx,row in test.iterrows():\n",
    "    #print str(test.loc[idx,'ID'])\n",
    "    if ('sorted' in str(test.loc[idx,'ID'])) and (str(test.loc[idx,'ID']) not in samplst):\n",
    "        idxlst.append(idx)\n",
    "        samplst.append(str(test.loc[idx,'ID']))\n",
    "test = test.loc[idxlst,:]\n",
    "test.index = [x for x in test['ID']]\n",
    "#new = pd.DataFrame(missingData.loc[:,missingData.columns[2:14]])\n",
    "test = pd.DataFrame(test.loc[:,[col for idx,col in enumerate(test.columns) if idx != 2]])\n",
    "test.sort_index(inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sDict = OrderedDict()\n",
    "for row in test.index:\n",
    "    #print row\n",
    "    if row not in sDict.keys():\n",
    "        sDict[row] = test.loc[row,'UCD_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ucDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.unique(ucDict.values())) #8 * 3 - 1 = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ucDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stpDict = OrderedDict()\n",
    "for k,v in sDict.items(): #k = samp , v = UCD_ID\n",
    "    if v in ucDict.keys(): # if UCD_ID in the ucDict.keys()\n",
    "        stpDict[k] = ucDict[v] #k = samp, v = [pop,plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stpDict['009compiled_sorted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stpDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stpDict['237compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['238compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['239compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['240compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['241compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['242compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['243compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['244compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['245compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['246compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['247compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])\n",
    "stpDict['248compiled_sorted'] = OrderedDict([('pop','Mt_Rose_Ophir'),('plot',3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.unique(stpDict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stpDict.keys()[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/sampsTOpop.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(filE,'w') as o:\n",
    "    line = \"samp\\tplot\\tpop\\n\"\n",
    "    o.write(\"%s\" % line)\n",
    "    for samp,popdata in stpDict.items():\n",
    "        if len(stpDict[samp].keys()) > 0:\n",
    "            pop = stpDict[samp]['pop']\n",
    "            plot = str(stpDict[samp]['plot'])\n",
    "            line = '\\t'.join([samp,plot,pop])+str('\\n')\n",
    "            o.write(\"%s\" % line)\n",
    "    o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filE,sep=\"\\t\",header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imputed_reader = vcf.Reader(open(VCFimputed),'r')\n",
    "#miss_reader = vcf.Reader(open(VCFmissing),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputed_reader = vcf.Reader(open(VCFimputed),'r') #must reset after this is sourced\n",
    "for rec in imputed_reader: \n",
    "    for sample in rec:\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a key so we can sample each rec in order of sampleID\n",
    "smpLST = [rec.samples[i].sample for i,x in enumerate(rec.samples)]\n",
    "sortSMPLST = sorted(smpLST)\n",
    "sampKey = []\n",
    "for i,smp in enumerate(sortSMPLST):\n",
    "    sampKey.append(smpLST.index(sortSMPLST[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smpLST[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sampKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampDict = OrderedDict()\n",
    "for pop in pops:\n",
    "    print pop\n",
    "    sampDict[pop] = []\n",
    "for i,smp in enumerate(smpLST):\n",
    "    if smp in stpDict.keys():\n",
    "        if len(stpDict[smp].keys()) > 0:\n",
    "            sampDict[stpDict[smp]['pop']].append(i)\n",
    "    else:\n",
    "        print smp\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sampDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampDict['Freel_Peak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stpDict.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hierf_trans = {0:'11', 1:'12', 2:'22', -1:'NA'}\n",
    "transDict = { \"0|0\":11,   #k = gt , v = hierftrans\n",
    "              \"0|1\":12,\n",
    "              \"1|0\":12,\n",
    "              \"1|1\":22  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transDict[\"0|0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample['GT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transDict[sample['GT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#may have accidentally deleted a cell. oops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampKey[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stpDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k,v in stpDict.items():\n",
    "    if len(stpDict[k].items()) > 0:\n",
    "        print k,stpDict[k]['pop'],stpDict[k]['plot']\n",
    "    else:\n",
    "        print 'crap'\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputed_reader = vcf.Reader(open(VCFimputed),'r') #must reset after this is sourced\n",
    "for rec in imputed_reader: \n",
    "    for sample in rec:\n",
    "        if sample.sample not in stpDict.keys():\n",
    "            print sample.sample\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_reader = vcf.Reader(open(VCFimputed),'r') #reset or waste time\n",
    "\n",
    "recCount = 0\n",
    "hierDict = OrderedDict()      #key = locus, value = lineDict[sampleID] = hierfTrans\n",
    "#for rec in miss_reader:   #for each locus\n",
    "for rec in imputed_reader:   #for each locus\n",
    "    locus = \"_\".join([str(rec.CHROM),str(rec.POS)])\n",
    "    #print locus\n",
    "    \n",
    "    if locus in intset: #if it's a locus we're interested in\n",
    "        \n",
    "        hierDict[locus] = OrderedDict()\n",
    "        for i in sampKey:\n",
    "            sample = rec.samples[i]\n",
    "            if len(stpDict[sample.sample].items()) > 0: #if there's a pop and plot for the sample.sample\n",
    "                gt = sample['GT'].split('|')\n",
    "                if '.' not in gt:\n",
    "                    hierDict[locus][sample.sample] = transDict[sample['GT']]\n",
    "                else:\n",
    "                    hierDict[locus][sample.sample] = 'NA'\n",
    "\n",
    "    recCount += 1\n",
    "    if recCount % 1000 == 0:\n",
    "        print recCount\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(hierDict.keys()) #hopefully 159803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "        #pop #plot #loc #loc2 #loc3\n",
    "#samp\n",
    "#samp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "      #samp #samp2 #samp3\n",
    "#pop\n",
    "#plot\n",
    "#loc\n",
    "#loc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in stpDict.items():\n",
    "    print k,v\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ptnDict = OrderedDict()\n",
    "for i,pop in enumerate(pops):\n",
    "    ptnDict[pop] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popDict = OrderedDict()\n",
    "for samp in hierDict[locus].keys():\n",
    "    if len(stpDict[samp].items())>0:\n",
    "        popDict[samp] = str(ptnDict[stpDict[samp]['pop']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(popDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotDict = OrderedDict()\n",
    "for samp in hierDict[locus].keys():\n",
    "    if len(stpDict[samp].items())>0:\n",
    "        plotDict[samp] = str(stpDict[samp]['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertrans_imputed.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(hierDict[locus].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(popDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(plotDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([str(x) for x in hierDict[locus].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(filE,'w') as o:\n",
    "    line = '\\t'.join(hierDict[locus].keys()) + str('\\n') #columns\n",
    "    o.write(\"%s\" % line)\n",
    "    line = '\\t'.join(popDict.values()) + str('\\n') #popid\n",
    "    o.write(\"%s\" % line)\n",
    "    line = '\\t'.join(plotDict.values()) + str('\\n') #plotid\n",
    "    o.write(\"%s\" % line)\n",
    "    for locus in hierDict.keys():\n",
    "        line = '\\t'.join([str(x) for x in hierDict[locus].values()]) + str('\\n')\n",
    "        o.write(\"%s\" % line)    \n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filE,header=0,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index = ['popid','plotid'] + hierDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(df2['popid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(df2['plotid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertransIDXHEADER_imputed.txt'\n",
    "filE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.index[0:8].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.sort_values([\"popid\", \"plotid\"])\n",
    "df2.loc[df2.index[7:25],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv(filE,sep='\\t',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertransHEADERnoIDX_imputed.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.to_csv(filE,sep='\\t',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Put into R (because it's slow)\n",
    "\n",
    "```R\n",
    "\n",
    "setwd(\"/home/lindb/eckertlab/wbp/hierfstat/\")\n",
    "get_varcomp = function(x) \n",
    "{\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) \n",
    "{\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels - 1))\n",
    "    for (i in 1:(nblevels - 1)) \n",
    "    {\n",
    "        for (j in i:(nblevels - 1)) \n",
    "        {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "data = data.frame(fread(\"hiertransHEADERnoIDX_imputed.txt\", header=T, sep=\"\\t\"))\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstatRUN_imputed.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_hierfstatRUN_imputed.rds\")\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_r(): ####/gpfs_fs/home/lindb/anaconda/envs/conda/lib/R ####/home/lindb/g/R3/lib64/R/\n",
    "    os.environ['R_HOME'] = '/home/lindb/g/R3/lib64/R/' \n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], ####/home/lindb/g/R3/lib64/R/bin/R\n",
    "                                                   os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri as pd2ri\n",
    "pd2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res = readRDS(\"/gpfs_fs/home/eckertlab/wbp/hierfstat/hierfstatRUN_imputed.rds\")\n",
    "#bs = readRDS(\"/gpfs_fs/home/eckertlab/wbp/hierfstat/bs_hierfstatRUN_imputed.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "names(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "dim(res$loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "hey = matrix(1:9,ncol=3,byrow=T)\n",
    "hey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataF = pd.DataFrame(index=[\"hey\",\"you\",\"jerk\"],columns=[\"here\",\"i\",\"am\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in dataF.index:\n",
    "    for col in dataF.columns:\n",
    "        count += 1\n",
    "        dataF.loc[row,col] = count\n",
    "dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Hs = series[0]+series[1]\n",
    "    Ht = sum(series)\n",
    "    return Hs/Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(snow)\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "compute_fst = function(vectr)\n",
    "{\n",
    "    print(vectr)\n",
    "    Hs = vectr[1] + vectr[2]\n",
    "    Ht = sum (vectr)\n",
    "    return (Hs/Ht)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst = dataF.apply(compute_fst, axis=1)\n",
    "loci_fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "class(hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "outmat = matrix(parCapply(cl,t(hey),compute_fst),nrow=nrow(hey),byrow=T)\n",
    "head(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "outmat = matrix(parCapply(cl, t(res$loc), compute_fst), nrow=nrow(res$loc),byrow=T)\n",
    "head(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "hist(outmat,main=paste(\"n=\",length(outmat),\n",
    "                       \" mean=\",round(mean(outmat),digits = 3),\n",
    "                       \" +/- \",round(sd(outmat),digits=2),\n",
    "                       \" +/- [\",round(min(outmat),digits = 2),\",\",round(max(outmat),digits = 2),\"]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "row.names(outmat) = row.names(res$loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "colnames(outmat) = c(\"FST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "row.names(outmat)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "head(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "write.table(outmat,file=\"/home/lindb/eckertlab/wbp/hierfstat/loci_FST_imputedIDX.txt\",sep=\"\\t\",eol=\"\\n\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = \"/home/lindb/eckertlab/wbp/hierfstat/loci_FST_imputedIDX.txt\"\n",
    "frame = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(frame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get the bayenv shiznit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/bayenv2/Final/imputed_bayenv2_outputSNPbyENV.txt'\n",
    "impEnvsBFs = pd.DataFrame(pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\"))\n",
    "impEnvsBFs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impSNPfstBF = pd.merge(impEnvsBFs,frame,left_index=True,right_index=True)\n",
    "impSNPfstBF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impSNPfstBF.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impSNPfstBF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/impSNP_by_BAYENV2andFST_IDXHEADER.txt'\n",
    "impSNPfstBF.to_csv(filE,sep=\"\\t\",header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impSNPfstBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/impSNP_by_BAYENV2andFST_IDXHEADER.txt'\n",
    "impsnpfstbf = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "impsnpfstbf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impsnpfstbf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#run hierfstat for SNPs in bayenv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the hierftrans for all SNPS, created above as infile for multilocus FST\n",
    "filE = '/home/lindb/eckertlab/wbp/hierfstat/hiertransIDXHEADER_imputed.txt'\n",
    "imptrans = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "imptrans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get bayenv2 SNPs\n",
    "files = os.listdir('/home/lindb/wbp/bayenv2/Final/imputed')\n",
    "files = [os.path.join('/home/lindb/wbp/bayenv2/Final/imputed',f) for f in files if not f.startswith('imputed')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get list of environmental variables\n",
    "envs = []\n",
    "for f in files:\n",
    "    env = os.path.basename(f).split(\"_\")[0]\n",
    "    if not env in envs:\n",
    "        envs.append(env)\n",
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make some dirs\n",
    "DIR = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed'\n",
    "for env in envs:\n",
    "    d = os.path.join(DIR,env)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dictionary with list of SNPs IDed by bayenv2\n",
    "snpDict = OrderedDict()\n",
    "for f in files:\n",
    "    env = os.path.basename(f).split(\"_\")[0]\n",
    "    df = pd.read_csv(f,header=0,sep=\"\\t\")\n",
    "    snpDict[env] = df[env].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a hierftrans df for each environmental variable\n",
    "for env in snpDict.keys():\n",
    "    snps = snpDict[env]\n",
    "    cols = ['popid','plotid'] + snps\n",
    "    df = imptrans[cols]\n",
    "    filE1 = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/bayenv2_%s_hiertrans_HEADERIDX.txt' % (env,env)\n",
    "    filE2 = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/bayenv2_%s_hiertrans_HEADERnoIDX.txt' % (env,env)\n",
    "    df.to_csv(filE1,header=True,index=True,sep=\"\\t\") #make a file so I know what's what\n",
    "    df.to_csv(filE2,header=True,index=False,sep=\"\\t\") #make hiertrans infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make R files\n",
    "for env in snpDict.keys():\n",
    "    text ='''\n",
    "setwd(\"%s\")\n",
    "get_varcomp = function(x) \n",
    "{\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) \n",
    "{\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels - 1))\n",
    "    for (i in 1:(nblevels - 1)) \n",
    "    {\n",
    "        for (j in i:(nblevels - 1)) \n",
    "        {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "\n",
    "print(\"reading data\")\n",
    "data = data.frame(fread(\"%s\", header=T, sep=\"\\\\t\"))\n",
    "print(\"done reading\")\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "print(\"getting varcomp\")\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstatRUN_%s_imputed.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_hierfstatRUN_%s_imputed.rds\")\n",
    "\n",
    "print(\"computing fst\")\n",
    "compute_fst = function(vectr)\n",
    "{\n",
    "    print(vectr)\n",
    "    Hs = vectr[1] + vectr[2]\n",
    "    Ht = sum (vectr)\n",
    "    return (Hs/Ht)\n",
    "}\n",
    "\n",
    "outmat = matrix(parCapply(cl, t(res$loc), compute_fst), nrow=nrow(res$loc),byrow=T)\n",
    "row.names(outmat) = row.names(res$loc)\n",
    "colnames(outmat) = c(\"FST\")\n",
    "\n",
    "print(\"writing table\")\n",
    "write.table(outmat,file=\"/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/loci_FST_%s_imputedHEADERIDX.txt\",sep=\"\\\\t\",eol=\"\\\\n\")\n",
    "\n",
    "\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "''' % ('/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/' % env,\n",
    "       'bayenv2_%s_hiertrans_HEADERnoIDX.txt' % env,\n",
    "       env,\n",
    "       env,\n",
    "       env,env\n",
    "      )\n",
    "    filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/%s_runfile.R' % (env,env)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy and paste output into a linux R window\n",
    "for env in envs:\n",
    "    print \"source('/home/lindb/wbp/hierfstat/Final/bayenv2/imputed/%s/%s_runfile.R')\" % (env,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check to make sure everything was made, and that each outfile is the correct length\n",
    "for env in envs:\n",
    "    filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/loci_FST_%s_imputedHEADERIDX.txt' % (env,env)\n",
    "    if not os.path.exists(filE):\n",
    "        print filE\n",
    "    else:\n",
    "        df = pd.read_csv(filE,header=0,sep=\"\\t\")\n",
    "        print env,len(snpDict[env]),len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#take a look\n",
    "frame = pd.read_csv(filE,header=0,index_col=0,sep=\"\\t\")\n",
    "filE,frame.shape,frame.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######################################################################################################################\n",
    "######                                                                                                          ######\n",
    "###### for each env, run hierfstat for 100 sets of random snps, each set equal in size to those IDed by bayenv2 ######\n",
    "######                                                                                                          ######\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each env, get a list of SNPs not IDed by bayenv\n",
    "buckets = OrderedDict()\n",
    "for env in envs:\n",
    "    #filE was made in 'bayenv2 covariances imputed.ipynb'\n",
    "    filE = '/home/lindb/wbp/covariances/bayenv2/imputed/drawbuckets/%s_bucket.txt' % env\n",
    "    df = pd.read_csv(filE,header=None,sep=\"\\t\")\n",
    "    df = pd.DataFrame(df[1])\n",
    "    df.columns = [env]\n",
    "    buckets[env] = df[env].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure snps IDed + not IDed = total snps (159803)\n",
    "for env in sorted(envs):\n",
    "    print env,len(snpDict[env]),len(buckets[env]),len(snpDict[env])+len(buckets[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get 100 hierftrans files for each env made with random snps\n",
    "for env in envs:\n",
    "    print env\n",
    "    DIR = '/home/lindb/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs' % env\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    for i in range(100):\n",
    "        snps = random.sample(buckets[env],len(snpDict[env]))\n",
    "        cols = ['popid','plotid'] + snps\n",
    "        df = imptrans[cols]\n",
    "        filE1 = os.path.join(DIR,'%s_%s_hiertrans_HEADERIDX.txt' % (env,str(i).zfill(2)))\n",
    "        filE2 = os.path.join(DIR,'%s_%s_hiertrans_HEADERnoIDX.txt' % (env,str(i).zfill(2)))\n",
    "        df.to_csv(filE1,header=True,index=True,sep=\"\\t\") #make a file so I know what's what\n",
    "        df.to_csv(filE2,header=True,index=False,sep=\"\\t\") #make hiertrans infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for env in envs:\n",
    "    for i in range(100):\n",
    "        newtext ='''\n",
    "setwd(\"%s\")\n",
    "get_varcomp = function(x) \n",
    "{\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) \n",
    "{\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels - 1))\n",
    "    for (i in 1:(nblevels - 1)) \n",
    "    {\n",
    "        for (j in i:(nblevels - 1)) \n",
    "        {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "\n",
    "print(\"reading data\")\n",
    "data = data.frame(fread(\"%s\", header=T, sep=\"\\\\t\"))\n",
    "print(\"done reading\")\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "print(\"getting varcomp\")\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstatRUN_%s_%s_imputed.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_hierfstatRUN_%s_%s_imputed.rds\")\n",
    "\n",
    "print(\"computing fst\")\n",
    "compute_fst = function(vectr)\n",
    "{\n",
    "    print(vectr)\n",
    "    Hs = vectr[1] + vectr[2]\n",
    "    Ht = sum (vectr)\n",
    "    return (Hs/Ht)\n",
    "}\n",
    "\n",
    "outmat = matrix(parCapply(cl, t(res$loc), compute_fst), nrow=nrow(res$loc),byrow=T)\n",
    "row.names(outmat) = row.names(res$loc)\n",
    "colnames(outmat) = c(\"FST\")\n",
    "\n",
    "print(\"writing table\")\n",
    "write.table(outmat,file=\"/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs/loci_FST_%s_%s_imputedHEADERIDX.txt\",sep=\"\\\\t\",eol=\"\\\\n\")\n",
    "\n",
    "\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "''' % ('/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs' % env, #working dir\n",
    "       '%s_%s_hiertrans_HEADERnoIDX.txt' % (env,str(i).zfill(2)), #infile\n",
    "       env,str(i).zfill(2), #res file\n",
    "       env,str(i).zfill(2), #bs file\n",
    "       env,env,str(i).zfill(2)) #write.table file\n",
    "        if i == 0:\n",
    "            text = newtext\n",
    "        else:\n",
    "            text = text + newtext\n",
    "    filE = '/home/lindb/wbp/hierfstat/Final/bayenv2/imputed/%s/make_rand.R' % env\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#put these into a linux R window - I'm runing these on 4 different nodes\n",
    "envcount = 0\n",
    "for env in envs:\n",
    "    print \"source('/home/lindb/wbp/hierfstat/Final/bayenv2/imputed/%s/make_rand.R')\" % env\n",
    "    envcount += 1\n",
    "    if envcount == 4:\n",
    "        print \"\\n\"\n",
    "        envcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs/loci_FST_%s_%s_imputedHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs/loci_FST_%s_%s_imputedHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "for env in envs:\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        filE = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs/loci_FST_%s_%s_imputedHEADERIDX.txt' % (env,env,str(i).zfill(2))\n",
    "        if os.path.exists(filE):\n",
    "            count += 1\n",
    "    print env,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of 100 fst for each env, make sure there're nenv*100 files total\n",
    "fstDict = OrderedDict()\n",
    "for i,env in enumerate(envs):\n",
    "    fstDict[env] = []\n",
    "    \n",
    "    DIR = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s/0randSNPs/' % env\n",
    "    newfiles = os.listdir(DIR)\n",
    "    newfiles = [os.path.join(DIR,f) for f in newfiles if 'loci' in f]\n",
    "    \n",
    "    for f in newfiles:\n",
    "        df = pd.read_csv(f,header=0,index_col=0,sep=\"\\t\")\n",
    "        fsts = df['FST'].tolist()\n",
    "        fstDict[env] = fstDict[env] + fsts\n",
    "    \n",
    "    #add all files to a list\n",
    "    if i == 0:\n",
    "        files = newfiles\n",
    "    else:\n",
    "        files = files + newfiles\n",
    "print len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check for coherence with snps IDed by bayenv2\n",
    "for env in envs:\n",
    "    print env,len(snpDict[env]),len(fstDict[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the empiriacal fst distributions\n",
    "empfst = OrderedDict()\n",
    "for env in envs:\n",
    "    DIR = '/home/lindb/eckertlab/wbp/hierfstat/Final/bayenv2/imputed/%s' % env\n",
    "    files = os.listdir(DIR)\n",
    "    for f in files:\n",
    "        if 'loci' in f:\n",
    "            df = pd.read_csv(os.path.join(DIR,f),header=0,index_col=0,sep=\"\\t\")\n",
    "            fsts = df['FST'].tolist()\n",
    "            empfst[env] = fsts\n",
    "            break\n",
    "    print env, len(snpDict[env]),len(empfst[env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(fstDict['Ann-ppt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(empfst['Ann-ppt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
