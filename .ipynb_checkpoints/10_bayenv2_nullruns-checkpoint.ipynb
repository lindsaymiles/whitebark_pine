{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vcf\n",
    "import random\n",
    "from collections import OrderedDict, Counter\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "from __future__ import division\n",
    "import math\n",
    "import os.path as op\n",
    "import os.listdir as ls\n",
    "from ipyparallel import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?opdirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_dir  = '/home/lindb/wbp/bayenv2/nullruns/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imputedData = pd.read_csv('/home/lindb/wbp/bayenv2/imputed_z12_maf_swp_trans_z12.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "imputedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stpDF = pd.read_csv('/home/lindb/wbp/sampsTOpop.txt',header=0,sep=\"\\t\")\n",
    "stpDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(imputedData.index),len(stpDF.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops = np.unique(stpDF['pop']).tolist()\n",
    "pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popDict = Counter()\n",
    "for row in stpDF.index:\n",
    "    POP = stpDF.loc[row,'pop']\n",
    "    popDict[POP] += 1\n",
    "for pop in popDict.keys():\n",
    "    print pop,popDict[pop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sums = 0\n",
    "for pop in popDict.keys():\n",
    "    sums = sums + popDict[pop]\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100): #make 100 runfiles to make SNPSFILES\n",
    "    num = str(i).zfill(3)\n",
    "    text = '''print \"starting\"\n",
    "import sys\n",
    "import os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "import random\n",
    "\n",
    "filE = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/%supdate.txt'\n",
    "with open(filE,'w') as o:\n",
    "    text = 'importing data\\\\n'\n",
    "    o.write(\"%%s\" %% text)\n",
    "imputedData = pd.read_csv('/home/lindb/wbp/bayenv2/imputed_z12_maf_swp_trans_z12.txt',header=0,index_col=0,sep=\"\\\\t\")\n",
    "print \"done importing\"\n",
    "\n",
    "stpDF = pd.read_csv('/home/lindb/wbp/sampsTOpop.txt',header=0,sep=\"\\\\t\")\n",
    "\n",
    "stpnew = stpDF\n",
    "\n",
    "pops = np.unique(stpnew['pop']).tolist()\n",
    "\n",
    "popDict = OrderedDict()\n",
    "for pop in pops:\n",
    "    popDict[pop] = 0\n",
    "\n",
    "for row in stpnew.index:\n",
    "    POP = stpDF.loc[row,'pop']\n",
    "    popDict[POP] += 1\n",
    "\n",
    "pops = []\n",
    "for pop in sorted(popDict.keys()):\n",
    "    pops.append(pop)\n",
    "\n",
    "print \"creating idx\"\n",
    "with open(filE,'a') as o:\n",
    "    text = 'creating idx\\\\n'\n",
    "    o.write(\"%%s\" %% text)\n",
    "idx = range(len(imputedData.index))\n",
    "sampDict = OrderedDict()\n",
    "print \"assigning random samps to pops\"\n",
    "with open(filE,'a') as o:\n",
    "    text = 'assigning random samps to pops\\\\n'\n",
    "    o.write(\"%%s\" %% text)\n",
    "for pop in sorted(popDict.keys()): #randomly assign samples to pops\n",
    "    which = random.sample(idx,popDict[pop])\n",
    "    samps = itemgetter(*which)(imputedData.index.tolist())\n",
    "    sampDict[pop] = imputedData[imputedData.index.isin(samps)]\n",
    "    idx = [x for x in idx if x not in which]\n",
    "\n",
    "print \"iterating loci\"\n",
    "with open(filE,'a') as o:\n",
    "    text = 'iterating loci\\\\n'\n",
    "    o.write(\"%%s\" %% text)\n",
    "locCount = 0\n",
    "nullDict = OrderedDict()\n",
    "for locus in imputedData.columns:\n",
    "    nullDict[locus] = OrderedDict()\n",
    "    \n",
    "    for pop in sorted(pops):\n",
    "        \n",
    "        zero = sampDict[pop][locus].tolist().count(0) #count the first homozygotes\n",
    "        one  = sampDict[pop][locus].tolist().count(1) #count the heterozygotes\n",
    "        two  = sampDict[pop][locus].tolist().count(2) #count the second homozygotes        \n",
    "        A1 = 2*zero + one\n",
    "        A2 = 2*two + one\n",
    "        if len(nullDict[locus].keys()) == 0:\n",
    "            nullDict[locus]['A1'] = OrderedDict()\n",
    "            nullDict[locus]['A2'] = OrderedDict()\n",
    "        nullDict[locus]['A1'][pop] = A1\n",
    "        nullDict[locus]['A2'][pop] = A2\n",
    "    locCount += 1\n",
    "    if locCount %% 1000 == 0:\n",
    "        print locCount\n",
    "        with open(filE,'a') as o:\n",
    "            text = \"%%s\\\\n\" %% str(locCount)\n",
    "            o.write(\"%%s\" %% text)\n",
    "        #break\n",
    "    #break\n",
    "        \n",
    "print \"writing file, iteration %s\"\n",
    "filE = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/UnbinnedImputedSNPSFILE%s_HEADERROW.txt' \n",
    "DIR = opdirname(filE)\n",
    "if not opexists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "with open(filE, 'w') as o:\n",
    "    line = '\\\\t'.join([str(pop) for pop in sorted(popDict.keys())]) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locus in nullDict.keys():\n",
    "        for allele in nullDict[locus].keys():\n",
    "            line = str(locus) + '\\\\t' + '\\\\t'.join([str(x) for x in nullDict[locus][allele].values()]) + str('\\\\n')\n",
    "            #print locus,allele,line\n",
    "            o.write(\"%%s\" %% line)\n",
    "o.close()\n",
    "''' % (str(num),str(i).zfill(3),str(i).zfill(3))\n",
    "    FILE = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEsrunfiles/imp_run%s.py' % str(i).zfill(3)\n",
    "    if not op.exists(op.dirname(FILE)):\n",
    "        os.makedirs(op.dirname(FILE))\n",
    "    with open(FILE,'w') as o:\n",
    "        o.write(text)\n",
    "    o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEsrunfiles/'\n",
    "files = ls(root)\n",
    "for f in files:\n",
    "    runname = op.join(root,f).split(\".\")[0].split(\"/\")[-1][-3:]\n",
    "    text = '''#!/bin/bash\n",
    "#$ -N %s\n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd /home/lindb/wbp/bayenv2/nullruns/SNPSFILEsrunfiles/\n",
    "python %s\n",
    "''' % ('null'+runname,f)\n",
    "    filE = op.join(root,'null'+runname + '.sh')\n",
    "    with open(filE,'w') as o:\n",
    "        o.write('%s' % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# null matrix estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#1 Get list of SNPSFILEs and create a directory using that name\n",
    "#2 get SNPSFILE with header/idx, save as SNPSFILE without headerIDX in new directory\n",
    "#3 copy ./bayenv2, ENVIRONFILE to each new folder\n",
    "#4 create qsub files to create MATRIXFILEs\n",
    "#5 split the SNPSFILE\n",
    "#6 make usable matrix files\n",
    "#7 run bayenv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snp_dir = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.join(snp_dir,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Get list of SNPSFILEs and create a directory using that name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#move each of the files into its own directory - eg, 'null000'\n",
    "os.chdir(snp_dir)\n",
    "files = ls(snp_dir)\n",
    "\n",
    "for f in files:\n",
    "    if f.endswith('txt'):\n",
    "        splits = f.split(\"_\")\n",
    "        num = splits[0][-3:]\n",
    "        DIR = op.join(snp_dir,'null%s' % str(num))\n",
    "        \n",
    "        newf = op.join(DIR,f)\n",
    "        print num,f,'\\n%s' % DIR\n",
    "        \n",
    "        \n",
    "        if not op.exists(DIR):\n",
    "            os.makedirs(DIR)\n",
    "            \n",
    "        shutil.move(op.join(snp_dir,f),newf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirs = ls(snp_dir)\n",
    "dirs = sorted([op.join(snp_dir,d) for d in dirs if 'null' in d])\n",
    "len(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/null000/UnbinnedImputedSNPSFILE000_HEADERROW.txt',\n",
    "                 header=0,index_col=0,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - get SNPSFILE with header/idx, save as SNPSFILE without headerIDX in new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in dirs:\n",
    "    num = d[-3:]\n",
    "    snpsfile = ls(d)[0]\n",
    "    df = pd.read_csv(op.join(d,snpsfile),header=0,index_col=0,sep=\"\\t\")\n",
    "    \n",
    "    filE = op.join(d,'UnbinnedImputedSNPSFILE%s_noHEADERIDX.txt' % num)\n",
    "    df.to_csv(filE,header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - copy ./bayenv2, ENVIRONFILE to each new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EF = '/home/lindb/wbp/bayenv2/ENVIRONFILE.txt'\n",
    "bayenv = '/home/lindb/wbp/bayenv2/bayenv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in sorted(dirs):\n",
    "    shutil.copy(EF,d)\n",
    "    shutil.copy(bayenv,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.sample(range(100000),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - create qsub files to create MATRIXFILEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/UnbinnedImputedSNPSFILE064_HEADERROW.txt')\n",
    "df.to_csv('/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/UnbinnedImputedSNPSFILE064_noHEADERIDX.txt',\n",
    "          header=False,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/home/lindb/wbp/bayenv2/bayenv2 -i UnbinnedImputedSNPSFILE064_noHEADERIDX.txt -p 8 -k 100000 -r 89754 > matrix_064.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in sorted(dirs):\n",
    "    #print d\n",
    "    num = d[-3:]\n",
    "    print num\n",
    "    text ='''#!/bin/bash\n",
    "#$ -N %s \n",
    "#$ -V\n",
    "#$ -j y\n",
    "#$ -cwd\n",
    "\n",
    "cd %s\n",
    "./bayenv2 -i UnbinnedImputedSNPSFILE%s_noHEADERIDX.txt -p 8 -k 100000 -r %s > matrix_%s.out\n",
    "\n",
    "''' % ('mat%s' % str(num),\n",
    "       d,\n",
    "       str(num),\n",
    "       str(random.sample(range(100000),1)[0]),\n",
    "       str(num)\n",
    "      )\n",
    "    #print text\n",
    "    filE = op.join(op.dirname(d),'M-est/get_%s_matrix.sh' % str(num))\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#qsub the .sh files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check on progress\n",
    "done_mats = []\n",
    "statslst = []\n",
    "for d in dirs:\n",
    "    files = ls(d)\n",
    "    f = op.join(d,[f for f in files if 'matrix' in f][0])\n",
    "    stats = os.stat(f)\n",
    "    if stats.st_size > 0:\n",
    "        #print f\n",
    "        #print stats.st_size\n",
    "        done_mats.append(f)\n",
    "        statslst.append(stats.st_size)\n",
    "len(done_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a look at the contents of one of the finished files, making sure it reached the 100,000th chain ...\n",
    "    #... by reading lines and making sure the output is an 8x8 matrix (npops = 8)\n",
    "matrixfile = open(done_mats[14])\n",
    "r = matrixfile.readlines()\n",
    "for line in r[2005:][:-1]:\n",
    "    print line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 5 - split the SNPSFILEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of the loci we want to run - created in 08_bayenv2\n",
    "nullf = '/home/lindb/wbp/bayenv2/results/uniq_loci_bfgreaterthan3and10worst.txt'\n",
    "nu\n",
    "lldf = pd.read_csv(nullf,header=0,sep='\\t')\n",
    "nulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(nulldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in dirs:\n",
    "    snpsdir = op.join(d,'snps')\n",
    "    os.makedirs(snpsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#godzilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"xmn\")\n",
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "#len(dview)\n",
    "len(lview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_SNPFILEs(two):\n",
    "    d,nulldf = two\n",
    "    import os\n",
    "    import os.path as op\n",
    "    import sys\n",
    "    import socket\n",
    "    import stopwatch\n",
    "    from subprocess import Popen, PIPE\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print d\n",
    "    snpsdir = op.join(d,'snps')\n",
    "    \n",
    "    files = ls(d)\n",
    "    if len(files) == 0:\n",
    "        return 're-queue'\n",
    "    f = [f for f in files if 'HEADERROW' in f][0]\n",
    "    print f\n",
    "    df = pd.read_csv(op.join(d,f),header=0,index_col=0,sep='\\t')\n",
    "    data = df[df.index.isin(nulldf['topandlowestBFs'].tolist())]\n",
    "    \n",
    "    loccount = 0\n",
    "    for locus in np.unique(data.index).tolist():\n",
    "        filE = op.join(snpsdir,locus)\n",
    "        snpdf = pd.DataFrame(data.loc[locus,:])\n",
    "        snpdf.to_csv(filE,header=False,index=False,sep='\\t')\n",
    "        loccount += 1 \n",
    "        if loccount % 1000 == 0:\n",
    "            print loccount \n",
    "    return loccount\n",
    "dview['write_SNPSFILEs'] = write_SNPFILEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_jobs = []\n",
    "for d in sorted(dirs):\n",
    "    snp_jobs.append(lview.apply_async(write_SNPFILEs,[d,nulldf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for s in snp_jobs:\n",
    "    if s.ready():\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in snp_jobs:\n",
    "    if s.ready():\n",
    "        print s.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in sorted(dirs):\n",
    "    num = op.basename(d)\n",
    "    snpdir = op.join(d,'snps')\n",
    "\n",
    "    files = ls(snpdir)\n",
    "    \n",
    "    print len(files),d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 6  - make usable MATRIXFILEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in sorted(dirs):\n",
    "    DIR = d\n",
    "    files = ls(DIR)\n",
    "    if len(files)>1: #all have /snps, so len>=1\n",
    "        for f in files:\n",
    "            if (f.startswith('matrix')) and (f.endswith('out')):\n",
    "                #print opjoin(DIR,f)\n",
    "                F = open(opjoin(DIR,f),'r')\n",
    "                g = F.readlines()\n",
    "                new = f[:-4] + '.txt'\n",
    "                filE = op.join(DIR,'usable_%s' % new)\n",
    "                #print filE\n",
    "                with open(filE,'w') as o:\n",
    "                    for line in g[2005:][:-1]:\n",
    "                        o.write(line)\n",
    "                o.close()\n",
    "                break\n",
    "    else:\n",
    "        print \"skipped\" , d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - make qsub files to run bayenv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snplst = []\n",
    "for d in sorted(dirs):\n",
    "    snpdir = op.join(d,'snps')\n",
    "    files = ls(snpdir)\n",
    "    if len(files) == 2003:\n",
    "        [snplst.append(op.join(snpdir,f)) for f in files]\n",
    "len(snplst) #one folder needs to be redone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_jobs = 190\n",
    "num_chunks = int(np.round(200300/bayenv_jobs))\n",
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = [snplst[x:x+num_chunks] for x in range(0, len(snplst), num_chunks)]\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par_dir = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/parallel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulldir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_exe = '/home/lindb/wbp/bayenv2/bayenv2'\n",
    "bay_ENV = '/home/lindb/wbp/bayenv2/ENVIRONFILE.txt'\n",
    "total = 0\n",
    "cpu = 0\n",
    "max_cpu = 30\n",
    "for i, chunk in enumerate(chunks):\n",
    "    opener = op.join(par_dir, \"bayenv_parallel_%s\" % str(i).zfill(3))\n",
    "    with open(opener, \"w\") as o:\n",
    "        text = 'cd /home/lindb/wbp/bayenv2/\\n'\n",
    "        o.write(\"%s\" % text)\n",
    "        for filE in chunk:\n",
    "            nulldir = op.dirname(op.dirname(filE))\n",
    "            num = nulldir[-3:]\n",
    "            cmd = '%s \\\n",
    "-i %s \\\n",
    "-m %s \\\n",
    "-e %s \\\n",
    "-p 8 -k 100000 -n 18 -t -X -c -f \\\n",
    "-r %s' % (bay_exe,\n",
    "          filE,\n",
    "          op.join(nulldir,'usable_matrix_%s.txt'%str(num)),\n",
    "          bay_ENV,\n",
    "          str(random.sample(xrange(100000),1)[0])\n",
    "         )\n",
    "            bayenv_cmd = cmd.split()\n",
    "            if cpu == max_cpu:\n",
    "                cpu = 0\n",
    "            \n",
    "            bayenv_cmd.insert(0, \"taskset -c %d\" % cpu)\n",
    "            bayenv_cmd.append(\"-o %s\" % op.join(nulldir,'bf_environfile.ENVIRONFILE.txt'))\n",
    "            o.write(\"%s\\n\" % \" \".join([str(x) for x in bayenv_cmd]))\n",
    "            total += 1\n",
    "            cpu += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find -type f -name 'NODE*' | parallel --progress '/home/lindb/wbp/bayenv2/bayenv2 -i {} \\\n",
    "-m /home/lindb/wbp/bayenv2/usable_matrix.txt \\\n",
    "-e /home/lindb/wbp/bayenv2/ENVIRONFILE.txt \\\n",
    "-p 8 -k 100000 -n 18 -t -X -c -f -r 34813'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(random.sample(xrange(100000),1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"xmn\")\n",
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "#len(dview)\n",
    "len(lview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_count(f):\n",
    "    res = !wc -l {f}\n",
    "    return int(res[2].split()[0])\n",
    "dview['get_line_count'] = get_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_par = lspar_dir)\n",
    "bay_par = [opjoin(par_dir,f) for f in bay_par if 'parallel' in f]\n",
    "len(bay_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for f in sorted(bay_par):\n",
    "    print(f)\n",
    "    total += get_line_count(f)\n",
    "total #189 + 99*2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(bay_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_qsub_files(bayenv_parallel):\n",
    "    files = []\n",
    "    for i, f in enumerate(bayenv_parallel):\n",
    "        d = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/qsubs/'\n",
    "        if not opexists(d):\n",
    "            os.makedirs(d)\n",
    "        qsub_file = opjoin(d, \"qsub_%s.sh\" % str(i).zfill(3))\n",
    "        files.append(qsub_file)\n",
    "        with open(qsub_file, \"w\") as o:\n",
    "            os.chmod(o.name, 0o744)\n",
    "            print(o.name)\n",
    "            o.write(\"%s\\n\" % \"\\n\".join([\"#!/bin/bash\", \n",
    "                                        \"#$ -N bayenv%d\" % i,\n",
    "                                        \"#$ -V\",\n",
    "                                        \"#$ -cwd\",\n",
    "                                        \"#$ -pe smp 30\",\n",
    "                                        \"#$ -j y\",\n",
    "                                        \"#$ -q all.q\",\n",
    "                                        \"unset module\",\n",
    "                                        \"echo \\\"Running on $HOSTNAME\\\"\",\n",
    "                                        \"cat %s | ~/bin/parallel -j 30 --progress --\" % f]))\n",
    "    return files\n",
    "qsub_files = write_qsub_files(bay_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    !ls /home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/parallel/ | parallel 'qsub {}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/wbp/bayenv2/nullruns/SNPSFILEs/'\n",
    "dirs = ls(DIR)\n",
    "dirs = [op.join(DIR,d) for d in dirs if 'null' in d]\n",
    "len(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for d in dirs:\n",
    "    files = ls(d)\n",
    "    if 'bf_environfile.ENVIRONFILE.txt.bf' in files:\n",
    "        #print d\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the environfile\n",
    "envdf = pd.read_csv('/home/lindb/wbp/bayenv2/ENVIRONFILE_headerIDX.txt',header=0,index_col=0,sep='\\t')\n",
    "envdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assign column value for each environmental variable, to be used to name columns in bf_ENVIRONFILE.txt\n",
    "envDict = OrderedDict()\n",
    "for i, env in enumerate(envdf.index):\n",
    "    #print i,env\n",
    "    envDict[env] = [(i*3),(i*3)+1,(i*3)+2]\n",
    "envDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orderDict = {}\n",
    "orderDict[0] = 'BF'\n",
    "orderDict[1] = 'rho'\n",
    "orderDict[2] = 'pearson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a dictionary to name columns in bf_environfile.ENVIRONFILE\n",
    "colDict = OrderedDict()\n",
    "for env,cols in envDict.items():\n",
    "    #print env,cols\n",
    "    colCount = 0\n",
    "    for col in cols:\n",
    "        sub = '_'.join([str(env), orderDict[colCount]]) \n",
    "        colDict[col] = sub\n",
    "        colCount += 1\n",
    "colDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.basename(d)[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs = sorted(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look to see how many loci finished bayenv2 runs\n",
    "for d in dirs:\n",
    "    num = d.split(\"/\")[-1][-3:]\n",
    "    snpdir = opjoin(d,'snps')\n",
    "    bffile = opjoin(d,'bf_environfile.ENVIRONFILE.txt.bf')\n",
    "    bfdf = pd.read_csv(bffile,header=None,sep=\"\\t\")        \n",
    "    print num,len(bfdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix missing loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a list of snps that should have been done\n",
    "snps = pd.read_csv('/home/lindb/wbp/bayenv2/results/uniq_loci_bfgreaterthan3and10worst.txt')['topandlowestBFs'].tolist()\n",
    "len(snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of snps left to do\n",
    "redos = OrderedDict()\n",
    "for d in sorted(dirs):\n",
    "    num = d.split(\"/\")[-1][-3:]\n",
    "    snpdir = opjoin(d,'snps')\n",
    "    \n",
    "    bffile = opjoin(d,'bf_environfile.ENVIRONFILE.txt.bf')\n",
    "    bfdf = pd.read_csv(bffile,header=None,sep=\"\\t\")\n",
    "    loci = [bfdf.loc[row,0].split(\"/\")[-1] for row in bfdf.index]\n",
    "    \n",
    "    redosnps = set(snps)-set(loci)\n",
    "    redos\n",
    "    print num,len(redosnps)\n",
    "    redos[num] = list(redosnps)\n",
    "    \n",
    "    if len(loci) > len(snps):\n",
    "        print 'uh oh'\n",
    "print 'len(redo.keys()) =',len(redos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end of fixing missing loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get all of the bf_ENVIRONFILEs as a dataframe within a dictionary\n",
    "bfDict = OrderedDict()\n",
    "for d in dirs:\n",
    "    if not '064' in d:\n",
    "        num = d.split(\"/\")[-1][-3:]\n",
    "        snpdir = opjoin(d,'snps')\n",
    "        bffile = opjoin(d,'bf_environfile.ENVIRONFILE.txt.bf')\n",
    "        bfdf = pd.read_csv(bffile,header=None,sep=\"\\t\")        \n",
    "        print num,len(bfdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.split(\"/\")[-1][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bfdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all of the bf_ENVIRONFILEs as a dataframe within a dictionary\n",
    "bfDict = OrderedDict()\n",
    "for d in sorted(dirs):\n",
    "    if not '064' in d:\n",
    "        num = d.split(\"/\")[-1][-3:]\n",
    "        print num\n",
    "        snpdir = opjoin(d,'snps')\n",
    "        bffile = opjoin(d,'bf_environfile.ENVIRONFILE.txt.bf')\n",
    "        bfdf = pd.read_csv(bffile,header=None,sep=\"\\t\")\n",
    "        \n",
    "        loci = []\n",
    "        for row in bfdf.index:\n",
    "            locus = bfdf.loc[row,0].split(\"/\")[-1]\n",
    "            loci.append(locus)\n",
    "        bfdf = pd.DataFrame(bfdf.loc[:,[x for x in bfdf.columns[1:-1]]])\n",
    "        bfdf.columns = [x for x in range(len(bfdf.columns))]\n",
    "        bfdf.columns = [colDict[col]+'_%s'%num for col in bfdf.columns]\n",
    "        bfdf.index = [locus for locus in loci]\n",
    "        bfDict[num] = bfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bfDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bfDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bfDict[90]['WCrdbar_BF_090'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bfDict[30].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make dataframes for each env that contain all BFs across runs\n",
    "envbfDict = OrderedDict()\n",
    "for env in envdf.index: # for each environmental variable\n",
    "#    print env\n",
    "    dfcount = 0\n",
    "    for run in bfDict.keys(): #for each bf_ENVIRONFILE\n",
    "        col = '%s_BF_%s' % (env,str(run).zfill(3))\n",
    "        df = pd.DataFrame(bfDict[run][col])\n",
    "        if dfcount == 0:\n",
    "            newdf = df\n",
    "        else:\n",
    "            newdf = pd.merge(newdf,df,left_index=True,right_index=True)\n",
    "        dfcount += 1\n",
    "        #break\n",
    "    filE = '/home/lindb/wbp/bayenv2/nullruns/results/%s_all_BFs.txt' % env\n",
    "    newdf.to_csv(filE,header=True,index=True,sep=\"\\t\")\n",
    "    envbfDict[env] = newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(bfDict[run][col]).sort_values(by='WC3rdbar_BF_099',ascending=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get BFs from the empirical (true data) run of bayenv2\n",
    "empBFs = pd.read_csv('/home/lindb/wbp/bayenv2/results/BF_all.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "empBFs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(envbfDict['Elev'].columns) #100 null runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the empirically IDed snps from bayenv2 (BF >= 3)\n",
    "snpdir = '/home/lindb/wbp/bayenv2/results/'\n",
    "snpfiles = [op.join(snpdir,f) for f in ls(snpdir) if '3and10' in f and 'uniq' not in f]\n",
    "\n",
    "snpDict = OrderedDict()\n",
    "for f in snpfiles:\n",
    "    env = op.basename(f).split(\"_\")[0]\n",
    "    snpDict[env] = OrderedDict()\n",
    "    df = pd.read_csv(f,header=0,index_col=0,sep=\"\\t\")\n",
    "    \n",
    "    snpDict[env]['best'] = df[df[\"%s_BF\"%env] >=3].index\n",
    "    snpDict[env]['worst']= df[df[\"%s_BF\"%env] < 3].index\n",
    "    \n",
    "    print env,len(snpDict[env]['best'])+len(snpDict[env]['worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get dataframes with just the snps IDed from empirical bayenv2 runs\n",
    "newDict = OrderedDict()\n",
    "for env in envbfDict.keys():\n",
    "    df = envbfDict[env]\n",
    "    df.index = [str(x[2:]) for x in envbfDict[env].index]\n",
    "    newDict[env] = df[df.index.isin(snpDict[env])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
