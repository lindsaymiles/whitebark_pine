{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vcf\n",
    "import os\n",
    "import pysam\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/WBP_IDS_MATCHED_POP_FINAL_110915.xlsx\")\n",
    "for idx, row in test.iterrows():\n",
    "    sample = str(row['ID'])\n",
    "    if len(sample) == 1:\n",
    "        test.loc[idx,'ID'] = ''.join(['0','0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 2:\n",
    "        test.loc[idx,'ID'] = ''.join(['0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 3:\n",
    "        test.loc[idx,'ID'] = ''.join([sample,'compiled_sorted'])\n",
    "idxlst = []\n",
    "samplst = []\n",
    "for idx,row in test.iterrows():\n",
    "    #print str(test.loc[idx,'ID'])\n",
    "    if ('sorted' in str(test.loc[idx,'ID'])) and (str(test.loc[idx,'ID']) not in samplst):\n",
    "        idxlst.append(idx)\n",
    "        samplst.append(str(test.loc[idx,'ID']))\n",
    "test = test.loc[idxlst,:]\n",
    "test.index = [x for x in test['ID']]\n",
    "#new = pd.DataFrame(missingData.loc[:,missingData.columns[2:14]])\n",
    "test = pd.DataFrame(test.loc[:,[col for idx,col in enumerate(test.columns) if idx != 2]])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piM_dir = '/home/lindb/eckertlab/wbp/piMASS/'\n",
    "new_mispifile = pd.read_csv(os.path.join(piM_dir,'mispifileIntersection.txt'),header=None,sep=\"\\t\")\n",
    "new_mispifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colz = pd.read_csv(os.path.join(piM_dir,'IntersectionColNames.txt'),header=None,sep=\"\\t\")\n",
    "colz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_mispifile.columns = [x for x in colz[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.loc[[x for x in new_mispifile.columns[3:]],:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misresiddf = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/misResidDf.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "misresiddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resids = OrderedDict()\n",
    "resids['mis'] = misresiddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pifiles = OrderedDict()\n",
    "pifiles['mis'] = new_mispifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = misresiddf.columns[0:10]\n",
    "phenos,len(phenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenots = OrderedDict()\n",
    "for dset in pifiles.keys():\n",
    "    phenots[dset] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        lst = resids[dset][pheno].values.tolist()\n",
    "        phenots[dset][pheno] = pd.DataFrame(resids[dset].loc[resids[dset].index[np.where(np.array(pd.notnull(lst)))[0].tolist()],pheno])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phenots[dset][pheno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsets = ['mis']\n",
    "for d in dsets:\n",
    "    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is what I used for the final alpha values\n",
    "#this is what I used to recalculate alphas making sure that the df was being read in as numbers\n",
    "alphas = OrderedDict() #k = imp or mis, v = data\n",
    "rowz   = OrderedDict()\n",
    "for dset in dsets:\n",
    "    print \"starting\",dset\n",
    "    count = 0\n",
    "    row_idx = []\n",
    "    alphas[dset] = OrderedDict()\n",
    "    \n",
    "    for row in pifiles[dset].index: #for each locus\n",
    "        lineDict = OrderedDict()\n",
    "        row_idx.append(pifiles[dset].loc[row,'locus'])\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print \"calculating %s file.\" % dset,\"rowCount =\",count\n",
    "        for pheno in phenos:     #for each phenotype\n",
    "            df = pd.DataFrame()\n",
    "            phenot = phenots[dset][pheno]\n",
    "            dosages = pd.DataFrame(pifiles[dset].loc[row,phenot.index.tolist()])\n",
    "            dosages.columns = ['dosages']\n",
    "            \n",
    "            dosages = dosages.dropna()\n",
    "            phenot = phenot[phenot.index.isin(dosages.index)]\n",
    "            \n",
    "            df = pd.merge(phenot,dosages,left_index=True,right_index=True)\n",
    "            df = df.astype(float)\n",
    "            \n",
    "            formula = '%s~dosages' % str(pheno)\n",
    "            lineDict[str(pheno)] = smf.ols(formula,df).fit().params[1] # = alpha\n",
    "            #alphas[i].loc[row,str(pheno)] = alpha\n",
    "            #break\n",
    "        alphas[dset][row] = lineDict\n",
    "        #break\n",
    "    rowz[dset] = row_idx\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dos = dosages.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ph = phenot[phenot.index.isin(dos.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#getting stuff for Andrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = '/home/lindb/eckertlab/wbp/piMASS/infiles2/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(out_dir):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [f for f in files if 'swp' not in f]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_logs = OrderedDict()\n",
    "mis_logs = OrderedDict()\n",
    "imp_mcmc = OrderedDict()\n",
    "mis_mcmc = OrderedDict()\n",
    "imp_path = OrderedDict()\n",
    "mis_path  = OrderedDict()\n",
    "imp_snp  = OrderedDict()\n",
    "mis_snp   = OrderedDict()\n",
    "imp_gamma = OrderedDict()\n",
    "mis_gamma = OrderedDict()\n",
    "\n",
    "for root,dirs,files in os.walk(out_dir):\n",
    "    for f in files:\n",
    "        if 'swp' not in f:\n",
    "            fs = f.split(\"_\")\n",
    "            pheno = fs[1]\n",
    "            #print f,fs,pheno\n",
    "            if pheno not in imp_logs.keys():\n",
    "                imp_logs[pheno]  = []\n",
    "                mis_logs[pheno]  = []\n",
    "                imp_mcmc[pheno]  = []\n",
    "                mis_mcmc[pheno]  = []\n",
    "                imp_path[pheno]  = []\n",
    "                mis_path[pheno]  = []\n",
    "                imp_snp[pheno]   = [] \n",
    "                mis_snp[pheno]   = []\n",
    "                imp_gamma[pheno] = []\n",
    "                mis_gamma[pheno] = []\n",
    "            if 'path' in f:\n",
    "                if 'imp' in f:\n",
    "                    print f,\"imp\"\n",
    "                    imp_path[pheno].append(os.path.join(root,f))\n",
    "                if 'mis' in f:\n",
    "                    print f,\"mis\"\n",
    "                    mis_path[pheno].append(os.path.join(root,f))\n",
    "            if 'log' in f:\n",
    "                if 'imp' in f:\n",
    "                    imp_logs[pheno].append(os.path.join(root,f))\n",
    "                if 'mis' in f:\n",
    "                    mis_logs[pheno].append(os.path.join(root,f))\n",
    "            if 'mcmc' in f:\n",
    "                if 'imp' in f:\n",
    "                    imp_mcmc[pheno].append(os.path.join(root,f))\n",
    "                if 'mis' in f:\n",
    "                    mis_mcmc[pheno].append(os.path.join(root,f))\n",
    "            if 'snp' in f:\n",
    "                if 'imp' in f:\n",
    "                    imp_snp[pheno].append(os.path.join(root,f))\n",
    "                if 'mis' in f:\n",
    "                    mis_snp[pheno].append(os.path.join(root,f))\n",
    "            if 'gamma' in f:\n",
    "                if 'imp' in f:\n",
    "                    imp_gamma[pheno].append(os.path.join(root,f))\n",
    "                if 'mis' in f:\n",
    "                    mis_gamma[pheno].append(os.path.join(root,f))\n",
    "\n",
    "logDict = OrderedDict()\n",
    "pathDict = OrderedDict()\n",
    "mcmcDict = OrderedDict()\n",
    "snpDict = OrderedDict()\n",
    "gammaDict = OrderedDict()\n",
    "\n",
    "logDict['imp'] = imp_logs\n",
    "logDict['mis'] = mis_logs\n",
    "pathDict['imp'] = imp_path\n",
    "pathDict['mis'] = mis_path\n",
    "mcmcDict['imp'] = imp_mcmc\n",
    "mcmcDict['mis'] = mis_mcmc\n",
    "snpDict['imp'] = imp_snp\n",
    "snpDict['mis'] = mis_snp\n",
    "gammaDict['imp'] = imp_gamma\n",
    "gammaDict['mis'] = mis_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathDict['imp']['c13popx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = pathDict['imp'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData = OrderedDict()\n",
    "for dset,dic in pathDict.items():\n",
    "    pathData[dset] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        pathData[dset][pheno] = []\n",
    "        DFs = [pd.read_csv(x,sep=\"\\t\") for x in pathDict[dset][pheno]]\n",
    "        for df in DFs:\n",
    "            df.columns = [x.strip() for x in df.columns]\n",
    "        pathData[dset][pheno] = [x.ix[:,:-1] for x in DFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData['imp']['c13famx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData['imp']['c13famx'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(phenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hmean_row(row):\n",
    "    row = row[row != 0]\n",
    "    row = abs(row)\n",
    "    try:\n",
    "        return sp.stats.hmean(row)\n",
    "    except ValueError as e:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_hmean_row([1,5,3,6,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdData = OrderedDict()\n",
    "for dset,dic in pathData.items():\n",
    "    stdData[dset] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        stdData[dset][pheno] = OrderedDict()\n",
    "        for df in pathData[dset][pheno]: #for each dataframe\n",
    "            for col in df.columns:    #for each column in the dataframe\n",
    "                stdData[dset][pheno][col] = get_hmean_row(df[col])\n",
    "            #break\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdData['imp']['c13popx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filE = '/home/lindb/eckertlab/wbp/piMASS/Final/summary_for_andrew.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(filE,'w') as o:\n",
    "    line = '\\t'.join(['trait','h','hh','p','snp','ar','war','sigma','bf','like','imp_status']) + str('\\n')\n",
    "    o.write(\"%s\" % line)\n",
    "    for dset in stdData.keys():\n",
    "        for pheno in stdData[dset].keys():\n",
    "                line =  str(pheno) + '\\t'+'\\t'.join([str(x) for x in stdData[dset][pheno].values()]) + '\\t' + str(dset) + str('\\n')\n",
    "                print line\n",
    "                o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filE,sep=\"\\t\",header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###pip+beta by SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData = OrderedDict()\n",
    "for dset in mcmcDict.keys():\n",
    "    mcmcData[dset] = OrderedDict()\n",
    "    print '\\t',dset\n",
    "    for pheno in phenos:\n",
    "        print pheno\n",
    "        mcmcData[dset][pheno] = []\n",
    "        DFs =[pd.read_csv(x,sep=\"\\t\") for x in mcmcDict[dset][pheno]]\n",
    "\n",
    "        count = 0\n",
    "        for df in DFs:\n",
    "            df.columns = [\"_\".join([x.strip(),str(count)]) for x in df.columns]\n",
    "            count += 1\n",
    "        mcmcData[dset][pheno] = [x.ix[:,:] for x in DFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcDict['imp']['c13popx'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData['imp']['c13popx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData['imp']['c13popx'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dset in mcmcData.keys():\n",
    "    for pheno in mcmcData[dset].keys():\n",
    "        for df in mcmcData[dset][pheno]:\n",
    "            df.index = df[df.columns[0]].values.tolist()\n",
    "            #mcmcData[dset][pheno] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData['imp']['c13popx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDF = OrderedDict()\n",
    "for dset in mcmcData.keys():\n",
    "    print '\\t',dset\n",
    "    allDF[dset] = OrderedDict()\n",
    "    for pheno in mcmcData[dset].keys():\n",
    "        print pheno\n",
    "        allDF[dset][pheno] = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(mcmcData[dset][pheno][9],mcmcData[dset][pheno][0],left_index=True,right_index=True),mcmcData[dset][pheno][1],left_index=True,right_index=True),mcmcData[dset][pheno][2],left_index=True,right_index=True),mcmcData[dset][pheno][3],left_index=True,right_index=True),mcmcData[dset][pheno][4],left_index=True,right_index=True),mcmcData[dset][pheno][5],left_index=True,right_index=True),mcmcData[dset][pheno][6],left_index=True,right_index=True),mcmcData[dset][pheno][7],left_index=True,right_index=True),mcmcData[dset][pheno][8],left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDF['imp']['c13popx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDF['imp']['c13popx'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pheno in allDF['mis'].keys():\n",
    "    filE = '/home/lindb/eckertlab/wbp/piMASS/Final/allBETASandPIPS/mis_%s_allBETASandPIPS.txt' %pheno\n",
    "    allDF['imp'][pheno].to_csv(filE,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in allDF['imp'].keys():\n",
    "    print pheno\n",
    "    filE = '/home/lindb/eckertlab/wbp/piMASS/Final/allBETASandPIPS/imp_%s_allBETASandPIPS.txt' %pheno\n",
    "    allDF['imp'][pheno].to_csv(filE,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finLST = os.listdir('/home/lindb/eckertlab/wbp/piMASS/Final/allBETASandPIPS')\n",
    "finLST = [os.path.join('/home/lindb/eckertlab/wbp/piMASS/Final/allBETASandPIPS',f) for f in finLST if 'PIP' in f]\n",
    "len(finLST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finLST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = allDF['imp'][pheno]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#start of runfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finLST[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(finLST[10],header=0,index_col=0,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basename = os.path.basename(finLST[10])\n",
    "basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas = df.loc[:,['betarb_9','betarb_8','betarb_7','betarb_6','betarb_5','betarb_4','betarb_3','betarb_2','betarb_1','betarb_0']]\n",
    "pips = df.loc[:,['postrb_9','postrb_8','postrb_7','postrb_6','postrb_5','postrb_4','postrb_3','postrb_2','postrb_1','postrb_0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "betaDict = OrderedDict()\n",
    "row = 0\n",
    "for locus in betas.index:\n",
    "    betaDict[locus] = get_hmean_row(betas.loc[locus,:])\n",
    "    row += 1\n",
    "    if row % 5 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipDict = OrderedDict()\n",
    "row = 0\n",
    "for locus in pips.index:\n",
    "    pipDict[locus] = get_hmean_row(pips.loc[locus,:])\n",
    "    row+=1\n",
    "    if row % 5 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(finLST[0]) + str('/temp')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betafile = os.path.join(path,str(\"beta_\" + os.path.basename(finLST[0])))\n",
    "betafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipfile = os.path.join(path,str(\"pip_\" + os.path.basename(finLST[0])))\n",
    "pipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for locus in betaDict.keys():\n",
    "    print '\\t'.join([locus,str(betaDict[locus])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(betafile,'w') as o:\n",
    "    line = '\\t'.join(['locus','beta']) + str('\\n')\n",
    "    o.write(\"%s\" % line)\n",
    "    for locus in betaDict.keys():\n",
    "        line = '\\t'.join([locus,str(betaDict[locus])]) + str('\\n')\n",
    "        o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betadf = pd.read_csv(betafile,header=0,sep=\"\\t\")\n",
    "betadf.index = betadf['locus'].values.tolist()\n",
    "betadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for locus in pipDict.keys():\n",
    "    print '\\t'.join([locus,str(pipDict[locus])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(pipfile,'w') as o:\n",
    "    line = '\\t'.join(['locus','PIP']) + str('\\n')\n",
    "    o.write(\"%s\" % line)\n",
    "    for locus in pipDict.keys():\n",
    "        line = '\\t'.join([locus,str(pipDict[locus])]) + str('\\n')\n",
    "        o.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipdf = pd.read_csv(pipfile,header=0,sep=\"\\t\")\n",
    "pipdf.index = pipdf['locus'].values.tolist()\n",
    "pipdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(pipdf,betadf,left_index=True,right_index=True)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finLST[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdir = os.path.dirname(finLST[0]) + str('/merged')\n",
    "mdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newbase = basename[:12] + 'SNP_by_BETAandPIP.txt'\n",
    "newbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfile = os.path.join(mdir,newbase) \n",
    "mfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv(mfile,sep=\"\\t\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#end of runfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.dirname(finLST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in finLST:\n",
    "    cmd = '''\n",
    "import vcf\n",
    "import os\n",
    "import pysam\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy as sp\n",
    "\n",
    "print \"defining hmean\"\n",
    "def get_hmean_row(row):\n",
    "    row = row[row != 0]\n",
    "    row = abs(row)\n",
    "    try:\n",
    "        return sp.stats.hmean(row)\n",
    "    except ValueError as e:\n",
    "        return np.nan\n",
    "\n",
    "print \"loading dataframe\"\n",
    "basename = os.path.basename('%s')\n",
    "df = pd.read_csv('%s',header=0,index_col=0,sep=\"\\\\t\")\n",
    "\n",
    "betas = df.loc[:,['betarb_9','betarb_8','betarb_7','betarb_6','betarb_5','betarb_4','betarb_3','betarb_2','betarb_1','betarb_0']]\n",
    "pips = df.loc[:,['postrb_9','postrb_8','postrb_7','postrb_6','postrb_5','postrb_4','postrb_3','postrb_2','postrb_1','postrb_0']]\n",
    "\n",
    "print \"making betaDict\"\n",
    "betaDict = OrderedDict()\n",
    "row = 0\n",
    "for locus in betas.index:\n",
    "    betaDict[locus] = get_hmean_row(betas.loc[locus,:])\n",
    "    row += 1\n",
    "\n",
    "print \"making pipDict\"\n",
    "pipDict = OrderedDict()\n",
    "row = 0\n",
    "for locus in pips.index:\n",
    "    pipDict[locus] = get_hmean_row(pips.loc[locus,:])\n",
    "    row+=1\n",
    "\n",
    "path = os.path.dirname('%s') + str('/temp')\n",
    "print \"path =\",path\n",
    "\n",
    "betafile = os.path.join(path,str(\"beta_\" + os.path.basename('%s')))\n",
    "print \"betafile=\",betafile\n",
    "\n",
    "pipfile = os.path.join(path,str(\"pip_\" + os.path.basename('%s')))\n",
    "print \"pipfile=\",pipfile\n",
    "\n",
    "print \"writing betafile\"\n",
    "with open(betafile,'w') as o:\n",
    "    line = '\\\\t'.join(['locus','beta']) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locus in betaDict.keys():\n",
    "        line = '\\\\t'.join([locus,str(betaDict[locus])]) + str('\\\\n')\n",
    "        o.write(\"%%s\" %% line)\n",
    "betadf = pd.read_csv(betafile,header=0,sep=\"\\\\t\")\n",
    "betadf.index = betadf['locus'].values.tolist()\n",
    "\n",
    "print \"writing pipfile\"\n",
    "with open(pipfile,'w') as o:\n",
    "    line = '\\\\t'.join(['locus','PIP']) + str('\\\\n')\n",
    "    o.write(\"%%s\" %% line)\n",
    "    for locus in pipDict.keys():\n",
    "        line = '\\\\t'.join([locus,str(pipDict[locus])]) + str('\\\\n')\n",
    "        o.write(\"%%s\" %% line)\n",
    "pipdf = pd.read_csv(pipfile,header=0,sep=\"\\\\t\")\n",
    "pipdf.index = pipdf['locus'].values.tolist()\n",
    "\n",
    "merged = pd.merge(pipdf,betadf,left_index=True,right_index=True)\n",
    "\n",
    "mdir = os.path.dirname('%s') + str('/merged')\n",
    "print \"mergedDir=\",mdir\n",
    "\n",
    "newbase = basename[:12] + 'SNP_by_BETAandPIP.txt'\n",
    "print \"new basename =\",newbase\n",
    "\n",
    "mfile = os.path.join(mdir,newbase)\n",
    "print \"merged filename\",mfile\n",
    "\n",
    "merged.to_csv(mfile,sep=\"\\\\t\",header=True,index=False)\n",
    "''' % (f,f,f,f,f,f)\n",
    "    rundir = '/home/lindb/wbp/piMASS/Final/allBETASandPIPS/runfiles/'\n",
    "    fz = os.path.basename(f)[:-4]\n",
    "    fzz = fz + str('_runfile.py')\n",
    "    FILE = os.path.join(rundir,fzz)\n",
    "    with open(FILE,'w') as o:\n",
    "        o.write(cmd)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_qsub_files(f):\n",
    "    fz = os.path.basename(f)\n",
    "    joined = \"_\".join([fz.split(\"_\")[0],fz.split(\"_\")[1]])\n",
    "    with open(\"%s_qsub.sh\" % f[:-3], \"w\") as o:\n",
    "            o.write(\"\"\"#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N %s\n",
    "#$ -cwd\n",
    "python %s\n",
    "\"\"\" % (joined, f))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('/home/lindb/wbp/piMASS/Final/allBETASandPIPS/runfiles/')\n",
    "files = [os.path.join('/home/lindb/wbp/piMASS/Final/allBETASandPIPS/runfiles/',f) for f in files]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    bname = os.path.basename(f)\n",
    "    pheno = \"_\".join(bname.split(\"_\")[0:2])\n",
    "    print bname[:-3]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    bname = os.path.basename(f)\n",
    "    dname = os.path.dirname(f)\n",
    "    pheno = \"_\".join(bname.split(\"_\")[0:2])\n",
    "    text = '''#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N %s\n",
    "#$ -cwd\n",
    "\n",
    "cd %s\n",
    "python %s\n",
    "''' % (pheno,\n",
    "       dname,\n",
    "       bname)\n",
    "    shname = bname[:-3]+'.sh'\n",
    "    filE = os.path.join('/home/lindb/wbp/piMASS/Final/allBETASandPIPS/runfiles/%s') % shname\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runfiles = []\n",
    "for root,dirs,files in os.walk(rundir):\n",
    "    for f in sorted(files):\n",
    "        runfiles.append(os.path.join(root,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in runfiles:\n",
    "    create_qsub_files(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I qsubbed all of these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/home/lindb/eckertlab/wbp/piMASS/Final/merged/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(file_dir,'imp_bffamx_aSNP_by_BETAandPIP.txt'),header=0,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
