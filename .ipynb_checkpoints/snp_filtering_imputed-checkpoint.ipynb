{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/cfriedline/ipynb/wbp/\")\n",
    "sys.path.append(\"/home/cfriedline/ipynb/include_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp /home/cfriedline/ipynb/gypsy_moth/hdfstorehelper.py /home/cfriedline/ipynb/wbp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.parallel import Client\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "from numbapro import autojit\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = \"/gpfs_fs/home/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri as pd2ri\n",
    "pd2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_session():\n",
    "    dill.dump_session(\"session.dill\")\n",
    "    \n",
    "def load_session():\n",
    "    dill.load_session(\"session.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samtools = \"/home/cfriedline/data7/src/samtools-1.2/samtools\"\n",
    "bcftools = \"/home/cfriedline/data7/src/bcftools-1.2/bcftools\"\n",
    "picard = \"/home/cfriedline/data7/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/jdk1.7.0_25/bin/java\"\n",
    "perl = \"/home/cfriedline/data7/opt/ActivePerl-5.16/bin/perl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##some snp analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_file = os.path.join(home, \"samtools_1.2.vcf.gz\")\n",
    "vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcftools = \"/home/cfriedline/data7/src/vcftools_0.1.12b/bin/vcftools\"\n",
    "vcftools2 = \"/home/cfriedline/data7/src/vcftools-code/trunk/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/data7/src/bcftools-1.2/bcftools\"\n",
    "tabix = \"/home/cfriedline/data7/src/samtools-1.2/htslib-1.2.1/tabix\"\n",
    "bgzip = \"/home/cfriedline/data7/src/samtools-1.2/htslib-1.2.1//bgzip\"\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.2/vcfutils.pl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcftools \\\n",
    "--remove-indels \\\n",
    "--min-alleles 2 \\\n",
    "--max-alleles 2 \\\n",
    "--max-missing 0.5 \\ \n",
    "--mac 1 \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--gzvcf \\\n",
    "$vcf_file \\\n",
    "--out $vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcf_filtered = \"%s.recode.vcf\" % vcf_file\n",
    "vcf_filtered_gz = \"%s.gz\" % vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!bgzip -c $vcf_filtered > {vcf_filtered_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tabix {vcf_filtered_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp = []\n",
    "qual = []\n",
    "mq = []\n",
    "reader = vcf.VCFReader(filename=vcf_filtered_gz)\n",
    "for i, rec in enumerate(reader):\n",
    "    dp.append(rec.INFO['DP']) #combined depth across samples\n",
    "    mq.append(rec.INFO['MQ'])a #mapping quality\n",
    "    qual.append(rec.QUAL) #phred-scaled quality score\n",
    "    if i % 10000 == 0:\n",
    "        print \"at %d\" % i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual = pd.Series(qual)\n",
    "qual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dp = pd.Series(dp)\n",
    "dp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mq = pd.Series(mq)\n",
    "mq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcf_varfilter = \"%s_filtered.vcf\" % vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcfutils varFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcfutils varFilter -Q 10 -D 700 {vcf_filtered} > {vcf_varfilter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcf_varfilter_gz = \"%s.gz\" % vcf_varfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$bgzip -c $vcf_varfilter > $vcf_varfilter_gz\n",
    "!$tabix $vcf_varfilter_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_varfilter_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_vcf = os.path.join(analysis_dir, \"snps.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reader = vcf.VCFReader(filename=vcf_varfilter_gz)\n",
    "#start only with true SNPs ()\n",
    "with open(snp_vcf, \"w\") as o:\n",
    "    writer = vcf.VCFWriter(o, reader)\n",
    "    for i, rec in enumerate(reader):\n",
    "        if len(rec.REF) == 1:\n",
    "            writer.write_record(rec)\n",
    "        if i % 1000 == 0:\n",
    "            print \"at %d\" % i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!zcat $vcf_varfilter_gz | grep -c -v '^#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snp_vcf_gz = \"%s.gz\" % snp_vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$bgzip -c $snp_vcf > $snp_vcf_gz\n",
    "!$tabix $snp_vcf_gz\n",
    "!zcat $snp_vcf_gz | grep -c -v '^#'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Impute missing data with BEAGLE\n",
    "\n",
    "```bash\n",
    "java -jar ~/g/src/BEAGLE4/beagle.r1399.jar \\\n",
    "gtgl=snps.vcf.gz \\\n",
    "out=imputed \\\n",
    "nthreads=50\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_vcf = os.path.join(analysis_dir, \"imputed.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(imputed_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcftools --012 \\\n",
    "--gzvcf \\\n",
    "$imputed_vcf \\\n",
    "--out $imputed_vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcftools --012 \\\n",
    "--gzvcf \\\n",
    "$snp_vcf_gz \\\n",
    "--out $snp_vcf_gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popdata = pd.read_excel(\"WBP_IDS_MATCHED_POP_PMEDIT2015_AJE_pid_only.xlsx\")\n",
    "phenodata = pd.read_excel(\"WBP_IDS_MATCHED_POP_FINAL_05182015.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popdata = popdata.merge(phenodata, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_sample_name(row):\n",
    "    return \"%scompiled_sorted\" % str(row.ID_x).rjust(3, \"0\")\n",
    "popdata['sample_name'] = popdata.apply(add_sample_name, axis=1)\n",
    "popdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenocols = phenodata.columns[-10:]\n",
    "popdatacols = ['sample_name', 'Population_ID_x', 'Plot_id_x']\n",
    "popdatacols.extend(phenocols)\n",
    "popdata = popdata[popdatacols]\n",
    "found = set()\n",
    "drop = []\n",
    "for idx, row in popdata.iterrows():\n",
    "    if not row.sample_name in found:\n",
    "        found.add(row.sample_name)\n",
    "    else:\n",
    "        drop.append(idx)\n",
    "popdata = popdata.drop(drop)\n",
    "popdata = popdata.set_index(\"sample_name\")\n",
    "popdata['popplot'] = popdata.apply(lambda x: \"%s-%d\" % (x.Population_ID_x, x.Plot_id_x), axis=1)\n",
    "popdata.columns = [x.replace(\"_x\", \"\") for x in popdata.columns]\n",
    "popdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## snp filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hdfstorehelper import HDFStoreHelper\n",
    "hdf = HDFStoreHelper(\"wbp_samtools_imputed.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('popdata', popdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#z12_file = os.path.join(analysis_dir, \"%s.012\" % snp_vcf_gz)\n",
    "z12_file = os.path.join(analysis_dir, \"%s.012\" % imputed_vcf)\n",
    "assert os.path.exists(z12_file)\n",
    "z12_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_z12_df(z12):\n",
    "    data = []\n",
    "    for i, line in enumerate(open(z12)):\n",
    "        line = line.strip()\n",
    "        line = [int(x) for x in line.split(\"\\t\")]\n",
    "        data.append(np.array(line))\n",
    "        if i % 10 == 0:\n",
    "            print i\n",
    "    data = np.array(data)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.drop(0, axis=1)\n",
    "    df.columns = pd.Series(df.columns)-1\n",
    "    indv = \"%s.indv\" % z12\n",
    "    names = [x.strip() for x in open(indv).readlines()]\n",
    "    df.index=names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df =  get_z12_df(z12_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"z12_df\", z12_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(z12_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_percent_missing(col):\n",
    "    return len(col[col==-1])*1.0/len(col)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time percent_missing = z12_df.apply(get_percent_missing, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('percent_missing', percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing[percent_missing > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc = z12_df.ix[:,percent_missing <= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc', z12_df_50_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_monomorphic(col):\n",
    "    u = col[col != -1].value_counts()\n",
    "    if len(u) == 1:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time monomorphic_loci = z12_df_50_perc.apply(is_monomorphic, axis=0)\n",
    "monomorphic_loci = monomorphic_loci[monomorphic_loci==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(monomorphic_loci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic = z12_df_50_perc.drop(monomorphic_loci.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic', z12_df_50_perc_polymorphic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic', z12_df_50_perc_polymorphic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "        ref = 0\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "        alt = 1\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    counts = [P,Q]\n",
    "    freqs = [p,q]\n",
    "    ret = pd.Series({\"p\":freqs[0], \n",
    "                      \"q\":freqs[1],\n",
    "                      \"P\":counts[0],\n",
    "                      \"Q\":counts[1],\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time allele_freqs = z12_df_50_perc_polymorphic.apply(get_allele_freqs, debug=False)\n",
    "mafs = allele_freqs.apply(lambda x: min(x[\"p\"], x[\"q\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('allele_freqs', allele_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs = hdf.get(\"allele_freqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf = z12_df_50_perc_polymorphic.drop(mafs[mafs<0.01].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic_maf', z12_df_50_perc_polymorphic_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_fis = allele_freqs[z12_df_50_perc_polymorphic_maf.columns].apply(lambda x: x[\"Fis\"])\n",
    "fis_outliers = global_fis[(global_fis < -0.5) | (global_fis > 0.5)]\n",
    "z12_df_50_perc_polymorphic_maf_fis = z12_df_50_perc_polymorphic_maf.drop(fis_outliers.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf_fis[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic_maf_fis', z12_df_50_perc_polymorphic_maf_fis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df = z12_df_50_perc_polymorphic_maf_fis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "working_df.to_csv(os.path.join(analysis_dir,\n",
    "                               \"z12_df_50_perc_polymorphic_maf_fis.txt\"),\n",
    "                                          header=True,\n",
    "                                          index=True,\n",
    "                                          sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df = hdf.get('z12_df_50_perc_polymorphic_maf_fis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_trans = {'NA':-1, '11':0, '12':1, '22':2}\n",
    "def convert_to_z12(col):\n",
    "    return [z12_trans[x] if x == 'NA' else z12_trans[str(int(x))] for x in col]\n",
    "\n",
    "hierf_trans = {0:'11', 1:'12', 2:'22', -1:'NA'}\n",
    "def apply_hierf_trans(series):\n",
    "    return [hierf_trans[x] for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.columns = [\"L%d\" % x for x in working_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_to_drop = set(working_df.index)-set(popdata.index)\n",
    "working_df=working_df.drop(samples_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swap_alleles(locus):\n",
    "    if locus.name.startswith(\"L\"):\n",
    "        locus_id = int(locus.name[1:]) #drop the L and convert\n",
    "        #locus_id = locus.name\n",
    "        freqs = allele_freqs[locus_id]\n",
    "        minor = min(freqs[\"P\"], freqs[\"Q\"])\n",
    "        if minor == freqs[\"P\"]:\n",
    "            return locus.replace({0:2,2:0})\n",
    "        return locus\n",
    "    else:\n",
    "        return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time z12_swapped = working_df.apply(swap_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"z12_swapped\", z12_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_final = pd.DataFrame(z12_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_final', z12_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_all = pd.read_csv(\"%s.012.pos\" % snp_vcf_gz, sep=\"\\t\", \n",
    "                      header=None,\n",
    "                     names=[\"contig\", \"pos\"])\n",
    "pos_all.index = [\"L%d\" % x for x in pos_all.index]\n",
    "pos_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_good = pos_all.ix[z12_final.columns, :]\n",
    "pos_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_good.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = z12_final.apply(apply_hierf_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('hierf_trans_df', hierf_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = hdf.get('hierf_trans_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id = {}\n",
    "i = 1\n",
    "for p in sorted(popdata.Population_ID.unique()):\n",
    "    pop_id[p] = i\n",
    "    i+=1\n",
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_id = {}\n",
    "i = 1\n",
    "for p in sorted(popdata.popplot.unique()):\n",
    "    plot_id[p] = i\n",
    "    i+=1\n",
    "plot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_popid(row):\n",
    "    if row.name in popdata.index:\n",
    "        return pop_id[popdata.ix[row.name, 'Population_ID']]\n",
    "    return None\n",
    "\n",
    "def get_plotid(row):\n",
    "    if row.name in popdata.index:\n",
    "        try:\n",
    "            return plot_id[popdata.ix[row.name, 'popplot']]\n",
    "        except:\n",
    "            print row.name\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popids = hierf_trans_df.apply(get_popid, axis=1)\n",
    "plotids = hierf_trans_df.apply(get_plotid, axis=1)\n",
    "hierf_trans_df['popid'] = popids\n",
    "hierf_trans_df['plotid'] = plotids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "hierf_trans_df.to_csv(\"hierf_trans_df.txt\", header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "hierf_trans_df = pd.read_csv(\"hierf_trans_df.txt\", header=0, index_col=0, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('hierf_trans_df', hierf_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = hdf.get('hierf_trans_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['popid', 'plotid']\n",
    "# cols.extend(hierf_trans_df.columns[:-3])\n",
    "cols.extend([x for x in hierf_trans_df.columns if x.startswith(\"L\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2 = hierf_trans_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.popid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2 = hierf_trans_df2.sort([\"popid\", \"plotid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('hierf_trans_df2', hierf_trans_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write out hierfstat input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.ix[:,'popid'].to_csv(\"wbp_pops.txt\", \n",
    "                                     sep=\"\\t\",\n",
    "                                    header=False,\n",
    "                                    index=True)\n",
    "hierf_trans_df2.to_csv(\"hierfstat_samtools_imputed.txt\", header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put into R (because it's slow)\n",
    "\n",
    "```R\n",
    "\n",
    "get_varcomp = function(x) {\n",
    "    library(hierfstat)\n",
    "    loci = data.frame(x)\n",
    "    res <- varcomp(cbind(levels, loci),diploid=T)$overall\n",
    "}\n",
    "\n",
    "finish_varcomp = function(m) {\n",
    "    tot <- apply(m, 2, sum, na.rm = TRUE)\n",
    "    nblevels <- length(tot)\n",
    "    f <- matrix(rep(0, (nblevels - 1)^2), ncol = (nblevels -\n",
    "                                                      1))\n",
    "    for (i in 1:(nblevels - 1)) {\n",
    "        for (j in i:(nblevels - 1)) {\n",
    "            f[i, j] <- sum(tot[i:j])/sum(tot[i:nblevels])\n",
    "        }\n",
    "    }\n",
    "    row.names(m) <- lnames\n",
    "    print(names(tot))\n",
    "    tf <- t(f)\n",
    "    row.names(tf) <- fnames\n",
    "    f <- t(tf)\n",
    "    row.names(f) <- c(\"Total\", fnames[-length(fnames)])\n",
    "    return(list(loc = m, overall = tot, F = f))\n",
    "}\n",
    "\n",
    "\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "data = data.frame(fread(\"hierfstat_samtools_imputed.txt\", header=T, sep=\"\\t\"))\n",
    "levels = data.frame(data[,1:2])\n",
    "loci = data[,3:ncol(data)]\n",
    "lnames=names(loci)\n",
    "fnames=c(names(levels), \"Ind\")\n",
    "cl = makeSOCKcluster(50)\n",
    "clusterExport(cl, \"levels\", envir=environment())\n",
    "system.time(res <- matrix(parCapply(cl, loci, get_varcomp), nrow=length(names(loci)),byrow=T))\n",
    "res = finish_varcomp(res)\n",
    "saveRDS(res, \"hierfstat_samtools_imputed.rds\")\n",
    "system.time(bs <- basic.stats(data))\n",
    "saveRDS(bs, \"bs_samtools_imputed.rds\")\n",
    "stopCluster(cl)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write out good snps and samples to VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_pos = pd.read_csv(\"imputed.vcf.gz.012.pos\", sep=\"\\t\", header=None, names=[\"contig\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snp_names = hierf_trans_df2.columns[2:]\n",
    "good_snp_names_df = pd.DataFrame()\n",
    "good_snp_names_df['snp_name'] = good_snp_names\n",
    "good_snp_names_df['idx'] = good_snp_names_df.apply(lambda x: int(x.snp_name[1:]), axis=1)\n",
    "good_snp_names_df = good_snp_names_df.set_index(\"idx\")\n",
    "good_snp_names_df.index.name = None\n",
    "good_snp_names_df = good_snp_names_df.merge(z12_pos, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snp_names_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snp_names_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = vcf.Reader(filename=\"imputed.vcf.gz\")\n",
    "with open(\"good_snps.vcf\", \"w\") as o:\n",
    "    writer = vcf.Writer(o, reader)\n",
    "    for row, data in good_snp_names_df.iterrows():\n",
    "        snps = reader.fetch(data.contig, data.pos-1, data.pos)\n",
    "        for snp in snps:\n",
    "            writer.write_record(snp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"good_samples.txt\", \"w\") as o:\n",
    "    o.writelines(\"\\n\".join([x for x in popdata.index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "bgzip -c good_snps.vcf > good_snps.vcf.gz\n",
    "\n",
    "perl ~/g/src/vcftools_0.1.12b/bin/vcf-subset -c good_samples.txt good_snps.vcf.gz > good_snps_good_samples.vcf\n",
    "\n",
    "bgzip -c good_snps_good_samples.vcf > good_snps_good_samples.vcf.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_r_series(key):\n",
    "    s = pd.Series(get_r(key))\n",
    "    s.index = get_r(\"names(%s)\" % key)\n",
    "    return s\n",
    "\n",
    "def get_r_df(key):\n",
    "    df = pd.DataFrame(get_r(key))\n",
    "    try:\n",
    "        rname = get_r(\"rownames(%s)\" % key)\n",
    "        df.index = rname\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        cname = get_r(\"colnames(%s)\" % key)\n",
    "        df.columns = cname\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_r(key):\n",
    "    return pd2ri.ri2py(r(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res = readRDS(\"/gpfs_fs/home/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/hierfstat_samtools_imputed.rds\")\n",
    "bs = readRDS(\"/gpfs_fs/home/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/bs_samtools_imputed.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_df = get_r_df('res$loc')\n",
    "F_df = get_r_df('res$F')\n",
    "overall_df = get_r_df('res$overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Hs = series[0]+series[1]\n",
    "    Ht = sum(series)\n",
    "    return Hs/Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst = loc_df.apply(compute_fst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"loci_fst\", loci_fst) #still put into wbp_samtools_imputed.hd5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(loci_fst, bins=20)\n",
    "plt.title(\"n=%d mean=%.2f +/- %.2f [%.2f, %.2f]\" % (len(loci_fst), \n",
    "                                                    np.mean(loci_fst), \n",
    "                                                    np.std(loci_fst),\n",
    "                                                    np.min(loci_fst), \n",
    "                                                    np.max(loci_fst)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time hierf_z12 = hierf_trans_df2.ix[:,2:].apply(convert_to_z12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"hierf_z12\", hierf_z12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_z12.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Prcomp PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_maf = pd.DataFrame(hierf_z12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_maf', pca_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_maf = hdf.get('pca_maf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pca_maf.to_csv(\"pca_maf.txt\", sep=\"\\t\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_maf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs.ix[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)\n",
    "\n",
    "def center_and_standardize(locus):\n",
    "    if locus.name.startswith(\"L\"):\n",
    "        locus_id = int(locus.name[1:])\n",
    "        #locus_id = locus.name\n",
    "        freqs = allele_freqs[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time pca_std = pca_maf.apply(center_and_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std', pca_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std = hdf.get('pca_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data = pd.DataFrame(pca_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_snps = pd.DataFrame(pca_std_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std_data', pca_std_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std_data_snps', pca_std_data_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data_snps = hdf.get('pca_std_data_snps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp = r('prcomp')\n",
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_snps.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pca_std_data_snps.to_csv(\"pca_std_data_snps.txt\", header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time prcomp_res = prcomp(pca_std_data_snps, scale=False, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r('saveRDS')(prcomp_res, \"prcomp_res_imputed.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print summary(prcomp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data = hdf.get(\"pca_std_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd2ri.ri2py_dataframe(prcomp_res.rx2(\"x\"))\n",
    "x.index = pca_std_data.index\n",
    "x.columns = prcomp_res.rx2(\"x\").names.rx2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = x.join(pca_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popids.name=\"popid\"\n",
    "plotids.name=\"plotid\"\n",
    "joined = pd.concat([joined, popids, plotids, popdata], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('joined', joined)\n",
    "hdf.put('x', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = hdf.get(\"joined\")\n",
    "pca_std_data = hdf.get('pca_std_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "legend = {}\n",
    "for row, data in joined.iterrows():\n",
    "    pop = data['Population_ID']\n",
    "    n = norm(pop_id[pop])\n",
    "    color = cm.rainbow(n)\n",
    "    legend[pop] = color\n",
    "    plt.scatter(data.PC1, \n",
    "                data.PC2, \n",
    "                s=50, \n",
    "                c=color)\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "cmap = plt.get_cmap()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.title(\"PCA of n=%d samples on %d loci\" % (len(joined), len(pca_std_data.columns)))\n",
    "#0.05294  0.01079\n",
    "plt.xlabel(\"PC1 (5.294%)\")\n",
    "plt.ylabel(\"PC2 (1.079%)\")\n",
    "\n",
    "handles = []\n",
    "for pop in sorted(legend):\n",
    "    handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "plt.legend(handles=sorted(handles), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snps_df = get_z12_df(\"snps.vcf.gz.012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snps_df = snps_df[[int(x[1:]) for x in pca_std_data_snps.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snps_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = snps_df.apply(lambda x: x.value_counts(), axis=1)\n",
    "counts = pd.DataFrame(counts)\n",
    "counts.columns = [str(x) for x in counts.columns]\n",
    "counts['missing'] = counts.apply(lambda x: x[\"-1\"]/np.sum(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(counts['missing'], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_missing = joined.join(counts, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_missing[joined_missing.missing>0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pc in [\"PC1\", \"PC2\"]:\n",
    "    plt.scatter(joined_missing.missing, joined_missing[pc])\n",
    "    plt.xlabel(\"missing in sample\")\n",
    "    plt.ylabel(pc)\n",
    "    plt.title(\"%d samples/%d snps\" % (len(joined_missing),\n",
    "                                     snps_df.shape[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PC-AiR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_maf = hdf.get(\"pca_maf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_maf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(GENESIS)\n",
    "library(SNPRelate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###GENESIS\n",
    "\n",
    "http://www.bioconductor.org/packages/release/bioc/vignettes/GENESIS/inst/doc/pcair.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(SNPRelate)\n",
    "snpgdsVCF2GDS(\"good_snps_good_samples.vcf.gz\", \"snprelate_imputed.gds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Write KING files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_vcf = \"good_snps_good_samples.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_pos = pd.read_csv(\"imputed.vcf.gz.012.pos\", sep=\"\\t\", header=None, names=[\"contig\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_pos['snp'] = [\"L%d\" % x for x in z12_pos.index]\n",
    "contigs = sorted(z12_pos.contig.unique())\n",
    "contig_num = {x:i for i, x in enumerate(contigs)}\n",
    "z12_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "vcftools --gzvcf good_snps_good_samples.vcf.gz --out good_snps_good_samples.vcf.gz --plink\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pospanel = z12_pos.set_index([\"contig\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_marker_name(row):\n",
    "    return pospanel.ix[row.contig,row.pos].snp\n",
    "\n",
    "\n",
    "pm = pd.read_csv(\"good_snps_good_samples.vcf.gz.map\",\n",
    "                header=None,\n",
    "                sep=\"\\t\",\n",
    "                names=[\"chrom\",\"contig\",\"gd\",\"pos\"])\n",
    "pm.contig = pm.contig.apply(lambda x: x.split(\":\")[0])\n",
    "pm.chrom = pm.contig.apply(lambda x: contig_num[x])\n",
    "pm['marker'] = pm.apply(get_marker_name, axis=1)\n",
    "pm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm = pm[['chrom', 'marker', 'gd', 'pos']]\n",
    "pm.to_csv(\"imputed.map\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pedfile = \"good_snps_good_samples.vcf.gz.ped\"\n",
    "peddata = []\n",
    "for i, line in enumerate(open(pedfile)):\n",
    "    line = line.strip().split()\n",
    "    peddata.append(line)\n",
    "    if i % 10 == 0:\n",
    "        print \"at %d\" % i\n",
    "peddata = np.array(peddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ped = pd.DataFrame(peddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pedcols = ped.columns.tolist()\n",
    "pedcols[0] = \"family\"\n",
    "pedcols[1] = \"sample\"\n",
    "pedcols[2] = \"father\"\n",
    "pedcols[3] = \"mother\"\n",
    "pedcols[4] = \"sex\"\n",
    "pedcols[5] = \"phenotype\"\n",
    "\n",
    "snpcols = []\n",
    "for x in pm.marker:\n",
    "    snpcols.append(x+\"_1\")\n",
    "    snpcols.append(x+\"_2\")\n",
    "pedcols[6:] = snpcols\n",
    "ped.columns = pedcols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ped.family = ped['sample'].apply(lambda x: popdata.ix[x, 'Population_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ped.to_csv(\"imputed.ped\",\n",
    "          sep=\"\\t\",\n",
    "          header=False,\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have both `imputed.map` and `.ped` files, we can create a bed file for \n",
    "input into `KING`.\n",
    "\n",
    "First,\n",
    "\n",
    "```bash\n",
    "~/g/src/plink-1.07-x86_64/plink --noweb --file imputed --make-bed\n",
    "```\n",
    "\n",
    "Next,\n",
    "\n",
    "```\n",
    "~/g/src/king-1.4/king -b plink.bed --kinship --prefix king_imputed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "gdsfile = \"snprelate_imputed.gds\"\n",
    "geno <- GdsGenotypeReader(filename = gdsfile)\n",
    "genoData <- GenotypeData(geno)\n",
    "iids = getScanID(genoData)\n",
    "KINGmat <- king2mat(\"king_imputed.kin0\", \"king_imputed.kin\",iids=iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "kt = 0.025\n",
    "pcair_res=pcair(genoData = genoData, \n",
    "          kinMat = KINGmat, \n",
    "          divMat = KINGmat,\n",
    "          kin.thresh=kt,\n",
    "          v=NULL,\n",
    "          MAF=0,\n",
    "          snp.include=getSnpID(genoData), verbose=T,\n",
    "          scan.include=rownames(KINGmat))\n",
    "\n",
    "values = pcair_res$values\n",
    "tot = sum(values)\n",
    "var_exp = lapply(values, function(x) x/tot)\n",
    "v = round(unlist(var_exp), 4)\n",
    "print(unlist(var_exp)[1:5])\n",
    "pc1 = pcair_res$vectors[,1]\n",
    "pc2 = pcair_res$vectors[,2]\n",
    "plot(pcair_res, main=paste(kt, \"/\", v[1], \"/\", v[2], \"/\", length(pcair_res$rels), \"/\", length(pcair_res$unrels)))\n",
    "print(summary(pcair_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R close(geno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tw_calc_cjf.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "tw=TWcalc(pcair_res$values,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_p = pd2ri.ri2py_vector(r(\"tw[[2]]\"))\n",
    "tw_e = pd2ri.ri2py_vector(r(\"tw[[1]]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num = 0\n",
    "for i, p in enumerate(tw_p):\n",
    "    print p\n",
    "    if p > 0.05:\n",
    "        tw_num = i\n",
    "        break\n",
    "print \"Tracy-Widom test yields %d axes of pop structure\" % tw_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0.012288293\n",
    "    0.055779577\n",
    "    Tracy-Widom test yields 1 axes of pop structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectors = pd2ri.ri2py_dataframe(r('pcair_res$vectors'))\n",
    "vectors.index = r('rownames(pcair_res$vectors)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov = x.ix[:,0:tw_num-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_cov', pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno['sample_id'] = pheno.apply(lambda x: \"%s_0\" % x.sample_pheno, axis=1)\n",
    "pheno.index = pheno['sample_id']\n",
    "pheno = pheno.drop('sample_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = popdata.ix[:,2:].join(pca_cov, how=\"inner\").join(pca_maf, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std_pheno', pca_std_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = vcf.VCFReader(filename=os.path.join(analysis_dir, \"good_snps_good_samples.vcf.gz\"))\n",
    "\n",
    "\n",
    "gt_base_data = {}\n",
    "for i, row in enumerate(pos_good.iterrows()):\n",
    "    snp_id = row[0]\n",
    "    snps = reader.fetch(row[1].contig, row[1].pos-1, row[1].pos)\n",
    "    for snp in snps:\n",
    "        for sample in snp.samples:\n",
    "            if not snp_id in gt_base_data:\n",
    "                gt_base_data[snp_id] = {}\n",
    "            sample_name = sample.sample\n",
    "            gt_base_data[snp_id][sample_name] = sample.gt_bases\n",
    "    if i % 1000 == 0:\n",
    "        print i\n",
    "gt_base_df = pd.DataFrame(gt_base_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in gt_base_df.ix[:,0:30]:\n",
    "    print col, gt_base_df[col].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('gt_base_df', gt_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df=hdf.get('gt_base_df')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "gt_base_df.to_csv(\"gt_base_df.csv\", header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "gt_base_df = pd.read_csv(\"gt_base_df.csv\", index_col=0, sep=\"\\t\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(SNPassoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno=phenodata\n",
    "phenodata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_cols = pheno.columns[-10:].tolist()\n",
    "pheno_cols.extend(gt_base_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base = popdata.merge(gt_base_df, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base = pheno_gt_base[pheno_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno_gt_base', pheno_gt_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = r('scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenotypes = pheno_gt_base.ix[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_pheno = pd2ri.ri2py_dataframe(scale(phenotypes, center=True, scale=True))\n",
    "scaled_pheno.columns = phenotypes.columns\n",
    "scaled_pheno.index = phenotypes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca = pd.DataFrame(pheno_gt_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.ix[:,0:10] = scaled_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca = pheno_gt_base.merge(pca_cov, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.ix[:,0:10].apply(np.mean),pheno_gt_base_pca.ix[:,0:10].apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno_gt_base_pca', pheno_gt_base_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca=hdf.get('pheno_gt_base_pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = pheno_gt_base_pca.columns.tolist()\n",
    "cols[-1] = \"PC1\"\n",
    "pheno_gt_base_pca.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def snpassoc_filter(col):\n",
    "    if col.name.startswith(\"L\"):\n",
    "        if len(col.value_counts()) == 3:\n",
    "            return col.fillna(\"NA\")\n",
    "    else:\n",
    "        return col\n",
    "pheno_gt_base_pca_snpassoc = pheno_gt_base_pca.apply(snpassoc_filter).dropna(how=\"all\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca_snpassoc.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pheno_gt_base_pca_snpassoc.to_csv(\"pheno_gt_base_pca_snpassoc.txt\",\n",
    "                         header=True,\n",
    "                         index=True,\n",
    "                         sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snpassoc_input_file = \"pheno_gt_base_pca_snpassoc_imputed.txt\"\n",
    "pheno_gt_base_pca_snpassoc.to_csv(snpassoc_input_file,\n",
    "                         header=True,\n",
    "                         index=True,\n",
    "                         sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_snpassoc_files(df, input_file, num_pca_axes):\n",
    "    pheno = df.columns[0:10]\n",
    "    out_files = []\n",
    "    for p in pheno:\n",
    "        with open(\"snpassoc_%s_imputed.R\" % p.lower(), \"w\") as o:\n",
    "            print \"writing %s\" % o.name\n",
    "            out_files.append(o.name)\n",
    "            text = '''\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('%s', sep=\"\\\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 11:(ncol(d)-%d)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"\\\\\\\\|\")\n",
    "pca_cols = (ncol(d)-%d):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(%s~1+pca_data$PC1, data=snp_data, model=\"co\", genotypingRate=5)\n",
    "saveRDS(wg, \"wg_%s_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"wgstats_%s.rds\")\n",
    "''' % (input_file, \n",
    "       num_pca_axes,\n",
    "       num_pca_axes-1,\n",
    "       p, \n",
    "       p.lower(), \n",
    "       p.lower())\n",
    "        \n",
    "            o.write(text)\n",
    "    return out_files\n",
    "\n",
    "snpassoc_files = write_snpassoc_files(pheno_gt_base_pca_snpassoc, \n",
    "                          snpassoc_input_file,\n",
    "                         1)\n",
    "\n",
    "with open(\"snpassoc_jobs_imputed.txt\", \"w\") as o:\n",
    "    for f in snpassoc_files:\n",
    "        o.write(\"R CMD BATCH %s\\n\" % f)\n",
    "snpassoc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat snpassoc_ht_pop_imputed.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```R\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('pheno_gt_base_pca_snpassoc.txt', sep=\"\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-10)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-9):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(Mass~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9+pca_data$PC10, data=snp_data, model=\"co\", genotypingRate=5)\n",
    "saveRDS(wg, \"wg_mass_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"wgstats_mass.rds\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "wg_mass_co = readRDS(\"wg_mass_co.rds\")\n",
    "wg_pd_co = readRDS(\"wg_pupual_duration_co.rds\")\n",
    "wg_tdt_co = readRDS(\"wg_total_dev_time_co.rds\")\n",
    "\n",
    "wgstats_mass = readRDS(\"wgstats_mass.rds\")\n",
    "wgstats_pd = readRDS(\"wgstats_pupual_duration.rds\")\n",
    "wgstats_tdt = readRDS(\"wgstats_total_dev_time.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wgstats_mass = r['wgstats_mass']\n",
    "wgstats_mass_labels = r('labels(wg_mass_co)')\n",
    "\n",
    "wgstats_pd = r['wgstats_pd']\n",
    "wgstats_pd_labels = r('labels(wg_pd_co)')\n",
    "\n",
    "wgstats_tdt = r['wgstats_tdt']\n",
    "wgstats_tdt_labels = r('labels(wg_tdt_co)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = com.convert_robj(wgstats_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in test:\n",
    "    print pd.DataFrame(test[x])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_vals = {}\n",
    "\n",
    "wgstats = {\"mass\":[wgstats_mass, wgstats_mass_labels.rx2(1)],\n",
    "           \"pd\":[wgstats_pd, wgstats_pd_labels.rx2(1)],\n",
    "           \"tdt\":[wgstats_tdt, wgstats_tdt_labels.rx2(1)]}\n",
    "\n",
    "for key, datalist in wgstats.items():\n",
    "    print \"converting %s\" % key\n",
    "    wgstats[key] = [com.convert_robj(x) for x in datalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_alleles(data):\n",
    "    a = set()\n",
    "    for x in data.index:\n",
    "        for elem in x.split(\"/\"):\n",
    "            a.add(elem)\n",
    "    return list(a)  \n",
    "\n",
    "def get_allele_freqs_wg(data, AA, Aa, aa):\n",
    "    total = np.sum(data['n'])*2\n",
    "    A = data.ix[AA, \"n\"]*2 + data.ix[Aa, \"n\"]\n",
    "    a = data.ix[aa, \"n\"]*2 + data.ix[Aa, \"n\"]\n",
    "    return A/total, a/total\n",
    "\n",
    "def get_genotypes(data, alleles):\n",
    "    homos = [\"%s/%s\" % (x,x) for x in alleles]\n",
    "    Aa = \"%s/%s\" % (alleles[0], alleles[1])\n",
    "    if Aa not in data.index:\n",
    "        Aa = Aa[::-1] #reverse it\n",
    "    AA, aa = homos\n",
    "    if data.ix[AA, \"n\"] < data.ix[aa, \"n\"]:\n",
    "        AA, aa = homos[::-1] #reverse it so that major is first\n",
    "    return AA, Aa, aa\n",
    "\n",
    "def get_genotypic_values(data, alleles):\n",
    "    AA, Aa, aa = get_genotypes(data, alleles)\n",
    "    G_AA = float(data.ix[AA, 'me'])\n",
    "    G_aa = float(data.ix[aa, 'me'])\n",
    "    additive = (G_AA-G_aa)/2\n",
    "    G_Aa = float(data.ix[Aa, 'me'])\n",
    "    dominance = G_Aa - ((G_AA+G_aa)/2)\n",
    "    return additive, dominance, AA, Aa, aa\n",
    "    \n",
    "def get_alpha(data):\n",
    "    alleles = get_alleles(data)\n",
    "    additive, dominance, AA, Aa, aa = get_genotypic_values(data, alleles)\n",
    "    p, q = get_allele_freqs_wg(data, AA, Aa, aa)\n",
    "    alpha = additive + (dominance*(q-p))\n",
    "    return alpha, AA, aa, p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lt3 = {}\n",
    "errors = {}\n",
    "for p in wgstats:\n",
    "    print \"running %s\" % p\n",
    "    df = pd.DataFrame(index=[\"alpha\", \"p-value\", \"AA\", \"aa\", \"p\", \"q\"])\n",
    "    alpha_vals[p] = df\n",
    "    lt3[p] = 0\n",
    "    errors[p] = []\n",
    "    d = wgstats[p][0]\n",
    "    labels = wgstats[p][1]\n",
    "    for i, locus in enumerate(d):\n",
    "        try:\n",
    "            data = pd.DataFrame(d[locus])\n",
    "            snp = labels[i]\n",
    "            genotypes = [g for g in data.index if \"/\" in g]\n",
    "            data = data.ix[genotypes,:]\n",
    "            pvalue = data['p-value'].dropna()[0]\n",
    "            if len(genotypes) == 3:\n",
    "                alpha, AA, aa, p, q = get_alpha(data)\n",
    "                df[snp] = [alpha, pvalue, AA, aa, p, q]\n",
    "            elif len(genotypes) < 3:\n",
    "                lt3[p] += 1\n",
    "        except Exception as e: #needed for genotypes that are skipped b/c of genotyping rate\n",
    "            traceback.print_exc()\n",
    "            errors[p].append(data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_vals['mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(alpha_vals['mass'].ix['alpha',:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write Berg/Coop files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = {}\n",
    "for pop, data in pca_maf.groupby('population'):\n",
    "    data = data.ix[:,:-2]\n",
    "    pop_allele_freqs[pop] = data.apply(get_allele_freqs, args=(True,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = pca_maf.apply(get_percent_missing)\n",
    "missing = DataFrame(missing)\n",
    "missing.columns = [\"missing\"]\n",
    "missing[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_gwas_data_file(df, pheno, outdir):\n",
    "    out = \"%s_gwas_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    df = df.sort_index()\n",
    "    df[['A1', 'A2', 'EFF', 'FRQ']].to_csv(out,\n",
    "                                          header=True, \n",
    "                                          index=True,\n",
    "                                          sep=\"\\t\")\n",
    "    print out\n",
    "    return out\n",
    "\n",
    "def write_freqs_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_freqs_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in pop_freqs.items():\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))\n",
    "def write_match_pop_file(df, pheno, pop_freqs, pop, outdir):\n",
    "    out = \"%s_match_pop_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for key, data in pop_freqs.items():\n",
    "            if key == pop:\n",
    "                m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "                m['population'] = pop\n",
    "                m.index.name = 'SNP'\n",
    "                m = m.sort_index()\n",
    "                o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                                 index=True,\n",
    "                                                                 sep=\"\\t\"))\n",
    "                break\n",
    "                \n",
    "def write_full_dataset_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_full_dataset_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in pop_freqs.items():\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))   \n",
    "def write_env_var_data_file(pheno, pop_freqs, outdir):\n",
    "    out = \"%s_env_var_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"CLST\\tENV\\tREG\\n\")\n",
    "        pop_id = 0\n",
    "        for pop in pop_freqs:\n",
    "            pop_id += 1\n",
    "            o.write(\"%s\\t%f\\t%d\\n\" % (pop, np.random.randn(), pop_id))\n",
    "                \n",
    "                \n",
    "for p in alpha_vals:\n",
    "    outdir = \"/home/cfriedline/ipynb/gypsy_moth\"\n",
    "    full = alpha_vals[p].T\n",
    "    full = full.merge(missing, how=\"inner\", left_index=True, right_index=True)\n",
    "    full = full[(full['missing'] <= 0.2) & (full['missing'] >= 0.1)]\n",
    "    #full = full[(full['missing'] <= 0.3) & (full['missing'] >= 0.2)]\n",
    "    #full = full[(full['missing'] <= 0.3)]\n",
    "    full.index.name = \"SNP\"\n",
    "    full.AA = full.AA.apply(lambda x: x[0])\n",
    "    full.aa = full.aa.apply(lambda x: x[0])\n",
    "    full = full.rename(columns={'alpha':'EFF',\n",
    "                                'AA':'A1',\n",
    "                                'aa':'A2',\n",
    "                                'p': 'FRQ'})\n",
    "    candidates = full[full['p-value']<0.01]\n",
    "    write_gwas_data_file(candidates, p, outdir)\n",
    "    write_freqs_file(candidates, p, pop_allele_freqs, outdir)\n",
    "    write_match_pop_file(full, p, pop_allele_freqs, \"QC32\", outdir)\n",
    "    write_full_dataset_file(full, p, pop_allele_freqs, outdir)\n",
    "    write_env_var_data_file(p, pop_allele_freqs, outdir)\n",
    "run_squat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squat_dir = \"/data7/eckertlab/src/PolygenicAdaptationCode/Scripts/\"\n",
    "def get_squat_vars(pheno):\n",
    "    d = {\"gwas.data.file\":\"'../%s_gwas_data_file.txt'\" % pheno,\n",
    "         \"freqs.file\":\"'../%s_freqs_file.txt'\" % pheno,\n",
    "         \"env.var.data.files\":\"list('../%s_env_var_data_file.txt')\" % pheno,\n",
    "         \"match.pop.file\":\"'../%s_match_pop_file.txt'\" % pheno,\n",
    "         \"full.dataset.file\":\"'../%s_full_dataset_file.txt'\" % pheno,\n",
    "         \"path\":\"'%s'\" % pheno,\n",
    "         \"match.categories\":\"c('MAF')\",\n",
    "         \"match.bins\":\"list(seq(0,0.5,0.02), c(2), seq(0,1000,100))\",\n",
    "         \"cov.SNPs.per.cycle\":5000,\n",
    "         \"cov.cycles\":1,\n",
    "         \"null.phenos.per.cycle\":1000,\n",
    "         \"null.cycles\":1,\n",
    "         \"load.cov.mat\":\"F\",\n",
    "         \"sim.null\":\"T\",\n",
    "         \"check.allele.orientation\":\"F\"}\n",
    "    return ',\\n'.join(\"%s=%s\" % (key,val) for (key,val) in d.items())\n",
    "\n",
    "def create_squat_run_file(pheno):\n",
    "    if not os.path.exists(\"squat\"):\n",
    "        os.mkdir(\"squat\")\n",
    "    squat_file = os.path.join(\"squat\", \"squat_%s.r\" % pheno)\n",
    "    with open(squat_file, \"w\") as o:\n",
    "        o.write(\"setwd('/data7/eckertlab/src/PolygenicAdaptationCode')\\n\")\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"CreateTraitFile.R\"))\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"functions.R\"))\n",
    "        o.write(\"setwd('%s')\\n\" % os.path.abspath(\"squat\"))\n",
    "        o.write(\"PolygenicAdaptationFunction(%s)\\n\" % get_squat_vars(pheno))\n",
    "    return squat_file\n",
    "\n",
    "for pheno in alpha_vals:\n",
    "    squat_file = create_squat_run_file(pheno)\n",
    "    print squat_file\n",
    "    !cat $squat_file\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_squat():\n",
    "    for p in [\"mass\", \"pd\", \"tdt\"]:\n",
    "        print \"running %s\" % p\n",
    "        output = \"squat/%s\" % p\n",
    "        if os.path.exists(output):\n",
    "            !rm -rf {output}\n",
    "        r('setwd(\"/data7/cfriedline/ipython/notebooks/gypsy_moth\")')\n",
    "        r('source(\"squat/squat_%s.r\")' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfiles = !find . | grep Robj | grep Output\n",
    "bc = {}\n",
    "for f in rfiles:\n",
    "    d = f.split(\"/\")\n",
    "    if not d[1] in bc:\n",
    "        bc[d[1]] = []\n",
    "    bc[d[1]].append(f)\n",
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pheno in bc:\n",
    "    print pheno\n",
    "    for obj in bc[pheno]:\n",
    "        r('setwd(\"/data7/cfriedline/ipython/notebooks/gypsy_moth/squat\")')\n",
    "        r('load(\"%s\")' % obj)\n",
    "    print r(\"the.stats$LD.component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##LD.component\n",
    "\n",
    "### $\\le 10\\%$ missing\n",
    "```R\n",
    "mass\n",
    "[1] 0.4982402\n",
    "\n",
    "pd\n",
    "[1] 4.348401\n",
    "\n",
    "tdt\n",
    "[1] 0.5364081\n",
    "```\n",
    "\n",
    "### $\\le20\\%$ missing\n",
    "```R\n",
    "mass\n",
    "[1] 5.898219\n",
    "\n",
    "pd\n",
    "[1] -2.866864\n",
    "\n",
    "tdt\n",
    "[1] 8.790254\n",
    "```\n",
    "\n",
    "### $\\le30\\%$ missing\n",
    "```R\n",
    "mass\n",
    "[1] -6.6321\n",
    "\n",
    "pd\n",
    "[1] -4.397929\n",
    "\n",
    "tdt\n",
    "[1] -2.612447\n",
    "```\n",
    "\n",
    "### $10\\% \\le \\text{missing} \\le20\\%$\n",
    "```R\n",
    "mass\n",
    "[1] 3.180166\n",
    "\n",
    "pd\n",
    "[1] 0.7489133\n",
    "\n",
    "tdt\n",
    "[1] 2.044332\n",
    "```\n",
    "\n",
    "\n",
    "### $20\\% \\le \\text{missing} \\le30\\%$\n",
    "```R\n",
    "mass\n",
    "[1] -7.177221\n",
    "\n",
    "pd\n",
    "[1] -0.0530245\n",
    "\n",
    "tdt\n",
    "[1] 17.68173\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Run BEAGLE to impute missing genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle = \"/data7/eckertlab/src/beagle_3.3.2/beagle.jar\"\n",
    "java = \"/home/cfriedline/jdk1.7.0_25/bin/java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_df = gt_base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_dict = beagle_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_split = {}\n",
    "for snp, sample_data in beagle_dict.items():\n",
    "    beagle_split[snp] = {}\n",
    "    for sample, gt in sample_data.items():\n",
    "        s1 = sample + \"_1\"\n",
    "        s2 = sample + \"_2\"\n",
    "        if not gt:\n",
    "            beagle_split[snp][s1] = '?'\n",
    "            beagle_split[snp][s2] = '?'\n",
    "        else:\n",
    "            gt = gt.split(\"/\")\n",
    "            beagle_split[snp][s1] = gt[0]\n",
    "            beagle_split[snp][s2] = gt[1]\n",
    "split_df = DataFrame(beagle_split).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_col = split_df.index\n",
    "split_df.insert(0, \"id\", id_col)\n",
    "split_df.insert(0, \"I\", \"M\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "split_df.to_csv(\"input.bgl\", sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "java -Xmx20g -jar /data7/eckertlab/src/beagle_3.3.2/beagle.jar \\\n",
    "unphased=input.bgl \\\n",
    "missing='?' \\\n",
    "out=beagle_output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased = pd.read_csv(gzip.open(\"beagle_output.input.bgl.phased.gz\"), sep=\" \")\n",
    "phased.index = phased['id']\n",
    "phased = phased.drop([\"I\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_dict = phased.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_comb = {}\n",
    "for snp, sample_data in phased_dict.items():\n",
    "    phased_comb[snp] = {}\n",
    "    samples = [x[:-2] for x in sample_data]\n",
    "    for s in samples:\n",
    "        phased_comb[snp][s] = sample_data[\"%s_1\" % s] + \"/\" + sample_data[\"%s_2\" % s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_df = DataFrame(phased_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf_fis = hdf.get('z12_df_50_perc_polymorphic_maf_fis')\n",
    "duplicates = z12_df_50_perc_polymorphic_maf_fis[z12_df_50_perc_polymorphic_maf_fis.duplicate==\"1\"]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df = phased_df.drop(duplicates.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_to_z12(locus):\n",
    "    alleles = set()\n",
    "    counts = locus.value_counts()\n",
    "    num_individuals = sum(counts)\n",
    "    c = {}\n",
    "    for i, val in enumerate(counts):\n",
    "        for allele in counts.index[i].split(\"/\"):\n",
    "            if not allele in c:\n",
    "                c[allele] = 0\n",
    "            c[allele] += val\n",
    "    c = sorted(c.items(), key=lambda x:x[1], reverse=True)\n",
    "    A = c[0][0]\n",
    "    P = c[0][1]\n",
    "    a = c[1][0]\n",
    "    Q = c[1][1]\n",
    "    total = P+Q*1.0\n",
    "    p = P/total\n",
    "    q = Q/total\n",
    "    hets = [\"%s/%s\" % (A,a),\"%s/%s\" % (A,a)]\n",
    "    PQ = 0\n",
    "    for het in hets:\n",
    "        if het in counts:\n",
    "            PQ += counts[het]\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    af = [A,a,P,Q,p,q,Fis,He,Ho]\n",
    "    trans = {\"%s/%s\" % (A,A): 0,\n",
    "             \"%s/%s\" % (a,a): 2,\n",
    "             \"%s/%s\" % (A,a): 1,\n",
    "             \"%s/%s\" % (a,A): 1}\n",
    "    phased_af[locus.name] = af\n",
    "    z12 = locus.apply(lambda x: trans[x])\n",
    "    return z12\n",
    "\n",
    "phased_af = DataFrame(index=[\"A\",\"a\",\"P\",\"Q\",\"p\",\"q\",\"Fis\",\"He\",\"Ho\"], \n",
    "                      columns=phased_df.columns)\n",
    "phased_z12 = phased_df.apply(convert_to_z12)\n",
    "phased_z12[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phased_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_af[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_df', phased_df)\n",
    "hdf.put('phased_af', phased_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(phased_af.T['q'], bins=100)\n",
    "plt.title(\"MAF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_af.T[['Fis','Ho','He','p','q']].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_maf_drop = phased_af.T[phased_af.T['q']<0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf = phased_z12.drop(phased_maf_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_Fis_drop = phased_af.T[(phased_af.T['Fis'] < -0.5) | (phased_af.T['Fis'] > 0.5)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis = phased_z12_maf.drop(phased_Fis_drop.intersection(phased_z12_maf.columns), \n",
    "                                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_monomorphic = phased_z12_maf_fis.apply(is_monomorphic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_monomorphic[phased_monomorphic==True] #none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_hierf_trans2(series):\n",
    "    return series.apply(lambda x: hierf_trans[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf = phased_z12_maf_fis.apply(apply_hierf_trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/uc?export=download&id=0B4xHxBFoPCoWT0NneHJadUI0OHM'\n",
    "response = urllib2.urlopen(url)\n",
    "pheno = pd.read_excel(response, \"Males-forGenomics-final\")\n",
    "pheno=pheno[['Population', 'Number', 'Mass', 'Pupual Duration', 'Total Dev Time']]\n",
    "for x in pheno.index:\n",
    "    pheno.ix[x, 'sample_pheno'] = \"%s_%d\" % (pheno.ix[x, 'Population'], pheno.ix[x, 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno['sample_id'] = pheno.apply(lambda x: \"%s_0\" % x.sample_pheno, axis=1)\n",
    "pheno.index = pheno['sample_id']\n",
    "pheno = pheno.drop('sample_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno', pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf['population'] = phased_hierf.apply(lambda row: row.name.split(\"_\")[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf2 = phased_hierf.apply(assign_popid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_cols = ['popid']\n",
    "hierf_cols.extend(sorted(phased_hierf2.columns[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf3 = phased_hierf2.reindex(columns=hierf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phased_hierf3[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf2.ix[0:5,[\"L10\",\"L100047\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf3.popid.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "phased_hierf3.to_csv(\"hierfstat_phased.txt\", header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```R\n",
    "library(hierfstat)\n",
    "data = read.table(\"hierfstat_phased.txt\", header=T, sep=\"\\t\")\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "saveRDS(res, \"hierfstat_phased.rds\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res = readRDS(\"hierfstat_phased.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = com.convert_robj(robjects.r('res'))\n",
    "loc_df = res['loc']\n",
    "F_df = res['F']\n",
    "overall_df = res['overall']\n",
    "F_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_fst = loc_df.apply(compute_fst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_fst', phased_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(phased_fst, bins=50)\n",
    "plt.title(\"$n=%d \\ \\mu=%.2f \\pm %.2f \\ [%.2f, %.2f]$\" % (len(phased_fst), \n",
    "                                                    np.mean(phased_fst), \n",
    "                                                    np.std(phased_fst),\n",
    "                                                    np.min(phased_fst), \n",
    "                                                    np.max(phased_fst)))\n",
    "plt.xlim(0, 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(phased_af.T.Fis, bins=50)\n",
    "d = phased_af.T.Fis\n",
    "plt.title(\"$\\mu=%.4f \\pm %.4f \\ [%.2f, %.2f]$ \" % (np.mean(d), \n",
    "                                                 np.std(d),\n",
    "                                                np.min(d),\n",
    "                                                np.max(d)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.in_store(\"phased_af\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_phased(locus):\n",
    "    if locus.name.startswith(\"L\"):\n",
    "        maf = phased_af.ix['q',locus.name]\n",
    "        var = np.sqrt(maf*(1-maf))\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis_std = phased_z12_maf_fis.apply(center_and_standardize_phased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis_std[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prcomp_phased = prcomp(phased_z12_maf_fis_std, scale=False, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(summary(prcomp_phased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_x = com.convert_robj(prcomp_phased.rx2(\"x\"))\n",
    "phased_x.index = phased_z12_maf_fis_std.index\n",
    "phased_joined = phased_x.join(phased_z12_maf_fis)\n",
    "phased_joined['population'] = phased_joined.apply(lambda row: row.name.split(\"_\")[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))\n",
    "legend = {}\n",
    "for row in phased_joined.iterrows():\n",
    "    pop = row[1]['population']\n",
    "    n = norm(pop_id[pop])\n",
    "    color = cm.hsv(n)\n",
    "    legend[pop] = color\n",
    "    plt.scatter(row[1].PC1, \n",
    "                row[1].PC2, \n",
    "                s=50, \n",
    "                c=color)\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "cmap = plt.get_cmap()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.title(\"PCA of n=%d samples on %d loci\" % (len(phased_joined), \n",
    "                                              len(phased_z12_maf_fis.columns)))\n",
    "plt.xlabel(\"PC1 (3.344%)\")\n",
    "plt.ylabel(\"PC2 (3.238%)\")\n",
    "\n",
    "handles = []\n",
    "for pop in sorted(legend):\n",
    "    handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "plt.legend(handles=sorted(handles))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TWcalc = r('TWcalc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_tw = TWcalc(phased_z12_maf_fis_std.values, 15)\n",
    "print phased_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_tw_p = com.convert_robj(phased_tw.rx2(2))\n",
    "phased_tw_e = com.convert_robj(phased_tw.rx2(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_tw_num = 0\n",
    "for i, p in enumerate(phased_tw_p):\n",
    "    print p\n",
    "    if p > 0.05:\n",
    "        phased_tw_num = i\n",
    "        break\n",
    "print \"Tracy-Widom test yields %d axes of pop structure\" % phased_tw_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "0.023286351\n",
    "0.667231036\n",
    "Tracy-Widom test yields 12 axes of pop structure\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_pca_cov = phased_x.ix[:,0:phased_tw_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_pca_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_pca_cov', phased_pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_pca_phased_z12_maf_fis = pheno.join(phased_pca_cov, how='inner').join(phased_z12_maf_fis, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df_filtered = phased_df.ix[phased_z12_maf_fis.index, phased_z12_maf_fis.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_cols = ['Mass','Pupual Duration','Total Dev Time']\n",
    "pheno_cols.extend(phased_df_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered = pheno.join(phased_df_filtered, how='inner')\n",
    "pheno_phased_df_filtered = pheno_phased_df_filtered[pheno_cols]\n",
    "pheno_phased_df_filtered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered.ix[:,0:3] = preprocessing.scale(pheno_phased_df_filtered.ix[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered_pca_cov = pheno_phased_df_filtered.join(phased_pca_cov, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno_phased_df_filtered_pca_cov', pheno_phased_df_filtered_pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_snpassoc = pheno_phased_df_filtered_pca_cov.apply(snpassoc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_snpassoc = phased_snpassoc.dropna(how=\"all\", axis=1)\n",
    "phased_snpassoc.columns = [x.replace(\" \", \"_\") for x in phased_snpassoc.columns]\n",
    "phased_snpassoc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_snpassoc', phased_snpassoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_snpassoc.to_csv(\"phased_snpassoc.txt\",\n",
    "                     header=True,\n",
    "                     index=True,\n",
    "                     sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_phased_snpassoc_files(df, input_file, num_pca_axes):\n",
    "    pheno = df.columns[0:3]\n",
    "    out_files = []\n",
    "    for p in pheno:\n",
    "        with open(\"snpassoc_%s.R\" % p.lower(), \"w\") as o:\n",
    "            print \"writing %s\" % o.name\n",
    "            out_files.append(o.name)\n",
    "            text = '''\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('%s', sep=\"\\\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-%d)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-%d):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(%s~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9+pca_data$PC10+pca_data$PC11+pca_data$PC12, data=snp_data, model=\"co\")\n",
    "\n",
    "saveRDS(wg, \"phased_wg_%s_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"phased_wgstats_%s.rds\")\n",
    "''' % (input_file, \n",
    "       num_pca_axes,\n",
    "       num_pca_axes-1,\n",
    "       p, \n",
    "       p.lower(), \n",
    "       p.lower())\n",
    "        \n",
    "            o.write(text)\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phased_snpassoc_files = write_phased_snpassoc_files(phased_snpassoc,\n",
    "                                                    \"phased_snpassoc.txt\",\n",
    "                                                    12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat snpassoc_mass.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```R\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('phased_snpassoc.txt', sep=\"\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-12)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-11):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(Mass~1 + pca_data$PC1 + pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9+pca_data$PC10+pca_data$PC11+pca_data$PC12, data=snp_data, model=\"co\")\n",
    "\n",
    "saveRDS(wg, \"phased_wg_mass_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"phased_wgstats_mass.rds\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
