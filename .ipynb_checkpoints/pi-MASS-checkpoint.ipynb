{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vcf\n",
    "import os\n",
    "import pysam\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir'\n",
    "os.chdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VCFmissing = os.path.join(file_dir,'good_snps_good_samples_missing.vcf')\n",
    "VCFimputed = os.path.join(file_dir,'good_snps_good_samples.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputed_reader = vcf.Reader(open(VCFimputed),'r')\n",
    "miss_reader = vcf.Reader(open(VCFmissing),'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get data for imputed_piFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_genotype(gp): #GP is the list of likelihoods\n",
    "    total = 0\n",
    "    for i, val in enumerate(gp):\n",
    "        total += val*i\n",
    "    return np.round(total,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#example of what happens\n",
    "count = 0\n",
    "recCount = 0\n",
    "for rec in imputed_reader:\n",
    "    print rec\n",
    "    for sample in rec:\n",
    "        print sample\n",
    "        count +=1\n",
    "        if count % 10 ==0:\n",
    "            break\n",
    "    recCount += 1\n",
    "    if recCount % 10 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a key so we can sample each rec in order of sampleID\n",
    "smpLST = [rec.samples[i].sample for i,x in enumerate(rec.samples)]\n",
    "sortSMPLST = sorted(smpLST)\n",
    "sampKey = []\n",
    "for i,smp in enumerate(sortSMPLST):\n",
    "    sampKey.append(smpLST.index(sortSMPLST[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recCount = 0\n",
    "locDict = OrderedDict()      #key = locus, value = lineDict\n",
    "imputed_reader = vcf.Reader(open(VCFimputed),'r')\n",
    "for rec in imputed_reader:   #for each locus\n",
    "    lineDict = OrderedDict()      #key = piFILE column name (eg 'locus', 'mnr', 'mjr', 'sampID_X')\n",
    "                                  #value = either locus, mjr_all, mnr_all, or samp-specific mean_genotype\n",
    "    sampDict = OrderedDict()      #key = sampID, value = [ gt , [PL_LST] ]\n",
    "        \n",
    "    ref = rec.REF\n",
    "    alt = rec.ALT[0]\n",
    "    locus = \"_\".join([str(rec.CHROM),str(rec.POS)])\n",
    "    lineDict['locus'] = locus\n",
    "    c = Counter()\n",
    "    \n",
    "    ##add the following if the samples aren't in the same order within each rec\n",
    "    #smpLST = [rec.samples[i].sample for i,x in enumerate(rec.samples)]\n",
    "    #sampKey = []\n",
    "    #for i,smp in enumerate(sortSMPLST):\n",
    "    #    sampKey.append(smpLST.index(sortSMPLST[i]))\n",
    "    \n",
    "    #print \"rec =\", rec\n",
    "    #print \"ref, alt =\",ref,\",\", alt\n",
    "\n",
    "    samps = 0\n",
    "    for i in sampKey: #get allele counts from a sorted list of sampleIDs\n",
    "        \n",
    "        sample = rec.samples[i]\n",
    "        \n",
    "        gt = sample['GT'].split('|')\n",
    "        if '.' not in gt:  #if '.' isn't in the sample genotype\n",
    "            c[gt[0]] += 1 #count the first allele using the allele as a key\n",
    "            c[gt[1]] += 1 #count the second allele \" \" \" \"\n",
    "            sampDict[sample.sample] = [gt, sample['GP']] #keep track of samp-spec gt and likelihood scores\n",
    "        else:\n",
    "            sampDict[sample.sample] = [gt, sample['GP']] #shitty samples still need love\n",
    "        \n",
    "        samps += 1\n",
    "        #if samps % 20 == 0:\n",
    "            #break\n",
    "    \n",
    "    if c['0'] > c['1']: #if the reference allele isn't the minor allele\n",
    "        lineDict['mnr'] = alt\n",
    "        lineDict['mjr'] = ref\n",
    "        \n",
    "        for samp, sampLST in sampDict.items(): \n",
    "            if '.' in sampDict[samp][0]: #if the genotype has a '.'\n",
    "                mean_genotype = \"NA\"\n",
    "            else:\n",
    "                #calc mean genotype from sample['GP']\n",
    "                sampDict[samp][1] = list(reversed(sampDict[samp][1])) #reverse the sample['GP']\n",
    "                mean_genotype = get_mean_genotype(sampDict[samp][1])\n",
    "            \n",
    "            lineDict[samp] = mean_genotype #append the mean genotype score for each sample\n",
    "    else:\n",
    "        lineDict['mnr'] = ref\n",
    "        lineDict['mjr'] = alt\n",
    "        \n",
    "        for samp, sampLST in sampDict.items():\n",
    "            if '.' in sampDict[samp][0]: #if the genotype has a '.'\n",
    "                mean_genotype = \"NA\"\n",
    "            else:\n",
    "                #calc mean genotype from sample['GP']\n",
    "                mean_genotype = get_mean_genotype(sampDict[samp][1])\n",
    "                \n",
    "            lineDict[samp] = mean_genotype\n",
    "            \n",
    "        \n",
    "    locDict[locus] = [lineDict]\n",
    "    recCount += 1\n",
    "    #break\n",
    "    if recCount % 1000 == 0:\n",
    "        print recCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recCount #159927 expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locDict.items()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure this makes sense\n",
    "#if min != max then the sortSMPLST isn't correct - it may not include all samples\n",
    "MIN = 100000000000000000000000\n",
    "MAX = 0\n",
    "\n",
    "for loc in locDict.keys():\n",
    "    x = len(locDict[loc][0].keys())\n",
    "    if x < MIN:\n",
    "        MIN = x\n",
    "    if x > MAX:\n",
    "        MAX = x\n",
    "print MIN, MAX   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(locDict.keys()) #make sure this makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###make imputed piFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piM_dir = '/home/lindb/eckertlab/wbp/piMASS/'\n",
    "os.chdir(piM_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locDict.keys()[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locDict[locDict.keys()[9]][0].values()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'\\t'.join(str(x) for x in locDict[locDict.keys()[9]][0].values()) + str('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[x for x in locDict['NODE_1978391_length_96_cov_1.031250_27'][0].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = [x for x in locDict['NODE_1978391_length_96_cov_1.031250_27'][0].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coldf = pd.DataFrame(colnames)\n",
    "coldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coldfFILE = os.path.join(piM_dir,'imppifileColumns.txt')\n",
    "coldf.to_csv(coldfFILE,sep=\"\\t\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(locDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rowNames = [x for x in locDict.keys()]\n",
    "rnDF = pd.DataFrame(rowNames)\n",
    "rnDF.head()\n",
    "rnDF.to_csv(os.path.join(piM_dir,'imppifileRows.txt'),sep=\"\\t\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imppifile = os.path.join(piM_dir,'impPiFile.txt')\n",
    "imppifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locCount = 0\n",
    "with open(imppifile,'w') as o:\n",
    "    for locus, data in locDict.items():\n",
    "        line = '\\t'.join(str(x) for x in locDict[locus][0].values()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        locCount += 1\n",
    "        if locCount % 1000 == 0:\n",
    "            print locCount\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(impPiFile.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impPiFile = pd.read_table(imppifile,header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impPiFile.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get info for missing_piFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example of what happens\n",
    "count = 0\n",
    "recCount = 0\n",
    "for rec in miss_reader:\n",
    "    print rec\n",
    "    for sample in rec:\n",
    "        print sample\n",
    "        count +=1\n",
    "        if count % 10 ==0:\n",
    "            break\n",
    "    recCount += 1\n",
    "    if recCount % 10 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_GQ_to_p(q):\n",
    "    return pow(10,(q/-10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_miss_mean_gt(PL):\n",
    "    total = 0\n",
    "    pvals = [convert_GQ_to_p(x) for x in PL]\n",
    "    pval_sum = np.sum(pvals)\n",
    "    pvals = [x/pval_sum for x in pvals]\n",
    "    for i, val in enumerate(pvals):\n",
    "        total += val*i\n",
    "            \n",
    "    return np.round(total, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recCount = 0\n",
    "misslocDict = OrderedDict()      #key = locus, value = lineDict\n",
    "for rec in miss_reader:   #for each locus\n",
    "    lineDict = OrderedDict()      #key = piFILE column name (eg 'locus', 'mnr', 'mjr', 'sampID_X')\n",
    "                                  #value = either locus, mjr_all, mnr_all, or samp-specific mean_genotype\n",
    "    sampDict = OrderedDict()      #key = sampID, value = [ gt , [PL_LST] ]\n",
    "        \n",
    "    ref = rec.REF\n",
    "    alt = rec.ALT[0]\n",
    "    locus = \"_\".join([str(rec.CHROM),str(rec.POS)])\n",
    "    lineDict['locus'] = locus\n",
    "    c = Counter()\n",
    "    \n",
    "    ##add the following if the samples aren't in the same order within each rec\n",
    "    #smpLST = [rec.samples[i].sample for i,x in enumerate(rec.samples)]\n",
    "    #sampKey = []\n",
    "    #for i,smp in enumerate(sortSMPLST):\n",
    "    #    sampKey.append(smpLST.index(sortSMPLST[i]))\n",
    "    \n",
    "    #print \"rec =\", rec\n",
    "    #print \"ref, alt =\",ref,\",\", alt\n",
    "\n",
    "    samps = 0\n",
    "    for i in sampKey: #get allele counts from a sorted list of sampleIDs\n",
    "        \n",
    "        sample = rec.samples[i]\n",
    "        \n",
    "        gt = sample['GT'].split('/')\n",
    "        if '.' not in gt:  #if '.' isn't in the sample genotype\n",
    "            c[gt[0]] += 1 #count the first allele\n",
    "            c[gt[1]] += 1 #count the second allele\n",
    "            sampDict[sample.sample] = [gt, sample['PL']] #keep track of samp-spec gt and likelihood scores\n",
    "        else:\n",
    "            sampDict[sample.sample] = [gt, sample['PL']] #shitty samples still need love\n",
    "        \n",
    "        samps += 1\n",
    "        #if samps % 20 == 0:\n",
    "            #break\n",
    "    \n",
    "    if c['0'] > c['1']: #if the reference allele isn't the minor allele\n",
    "        lineDict['mnr'] = alt\n",
    "        lineDict['mjr'] = ref\n",
    "        \n",
    "        for samp, sampLST in sampDict.items(): \n",
    "            if '.' in sampDict[samp][0]: #if the genotype has a '.'\n",
    "                mean_genotype = \"NA\"\n",
    "            else:\n",
    "                #calc mean genotype from sample['GP']\n",
    "                sampDict[samp][1] = list(reversed(sampDict[samp][1])) #reverse the sample['GP']\n",
    "                mean_genotype = get_miss_mean_gt(sampDict[samp][1])\n",
    "            \n",
    "            lineDict[samp] = mean_genotype #append the mean genotype score for each sample\n",
    "    else:\n",
    "        lineDict['mnr'] = ref\n",
    "        lineDict['mjr'] = alt\n",
    "        \n",
    "        for samp, sampLST in sampDict.items():\n",
    "            if '.' in sampDict[samp][0]: #if the genotype has a '.'\n",
    "                mean_genotype = \"NA\"\n",
    "            else:\n",
    "                #calc mean genotype from sample['GP']\n",
    "                mean_genotype = get_miss_mean_gt(sampDict[samp][1])\n",
    "                \n",
    "            lineDict[samp] = mean_genotype\n",
    "            \n",
    "        \n",
    "    misslocDict[locus] = [lineDict]\n",
    "    recCount += 1\n",
    "    #break\n",
    "    if recCount % 1000 == 0:\n",
    "        print recCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recCount #should be 167701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(missinglocDict.keys()) #make sure this makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure this makes sense too\n",
    "MIN = 100000000000\n",
    "MAX = 0\n",
    "\n",
    "for loc in misslocDict.keys():\n",
    "    x = len(misslocDict[loc][0].keys())\n",
    "    if x < MIN:\n",
    "        MIN = x\n",
    "    if x > MAX:\n",
    "        MAX = x\n",
    "print MIN, MAX   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###make missing_piFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = [x for x in misslocDict['NODE_1978391_length_96_cov_1.031250_27'][0].keys()]\n",
    "colnames[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coldf = pd.DataFrame(colnames)\n",
    "coldf\n",
    "coldfFILE = os.path.join(piM_dir,'mispifileColumns.txt')\n",
    "coldf.to_csv(coldfFILE,sep=\"\\t\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(misslocDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rowNames = [x for x in misslocDict.keys()]\n",
    "rnDF = pd.DataFrame(rowNames)\n",
    "rnDF.to_csv(os.path.join(piM_dir,'mispifileRows.txt'),sep=\"\\t\",header=False)\n",
    "rnDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create Mean Genotype Files from the intersection of loci between sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imploc = set(locDict.keys())\n",
    "misloc = set(misslocDict.keys())\n",
    "intersection = imploc.intersection(misloc)\n",
    "len(intersection) #should be 159803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imppifile = os.path.join(piM_dir,'imppifileIntersection.txt')\n",
    "imppifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locCount = 0\n",
    "locs = []\n",
    "with open(imppifile,'w') as o:\n",
    "    for locus in intersection:\n",
    "        line = '\\t'.join(str(x) for x in locDict[locus][0].values()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        locCount += 1\n",
    "        locs.append(locus)\n",
    "        if locCount % 1000 == 0:\n",
    "            print locCount\n",
    "o.close()\n",
    "len(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mispifile = os.path.join(piM_dir,'mispifileIntersection.txt')\n",
    "mispifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locCount = 0\n",
    "locs = []\n",
    "with open(mispifile,'w') as o:\n",
    "    for locus in intersection:\n",
    "        line = '\\t'.join(str(x) for x in misslocDict[locus][0].values()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        locCount += 1\n",
    "        locs.append(locus)\n",
    "        if locCount % 1000 == 0:\n",
    "            print locCount\n",
    "o.close()\n",
    "len(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intRow = [x for x in intersection]\n",
    "intRow[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intRowdf = pd.DataFrame(intRow)\n",
    "intRowdf.to_csv(os.path.join(piM_dir,'IntersectionRowNames.txt'),sep=\"\\t\",header=False)\n",
    "intRowdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coldf.to_csv(os.path.join(piM_dir,'IntersectionColNames.txt'),sep=\"\\t\",header=False)\n",
    "coldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imppifile = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/imppifileIntersection.txt',header=None,sep=\"\\t\")\n",
    "mispifile = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/mispifileIntersection.txt',header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/IntersectionColNames.txt',header=None,sep=\"\\t\")\n",
    "columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imppifile.columns = [x for x in columns[1].values]\n",
    "imppifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mispifile.columns = [x for x in columns[1].values]\n",
    "mispifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samps = sorted(imppifile.columns[3:])\n",
    "samps[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_mispifile = mispifile[['locus','mnr','mjr']]\n",
    "new_mispifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_imppifile = imppifile[['locus','mnr','mjr']]\n",
    "new_imppifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hey = pd.DataFrame(new_imppifile)\n",
    "[hey == imppifile[x] for x in samps]\n",
    "hey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in samps:\n",
    "    print s\n",
    "    new_imppifile.loc[:,s] = imppifile.loc[:,s]\n",
    "    new_mispifile.loc[:,s] = mispifile.loc[:,s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_imppifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_mispifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(new_imppifile.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piM_dir = '/home/lindb/eckertlab/wbp/piMASS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_imppifile.to_csv(os.path.join(piM_dir,'imppifileIntersection.txt'),header=None,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_mispifile.to_csv(os.path.join(piM_dir,'mispifileIntersection.txt'),header=None,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = pd.DataFrame(new_imppifile.columns)\n",
    "columns.to_csv(os.path.join(piM_dir,'IntersectionColNames.txt'),header=None,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Make SNP location file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intRowdf = pd.read_table('/home/lindb/eckertlab/wbp/piMASS/IntersectionRowNames.txt',sep=\"\\t\",header=None)\n",
    "intRowdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0 \n",
    "for loc in intRowdf[1]:\n",
    "    print loc\n",
    "    count +=1\n",
    "    if count % 10 ==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pimass_contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piM_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loc file will be the same for both missing and imputed sets since it was made: [x for x in intersection]\n",
    "pimass_contigs = OrderedDict()\n",
    "contig_num = OrderedDict()\n",
    "num = 1\n",
    "with open(os.path.join(piM_dir, \"Intxn_loc.txt\"), \"w\") as o:    \n",
    "    for x in intRowdf[1]:\n",
    "        data = x.split(\"_\")\n",
    "        contig = \"_\".join(data[0:-1])\n",
    "        pos = data[-1]\n",
    "        if not contig in pimass_contigs:\n",
    "            pimass_contigs[contig] = []\n",
    "            contig_num[contig] = num\n",
    "            num += 1\n",
    "        pimass_contigs[contig].append(pos)\n",
    "        o.write(\"%s_%s\\t%s\\t%d\\n\" % (contig,pos,pos,contig_num[contig]))\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pimass_contigs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Get PCAs before making Phenotype file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first get pop.data (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/WBP_IDS_MATCHED_POP_FINAL_110915.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, row in test.iterrows():\n",
    "    sample = str(row['ID'])\n",
    "    if len(sample) == 1:\n",
    "        test.loc[idx,'ID'] = ''.join(['0','0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 2:\n",
    "        test.loc[idx,'ID'] = ''.join(['0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 3:\n",
    "        test.loc[idx,'ID'] = ''.join([sample,'compiled_sorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(test.loc[9,'ID']) == str(test.loc[10,'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxlst = []\n",
    "samplst = []\n",
    "for idx,row in test.iterrows():\n",
    "    #print str(test.loc[idx,'ID'])\n",
    "    if str(test.loc[idx,'ID']) not in samplst:\n",
    "        idxlst.append(idx)\n",
    "        samplst.append(str(test.loc[idx,'ID']))\n",
    "len(idxlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.loc[idxlst,:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.index = [x for x in test['ID']]\n",
    "#new = pd.DataFrame(missingData.loc[:,missingData.columns[2:14]])\n",
    "test = pd.DataFrame(test.loc[:,[col for idx,col in enumerate(test.columns) if idx != 2]])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) first need to take VCF files and order 0,1,2 as counts of minor allele\n",
    "# 2) then center and standardize each genotype\n",
    "# 3) then get PCAs from prcomp.R\n",
    "# 4) use Tracy-Widom to get sig PCs\n",
    "# 5) mult reg (get residuals): phen ~ PCs\n",
    "# 6) normal quantile transformation\n",
    "# 7) create piMASS phenotype infiles\n",
    "# 8) create piMASS runfiles\n",
    "# 9) sort SNPs on thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 1 - take VCF files and order 0,1,2 as counts of minor allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the missingData and imputedData were made from the BayEnv script which used \n",
    "    #good_snps_good_samples_missing.vcf.gz.012 and good_snps_good_samples.vcf.gz.012.pos as input\n",
    "%time missingData = pd.read_csv('/home/lindb/eckertlab/wbp/BayEnv/missingIntersection.txt',header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputedData = pd.read_csv('/home/lindb/eckertlab/wbp/BayEnv/imputedIntersection.txt',header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = pd.read_csv('/home/lindb/eckertlab/wbp/BayEnv/IntersectionRowNames.txt',header=None,sep=\"\\t\")\n",
    "miscol = pd.read_csv('/home/lindb/eckertlab/wbp/BayEnv/missingIntersectionColumns.txt',header=None,sep=\"\\t\")\n",
    "impcol = pd.read_csv('/home/lindb/eckertlab/wbp/BayEnv/imputedIntersectionColumns.txt',header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missingData.columns = [x for x in miscol.loc[:,0]]\n",
    "imputedData.columns = [x for x in impcol.loc[:,0]]\n",
    "missingData.index = imputedData.index = [x for x in idx.loc[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#counts refer to the reference allele\n",
    "missingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#counts refer to the reference allele\n",
    "imputedData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 2 - center and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def switch_em(d):\n",
    "    if d == 0:\n",
    "        return 2\n",
    "    if d == 2:\n",
    "        return 0\n",
    "    if d == 1:\n",
    "        return d\n",
    "    if math.isnan(d):\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val(gen, mu, var):\n",
    "    if math.isnan(gen):\n",
    "        return 0.0\n",
    "    return (gen-mu)/np.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#center and standardize missing\n",
    "def get_em(locus):\n",
    "\n",
    "    data = locus\n",
    "    \n",
    "    zero = [x for x in data].count(0) #count the ref homozygotes\n",
    "    one =  [x for x in data].count(1) #count the heterozygotes\n",
    "    two =  [x for x in data].count(2) #count the alt homozygotes \n",
    "    \n",
    "    #if 0,1,2 is counting the minor allele, p > q because there should be more 0s (genotypes without minor allele)\n",
    "    p = (2*zero + one)/(2*(zero+one+two))\n",
    "    q = (2*two + one) /(2*(zero+one+two)) \n",
    "    \n",
    "    maf = min(p,q)\n",
    "    var = maf*(1-maf)\n",
    "    \n",
    "    if p < q: #if 0,1,2 isn't counting the minor allele \n",
    "        data2 = data.apply(switch_em)\n",
    "        mu = np.mean([x for x in data2 if math.isnan(x) == False])\n",
    "        #print \"p=%.5f q=%.5f mu=%.5f var=%.5f\" % (p,q,mu,var)\n",
    "\n",
    "        return data2.apply(get_val, args=(mu,var)) #center and standardize the genotype for each individual\n",
    "        \n",
    "    else:\n",
    "        mu = np.mean([x for x in data if math.isnan(x) == False])\n",
    "        #print \"p=%.5f q=%.5f mu=%.5f var=%.5f\" % (p,q,mu,var)\n",
    "\n",
    "        return data.apply(get_val, args=(mu,var))  #center and standardize the genotype for each individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#see if this works using a subset of the data\n",
    "new = pd.DataFrame(missingData.loc[:,missingData.columns[2:14]])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#seeing if it works\n",
    "mis_std = new.apply(get_em)\n",
    "mis_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(0-0.39161)/np.sqrt(0.15746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 3 - get the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time mis_std = missingData.apply(get_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mis_std.columns = [x for x in miscol.loc[:,0]]\n",
    "mis_std.index = [x for x in idx.loc[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mis_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time imp_std = imputedData.apply(get_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_std.to_csv('/home/lindb/eckertlab/wbp/piMASS/imp_std.txt',header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_std.to_csv('/home/lindb/eckertlab/wbp/piMASS/imp_stdNOHEADNOIDX.txt',header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mis_std.to_csv('/home/lindb/eckertlab/wbp/piMASS/mis_std.txt',header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mis_std.to_csv('/home/lindb/eckertlab/wbp/piMASS/mis_stdNOHEADNOIDX.txt',header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mis_std = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/mis_std.txt',header=0,index_col=0,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mis_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mis_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time imp_std = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/imp_std.txt',header=0,index_col=0,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(imp_std.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_r(): ####/gpfs_fs/home/lindb/anaconda/envs/conda/lib/R ####/home/lindb/g/R3/lib64/R/\n",
    "    os.environ['R_HOME'] = '/home/lindb/g/R3/lib64/R/' \n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], ####/home/lindb/g/R3/lib64/R/bin/R\n",
    "                                                   os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri as pd2ri\n",
    "pd2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r('pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = r('summary')\n",
    "prcomp = r('prcomp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time prcomp_res = prcomp(imp_std,scale=False,center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r('saveRDS')(prcomp_res, \"prcomp_res_imputed.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "setwd('/home/lindb/eckertlab/wbp/piMASS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_res = r('readRDS')(\"prcomp_res_imputed.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mis_res = r('readRDS')(\"prcomp_res_missing.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd2ri.ri2py_dataframe(imp_res.rx2(\"x\"))\n",
    "x.index = imp_std.index\n",
    "x.columns = imp_res.rx2(\"x\").names.rx2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impPCs = pd.merge(x,test,left_index=True,right_index=True)\n",
    "impPCs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impPCs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in misPCs.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "legend = {}\n",
    "for row, data in impPCs.iterrows():\n",
    "    pop = data['Population_ID']\n",
    "    n = norm(pop_id[pop])\n",
    "    color = cm.rainbow(n)\n",
    "    legend[pop] = color\n",
    "    plt.scatter(data.PC1, \n",
    "                data.PC2, \n",
    "                s=50, \n",
    "                c=color)\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "cmap = plt.get_cmap()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.title(\"PCA of n=%d samples on %d loci\" % (len(impPCs), len(mis_std.columns)))\n",
    "#0.05294  0.01079\n",
    "#0.02051  0.01083\n",
    "plt.xlabel(\"PC1 (2.051%)\")\n",
    "plt.ylabel(\"PC2 (1.083%)\")\n",
    "\n",
    "handles = []\n",
    "for pop in sorted(legend):\n",
    "    handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "plt.legend(handles=sorted(handles), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Now for missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time mis_res = prcomp(mis_std, scale=False,center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(summary(mis_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r('saveRDS')(mis_res,\"prcomp_res_missing.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mis_res = r('readRDS')(\"prcomp_res_missing.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd2ri.ri2py_dataframe(mis_res.rx2(\"x\"))\n",
    "y.index = mis_std.index\n",
    "y.columns = mis_res.rx2(\"x\").names.rx2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misPCs = pd.merge(y,test,right_index=True,left_index=True)\n",
    "misPCs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "misPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in misPCs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "legend = {}\n",
    "for row, data in misPCs.iterrows():\n",
    "    pop = data['Population_ID']\n",
    "    n = norm(pop_id[pop])\n",
    "    color = cm.rainbow(n)\n",
    "    legend[pop] = color\n",
    "    plt.scatter(data.PC1, \n",
    "                data.PC2, \n",
    "                s=50, \n",
    "                c=color)\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "cmap = plt.get_cmap()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.title(\"PCA of n=%d samples on %d loci\" % (len(misPCs), len(mis_std.columns)))\n",
    "#0.05294  0.01079\n",
    "#0.02051  0.01083\n",
    "plt.xlabel(\"PC1 (2.051%)\")\n",
    "plt.ylabel(\"PC2 (1.083%)\")\n",
    "\n",
    "handles = []\n",
    "for pop in sorted(legend):\n",
    "    handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "plt.legend(handles=sorted(handles), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 4 - Use Tracy-Widom to get significant PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twtable = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/twTable.txt',header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twtable = twtable.loc[:,twtable.columns[0:3]]\n",
    "twtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twtable[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "TWcalc<-function(dat,k){\n",
    "    x<-dat\n",
    "    y<-x%*%t(x)\n",
    "    eig<-eigen(y)\n",
    "    eig<-eig$values\n",
    "    eig<-eig[1:(length(eig))]\n",
    "    n<-ncol(x)\n",
    "    m0=nrow(x)\n",
    "    k=k\n",
    "    TWres_<-c()\n",
    "    for (i in 1:k){\n",
    "        m=(m0)-i+1\n",
    "        m=m\n",
    "        eiv<-eig[i:(m-1)]\n",
    "        #n_=n\n",
    "        n_=((m+1)*sum(eiv)^2)/((m-1)*sum(eiv^2)-sum(eiv)^2)\n",
    "        S=((sqrt(n_-1)+sqrt(m)))/n_* (1/sqrt(n_-1)+1/sqrt(m))^(1/3)\n",
    "        u_=(sqrt(n_-1)+sqrt(m))^2/n_\n",
    "        L1<-(m-1)*eiv[1]/sum(eiv)\n",
    "        TW_<-(L1-u_)/S\n",
    "        TWres_<-c(TWres_,TW_)\n",
    "    }\n",
    "    #TWres_\n",
    "    pres<-c()\n",
    "    for (i in 1:length(TWres_)){\n",
    "        TW<-TWres_[i]\n",
    "        dif<-abs(twtable[,1]-TW)\n",
    "        p<-twtable[dif==min(dif),2]\n",
    "        pres<-c(pres,p)\n",
    "    }\n",
    "    #pres\n",
    "    res<-list(TWres_,pres)\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I ran this in R (command line) to find out the sig PCs\n",
    "%%R\n",
    "setwd(\"/home/lindb/eckertlab/wbp/piMASS/\")\n",
    "library(data.table)\n",
    "source(\"TWcalc.R\")\n",
    "twtable <- read.csv(\"/home/lindb/eckertlab/wbp/piMASS/twTable.txt\",sep=\"\\t\")\n",
    "mis <- fread(\"/home/lindb/eckertlab/wbp/piMASS/mis_stdNOHEADNOIDX.txt\",header=FALSE,sep=\"\\t\")\n",
    "tw_mis <- TWcalc(as.matrix(mis),224)\n",
    "tw_mis_p = tw_mis[[2]]\n",
    "tw_mis_e = tw_mis[[1]]\n",
    "for(i in 1:length(tw_mis_p)){\n",
    "    p = tw_mis_p[i]\n",
    "    if (p > 0.05){\n",
    "        tw_mis_num = i-1\n",
    "        break\n",
    "    }\n",
    "}\n",
    "tw_mis_num\n",
    "#[1] 2 #two significant axes of population structure\n",
    "\n",
    "imp <- fread(\"/home/lindb/eckertlab/wbp/piMASS/imp_stdNOHEADNOIDX.txt\",header=FALSE,sep=\"\\t\")\n",
    "tw_imp <- TWcalc(as.matrix(imp),224)\n",
    "tw_imp_p = tw_imp[[2]]\n",
    "tw_imp_e = tw_imp[[1]]\n",
    "for(i in 1:length(tw_imp_p)){\n",
    "    p = tw_imp_p[i]\n",
    "    if (p > 0.05){\n",
    "        tw_imp_num = i-1\n",
    "        break\n",
    "    }\n",
    "}\n",
    "tw_imp_num\n",
    "#[1] 2 #two significant aces of popuation structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 5 - linear reg (get residuals): phen ~ PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impPCs = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/imp_std.txt',header=0,index_col=0,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impPCs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impPCs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impPCs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impPCs.c13_fam[[i for i,x in enumerate(impPCs.c13_fam) if not math.isnan(x)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = impPCs.columns[-10:]\n",
    "phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impStatDict = OrderedDict()\n",
    "phenCount = 0\n",
    "for phen in phenos:\n",
    "    data = pd.DataFrame()\n",
    "    data[phen] = impPCs[phen][[i for i,x in enumerate(impPCs[phen]) if not math.isnan(x)]]\n",
    "    data['PC1']  = impPCs['PC1'][[i for i,x in enumerate(impPCs[phen]) if not math.isnan(x)]]\n",
    "    data['PC2']  = impPCs['PC2'][[i for i,x in enumerate(impPCs[phen]) if not math.isnan(x)]]\n",
    "    data = data.astype(float)\n",
    "    formula = str(\"%s~PC1+PC2\" % phen)\n",
    "    impStatDict[phen] = smf.ols(formula, data).fit()\n",
    "    phenCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misStatDict = OrderedDict()\n",
    "phenCount = 0\n",
    "for phen in phenos:\n",
    "    data = pd.DataFrame()\n",
    "    data[phen] = misPCs[phen][[i for i,x in enumerate(misPCs[phen]) if not math.isnan(x)]]\n",
    "    data['PC1']  = misPCs['PC1'][[i for i,x in enumerate(misPCs[phen]) if not math.isnan(x)]]\n",
    "    data['PC2']  = misPCs['PC2'][[i for i,x in enumerate(misPCs[phen]) if not math.isnan(x)]]\n",
    "    data = data.astype(float)\n",
    "    formula = str(\"%s~PC1+PC2\" % phen)\n",
    "    misStatDict[phen] = smf.ols(formula, data).fit()\n",
    "    phenCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(misStatDict.keys()),len(impStatDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDict = OrderedDict()\n",
    "for k,v in impStatDict.items():\n",
    "    data = impStatDict[k]\n",
    "    impResidDict[k] = data.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misResidDict = OrderedDict()\n",
    "for k,v in statDict.items():\n",
    "    data = misStatDict[k]\n",
    "    misResidDict[k] = data.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf = pd.DataFrame()\n",
    "misResidDf[0] = [\"\" for x in mis_std.index]\n",
    "misResidDf.index = mis_std.index\n",
    "misResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf = pd.DataFrame()\n",
    "impResidDf[0] = [\"\" for x in imp_std.index]\n",
    "impResidDf.index = imp_std.index\n",
    "impResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leng = 0\n",
    "count = 0\n",
    "for p in phenos:\n",
    "    for i,x in enumerate(misResidDict[p]):\n",
    "        SAMP = misResidDict[p].keys()[i]\n",
    "        #idx = [i for i,x in enumerate(mis_std.index) if x == SAMP][0]\n",
    "        print idx, SAMP\n",
    "        if SAMP.endswith('sorted'):\n",
    "            misResidDf.loc[SAMP,p] = x\n",
    "    #break\n",
    "    #residDF[k] = [x for x in residDict[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf = misResidDf.loc[:,[col for col in misResidDf.columns if col != 0]]\n",
    "misResidDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leng = 0\n",
    "count = 0\n",
    "for p in phenos:\n",
    "    for i,x in enumerate(impResidDict[p]):\n",
    "        SAMP = impResidDict[p].keys()[i]\n",
    "        #idx = [i for i,x in enumerate(imp_std.index) if x == SAMP][0]\n",
    "        #print idx, SAMP\n",
    "        if SAMP.endswith('sorted'):\n",
    "            impResidDf.loc[SAMP,p] = x\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf = impResidDf.loc[:,[col for col in impResidDf.columns if col != 0]]\n",
    "impResidDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impResidDf.to_csv('/home/lindb/eckertlab/wbp/piMASS/impResidDf.txt',header=True,index=True,sep=\"\\t\")\n",
    "misResidDf.to_csv('/home/lindb/eckertlab/wbp/piMASS/misResidDf.txt',header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 6 - normal qunatile transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i impResidDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i misResidDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "htpopx  = qqnorm(impResidDf$ht_pop,plot.it=F)$x\n",
    "bfpopx  = qqnorm(impResidDf$bf_pop,plot.it=F)$x\n",
    "rspopx  = qqnorm(impResidDf$rs_pop,plot.it=F)$x\n",
    "c13popx = qqnorm(impResidDf$c13_pop,plot.it=F)$x\n",
    "n15popx = qqnorm(impResidDf$n15_pop,plot.it=F)$x\n",
    "htfamx  = qqnorm(impResidDf$ht_fam,plot.it=F)$x\n",
    "bffamx  = qqnorm(impResidDf$bf_fam,plot.it=F)$x\n",
    "rsfamx  = qqnorm(impResidDf$rs_fam,plot.it=F)$x\n",
    "c13famx = qqnorm(impResidDf$c13_fam,plot.it=F)$x\n",
    "n15famx = qqnorm(impResidDf$n15_fam,plot.it=F)$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf['htpopx'] = r('htpopx')\n",
    "impResidDf['bfpopx'] = r('bfpopx')\n",
    "impResidDf['rspopx'] = r('rspopx')\n",
    "impResidDf['c13popx'] = r('c13popx')\n",
    "impResidDf['n15popx'] = r('n15popx')\n",
    "impResidDf['htfamx'] = r('htfamx')\n",
    "impResidDf['bffamx'] = r('bffamx')\n",
    "impResidDf['rsfamx'] = r('rsfamx')\n",
    "impResidDf['c13famx'] = r('c13famx')\n",
    "impResidDf['n15famx'] = r('n15famx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impResidDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "htpopx  = qqnorm(misResidDf$ht_pop,plot.it=F)$x\n",
    "bfpopx  = qqnorm(misResidDf$bf_pop,plot.it=F)$x\n",
    "rspopx  = qqnorm(misResidDf$rs_pop,plot.it=F)$x\n",
    "c13popx = qqnorm(misResidDf$c13_pop,plot.it=F)$x\n",
    "n15popx = qqnorm(misResidDf$n15_pop,plot.it=F)$x\n",
    "htfamx  = qqnorm(misResidDf$ht_fam,plot.it=F)$x\n",
    "bffamx  = qqnorm(misResidDf$bf_fam,plot.it=F)$x\n",
    "rsfamx  = qqnorm(misResidDf$rs_fam,plot.it=F)$x\n",
    "c13famx = qqnorm(misResidDf$c13_fam,plot.it=F)$x\n",
    "n15famx = qqnorm(misResidDf$n15_fam,plot.it=F)$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misResidDf['htpopx'] = r('htpopx')\n",
    "misResidDf['bfpopx'] = r('bfpopx')\n",
    "misResidDf['rspopx'] = r('rspopx')\n",
    "misResidDf['c13popx'] = r('c13popx')\n",
    "misResidDf['n15popx'] = r('n15popx')\n",
    "misResidDf['htfamx'] = r('htfamx')\n",
    "misResidDf['bffamx'] = r('bffamx')\n",
    "misResidDf['rsfamx'] = r('rsfamx')\n",
    "misResidDf['c13famx'] = r('c13famx')\n",
    "misResidDf['n15famx'] = r('n15famx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "misResidDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impResidDf.sort_index(inplace=True) #samples in phenotype file must be in same order as mean genotype file\n",
    "misResidDf.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impResidDf.to_csv('/home/lindb/eckertlab/wbp/piMASS/impResidDf.txt',header=True,index=True,sep=\"\\t\")\n",
    "misResidDf.to_csv('/home/lindb/eckertlab/wbp/piMASS/misResidDf.txt',header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - create piMASS pheno infiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piM_dir = '/home/lindb/eckertlab/wbp/piMASS/infiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/impResidDf.txt',sep=\"\\t\",header=0)\n",
    "misResidDf.index = [x for x in misResidDf['Unnamed: 0']]\n",
    "misResidDf = misResidDf.loc[:,misResidDf.columns[1:]]\n",
    "misResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/impResidDf.txt',sep=\"\\t\",header=0)\n",
    "impResidDf.index = [x for x in impResidDf['Unnamed: 0']]\n",
    "impResidDf = impResidDf.loc[:,impResidDf.columns[1:]]\n",
    "impResidDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impResidDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misResidDf = misResidDf.replace('NaN',\"NA\")\n",
    "impResidDf = impResidDf.replace('NaN',\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in misResidDf.columns[-10:]:\n",
    "    filE = os.path.join(piM_dir,str(col)+'_mis.txt')\n",
    "    print filE,len(misResidDf[col])\n",
    "    misResidDf[col].to_csv(filE,header=None, index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in impResidDf.columns[-10:]:\n",
    "    filE = os.path.join(piM_dir,str(col)+'_imp.txt')\n",
    "    print filE,len(impResidDf[col])\n",
    "    impResidDf[col].to_csv(filE,header=None,index=False,sep=\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - create piMASS runfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/home/lindb/eckertlab/wbp/piMASS/infiles2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def create_imp_pimass_run_files(num_runs):\n",
    "    phenos = ['htpopx_imp', 'bfpopx_imp', 'rspopx_imp','c13popx_imp','n15popx_imp','htfamx_imp','bffamx_imp','rsfamx_imp','c13famx_imp','n15famx_imp']\n",
    "    for p in phenos:\n",
    "        with open(os.path.join(file_dir, \"%s_run.txt\" % p), \"w\") as o:\n",
    "            for i in xrange(num_runs):\n",
    "                cmd = \"~/g/src/pimass/pimass-lin \\\n",
    "-g imppifileIntersection.txt \\\n",
    "-p %s.txt -pos Intxn_loc.txt \\\n",
    "-o pimass_%s_out_%d \\\n",
    "-w 1000000 \\\n",
    "-s 10000000 \\\n",
    "-num 500 \\\n",
    "-smin 1 \\\n",
    "-smax 100 \\\n",
    "-hmin 0.01 \\\n",
    "-hmax 0.9 \\\n",
    "-pmin 1 \\\n",
    "-pmax 1000 \\\n",
    "-r %.0f\" % (p, p, i, int(random.getrandbits(32)))\n",
    "                o.write(\"%s\\n\" % cmd) \n",
    "\n",
    "def create_imp_qsub_files():\n",
    "    files = !ls {file_dir}*imp_run.txt\n",
    "    for f in files[-10:]:\n",
    "        print f\n",
    "        with open(\"%s_qsub.sh\" % f[:-4], \"w\") as o:\n",
    "            o.write(\"\"\"#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N %s\n",
    "#$ -cwd\n",
    "parallel -a %s\n",
    "\"\"\" % (os.path.basename(f), f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_imp_pimass_run_files(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_imp_qsub_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mis_pimass_run_files(num_runs):\n",
    "    phenos = ['htpopx_mis', 'bfpopx_mis', 'rspopx_mis','c13popx_mis','n15popx_mis','htfamx_mis','bffamx_mis','rsfamx_mis','c13famx_mis','n15famx_mis']\n",
    "    for p in phenos:\n",
    "        with open(os.path.join(file_dir, \"%s_run.txt\" % p), \"w\") as o:\n",
    "            for i in xrange(num_runs):\n",
    "                cmd = \"~/g/src/pimass/pimass-lin \\\n",
    "-g mispifileIntersection.txt \\\n",
    "-p %s.txt -pos Intxn_loc.txt \\\n",
    "-o pimass_%s_out_%d \\\n",
    "-w 1000000 \\\n",
    "-s 10000000 \\\n",
    "-num 500 \\\n",
    "-smin 1 \\\n",
    "-smax 100 \\\n",
    "-hmin 0.01 \\\n",
    "-hmax 0.9 \\\n",
    "-pmin 1 \\\n",
    "-pmax 1000 \\\n",
    "-r %.0f\" % (p, p, i, int(random.getrandbits(32)))\n",
    "                o.write(\"%s\\n\" % cmd) \n",
    "\n",
    "def create_mis_qsub_files():\n",
    "    files = !ls {file_dir}*mis_run.txt\n",
    "    print len(files)\n",
    "    for f in files[-10:]:\n",
    "        print f[:-4]\n",
    "        with open(\"%s_qsub.sh\" % f[:-4], \"w\") as o:\n",
    "            o.write(\"\"\"#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N %s\n",
    "#$ -cwd\n",
    "parallel -a %s\n",
    "\"\"\" % (os.path.basename(f), f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_mis_pimass_run_files(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_mis_qsub_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!find -type f -name '*sh' | time parallel -j+0 --eta 'qsub {}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Explore piMASS outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = '/home/lindb/eckertlab/wbp/piMASS/infiles2/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_logs = OrderedDict()\n",
    "mis_logs = OrderedDict()\n",
    "imp_mcmc = OrderedDict()\n",
    "mis_mcmc = OrderedDict()\n",
    "imp_path = OrderedDict()\n",
    "mis_path  = OrderedDict()\n",
    "imp_snp  = OrderedDict()\n",
    "mis_snp   = OrderedDict()\n",
    "imp_gamma = OrderedDict()\n",
    "mis_gamma = OrderedDict()\n",
    "\n",
    "for root,dirs,files in os.walk(out_dir):\n",
    "    for f in files:\n",
    "        fs = f.split(\"_\")\n",
    "        pheno = fs[1]\n",
    "        #print f,fs,pheno\n",
    "        if pheno not in imp_logs.keys():\n",
    "            imp_logs[pheno]  = []\n",
    "            mis_logs[pheno]  = []\n",
    "            imp_mcmc[pheno]  = []\n",
    "            mis_mcmc[pheno]  = []\n",
    "            imp_path[pheno]  = []\n",
    "            mis_path[pheno]  = []\n",
    "            imp_snp[pheno]   = [] \n",
    "            mis_snp[pheno]   = []\n",
    "            imp_gamma[pheno] = []\n",
    "            mis_gamma[pheno] = []\n",
    "        if 'path' in f:\n",
    "            if 'imp' in f:\n",
    "                print f,\"imp\"\n",
    "                imp_path[pheno].append(os.path.join(root,f))\n",
    "            if 'mis' in f:\n",
    "                print f,\"mis\"\n",
    "                mis_path[pheno].append(os.path.join(root,f))\n",
    "        if 'log' in f:\n",
    "            if 'imp' in f:\n",
    "                imp_logs[pheno].append(os.path.join(root,f))\n",
    "            if 'mis' in f:\n",
    "                mis_logs[pheno].append(os.path.join(root,f))\n",
    "        if 'mcmc' in f:\n",
    "            if 'imp' in f:\n",
    "                imp_mcmc[pheno].append(os.path.join(root,f))\n",
    "            if 'mis' in f:\n",
    "                mis_mcmc[pheno].append(os.path.join(root,f))\n",
    "        if 'snp' in f:\n",
    "            if 'imp' in f:\n",
    "                imp_snp[pheno].append(os.path.join(root,f))\n",
    "            if 'mis' in f:\n",
    "                mis_snp[pheno].append(os.path.join(root,f))\n",
    "        if 'gamma' in f:\n",
    "            if 'imp' in f:\n",
    "                imp_gamma[pheno].append(os.path.join(root,f))\n",
    "            if 'mis' in f:\n",
    "                mis_gamma[pheno].append(os.path.join(root,f))\n",
    "\n",
    "logDict = OrderedDict()\n",
    "pathDict = OrderedDict()\n",
    "mcmcDict = OrderedDict()\n",
    "snpDict = OrderedDict()\n",
    "gammaDict = OrderedDict()\n",
    "\n",
    "logDict['imp'] = imp_logs\n",
    "logDict['mis'] = mis_logs\n",
    "pathDict['imp'] = imp_path\n",
    "pathDict['mis'] = mis_path\n",
    "mcmcDict['imp'] = imp_mcmc\n",
    "mcmcDict['mis'] = mis_mcmc\n",
    "snpDict['imp'] = imp_snp\n",
    "snpDict['mis'] = mis_snp\n",
    "gammaDict['imp'] = imp_gamma\n",
    "gammaDict['mis'] = mis_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = [x for x in imp_path.keys()]\n",
    "phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mis_logs['c13famx'], len(mis_path['bffamx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData = OrderedDict()\n",
    "for i,dic in enumerate(pathDict):\n",
    "    print i\n",
    "    pathData[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        pathData[i][pheno] = []\n",
    "        DFs = [pd.read_csv(x,sep=\"\\t\") for x in pathDict[i][pheno]]\n",
    "        for df in DFs:\n",
    "            df.columns = [x.strip() for x in df.columns]\n",
    "        pathData[i][pheno] = [x.ix[:,:-1] for x in DFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData[1]['c13famx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathData[1]['c13famx'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see if std is low across runs for a given phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdData = OrderedDict()\n",
    "for i,dic in enumerate(pathData):\n",
    "    stdData[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        stdData[i][pheno] = []\n",
    "        for x in pathData[i][pheno]: #for each dataframe\n",
    "            stdData[i][pheno].append(np.mean(x[u'hh']))\n",
    "            #break\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change to column name used to create stdData above to toggle through values.\n",
    "for x in stdData[0]:\n",
    "    print x\n",
    "    print np.mean(stdData[0][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in stdData[0]:\n",
    "    print x\n",
    "    print np.std(stdData[0][x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Get sig SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData = OrderedDict()\n",
    "for i,dic in enumerate(mcmcDict):\n",
    "    print i\n",
    "    mcmcData[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        mcmcData[i][pheno] = []\n",
    "        DFs = [pd.read_csv(x,sep=\"\\t\") for x in mcmcDict[i][pheno]]\n",
    "        for df in DFs:\n",
    "            df.columns = [x.strip() for x in df.columns]\n",
    "        mcmcData[i][pheno] = [x.ix[:,:-1] for x in DFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData[0]['c13famx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "an_dir = '/home/lindb/eckertlab/wbp/piMASS/analyses2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc = OrderedDict()\n",
    "for i,dic in enumerate(mcmcDict): #0 = imp, 1 = mis\n",
    "    mcmc[i] = OrderedDict()\n",
    "    y = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        mcmc[i][pheno] = pd.DataFrame()\n",
    "        for j,f in enumerate(sorted(mcmcDict[i][pheno])):\n",
    "            tdf = pd.read_csv(f,sep=\"\\t\")\n",
    "            tdf.columns = [\"%s_%s\" % (x.strip(), j) for x in tdf.columns]\n",
    "            mcmc[i][pheno] = pd.concat([mcmc[i][pheno], tdf], axis=1)\n",
    "        mcmc[i][pheno].to_csv(os.path.join(an_dir,'%s_%s_mcmcALL.txt' % (y,pheno)),header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hmean_row(row):\n",
    "    try:\n",
    "        return sp.stats.hmean(row)\n",
    "    except ValueError as e:\n",
    "        return np.nan\n",
    "    \n",
    "def get_hmean(df, col_pattern):\n",
    "    cols = ['rs','chr']\n",
    "    cols.extend([\"%s_hmean\" % x for x in col_pattern])\n",
    "    d = pd.DataFrame(columns=cols, index=df.index)\n",
    "    d['rs'] = df.rs_1.values\n",
    "    d[\"chr\"] = df.chr_1.values\n",
    "    for cp in col_pattern:\n",
    "        d[\"%s_hmean\" % cp] = np.abs(df[[x for x in df if cp in x]]).apply(get_hmean_row, axis=1).values\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmean = OrderedDict()\n",
    "for i,dic in enumerate(mcmc):\n",
    "    hmean[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        hmean[i][pheno] = get_hmean(mcmc[i][pheno],[\"postrb\",\"betarb\"])\n",
    "for i,dic in enumerate(hmean):\n",
    "    x = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        hmean[i][pheno].to_csv(os.path.join(an_dir + str('/1hmean'),'%s_%s_hmean.txt' % (x,pheno)),header=True,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmean = OrderedDict()\n",
    "hmean['imp'] = OrderedDict()\n",
    "hmean['mis'] = OrderedDict()\n",
    "for root,dirs,files in os.walk('/home/lindb/eckertlab/wbp/piMASS/analyses2/1hmean/'):\n",
    "    for f in files:\n",
    "        print f\n",
    "        if 'imp' in f:\n",
    "            splits = f.split(\"_\")\n",
    "            phen = splits[1]\n",
    "            hmean['imp'][phen] = pd.read_csv(os.path.join(root,f),sep=\"\\t\", header=0)\n",
    "        if 'mis' in f:\n",
    "            splits = f.split(\"_\")\n",
    "            phen = splits[1]\n",
    "            hmean['mis'][phen] = pd.read_csv(os.path.join(root,f),sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_difference(x, y):\n",
    "    x = float(x)\n",
    "    y = float(y)\n",
    "    return (np.abs(x-y)/np.mean([x, y]))*100\n",
    "\n",
    "def get_quantile_max(name, data, q):\n",
    "    d = data.quantile(q)\n",
    "    d.index = [str(x) for x in d.index]\n",
    "    d['median_val'] = data.median()\n",
    "    d['mean_val'] = data.mean()\n",
    "    d['cutoff'] = 0.01\n",
    "    #added start\n",
    "    d['x995_cutoff'] = percent_difference(d['0.995'],d['cutoff'])\n",
    "    d['x995_median'] = percent_difference(d['0.995'],d['median_val'])\n",
    "    d['strinj_cutoff'] = d['0.995']\n",
    "    #added end\n",
    "    d[\"x99_cutoff\"] = percent_difference(d['0.99'], d['cutoff'])\n",
    "    d[\"x99_median\"] =  percent_difference(d['0.99'], d['median_val'])\n",
    "    d[\"x95_cutoff\"] = percent_difference(d['0.95'], d['cutoff'])\n",
    "    d[\"x95_median\"] =  percent_difference(d['0.95'], d['median_val'])\n",
    "    d['relaxed_cutoff'] = d['0.99']\n",
    "    d['min'] = data.min()\n",
    "    d['max'] = data.max()\n",
    "    d.name = name\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quant = OrderedDict()\n",
    "for i,dic in enumerate(hmean):\n",
    "    quant[i] = OrderedDict()\n",
    "    x = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        quant[i][pheno] = get_quantile_max(str(pheno),hmean[i][pheno].postrb_hmean,[0.95,0.99])\n",
    "        quant[i][pheno].to_csv(os.path.join(an_dir + str('/2quant'),\"%s_%s_quant.txt\" % (x,pheno)),header=True,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "an_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "quant2 = OrderedDict()\n",
    "for i,dic in enumerate(hmean.items()):\n",
    "    quant2[i] = OrderedDict()\n",
    "    x = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        quant2[i][pheno] = get_quantile_max(str(pheno),hmean[i][pheno].postrb_hmean,[0.95,0.99,0.995])\n",
    "        quant2[i][pheno].to_csv(os.path.join(an_dir + str('/2quant'),\"%s_%s_quant2.txt\" % (x,pheno)),header=True,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantDF = pd.DataFrame()\n",
    "for i,dic in enumerate(quant):\n",
    "    y = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        test = pd.DataFrame(quant[i][pheno])\n",
    "        test.columns = [\"%s_%s\" % (y,str(x)) for x in test.columns]\n",
    "        quantDF = pd.concat([quantDF,test],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantDF2 = pd.DataFrame()\n",
    "for i,dic in enumerate(quant):\n",
    "    y = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        test = pd.DataFrame(quant2[i][pheno])\n",
    "        test.columns = [\"%s_%s\" % (y,str(x)) for x in test.columns]\n",
    "        quantDF2 = pd.concat([quantDF2,test],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "an_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantDF.to_csv(os.path.join(an_dir + str('/2quant'),'allquant.txt'),header=True,index=True,sep=\"\\t\")\n",
    "quantDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantDF2.to_csv(os.path.join(an_dir + str('/2quant'),'allquant2.txt'),header=True,index=True,sep=\"\\t\")\n",
    "quantDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quant[1]['htfamx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmean['imp']['bffamx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = hmean['imp'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "an_dir = '/home/lindb/eckertlab/wbp/piMASS/analyses2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_snps = OrderedDict()\n",
    "for i,dic in enumerate(hmean):\n",
    "    x = ['imp','mis'][i]\n",
    "    sig_snps[x] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        sig_snps[x][pheno] = hmean[x][pheno][hmean[x][pheno].postrb_hmean >= 0.01]\n",
    "        sig_snps[x][pheno].to_csv(os.path.join(an_dir + str('/3sig_snps'),\"%s_%s_sigSNPS.txt\" % (x,pheno)),header=True,Index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_snps = OrderedDict()\n",
    "for i,dic in enumerate(quant):\n",
    "    x = ['imp','mis'][i]\n",
    "    sig_snps[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        sig_snps[i][pheno] = hmean[i][pheno][hmean[i][pheno].postrb_hmean >= 0.01]\n",
    "        sig_snps[i][pheno].to_csv(os.path.join(an_dir + str('/3sig_snps'),\"%s_%s_sigSNPS.txt\" % (x,pheno)),header=True,Index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_snps[1]['rspopx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_snps = OrderedDict()\n",
    "for i,dic in enumerate(quant):\n",
    "    x = ['imp','mis'][i]\n",
    "    rel_snps[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        rel_snps[i][pheno] = hmean[i][pheno][hmean[i][pheno].postrb_hmean > quant[i][pheno].relaxed_cutoff]\n",
    "        rel_snps[i][pheno].to_csv(os.path.join(an_dir + str('/4relaxed'),\"%s_%s_relSNPS.txt\" % (x,pheno)),header=True,Index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strnj_snps = OrderedDict()\n",
    "for i,dic in enumerate(quant2.items()):\n",
    "    x = ['imp','mis'][i]\n",
    "    strnj_snps[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        strnj_snps[i][pheno] = hmean[i][pheno][hmean[i][pheno].postrb_hmean > quant2[i][pheno].strinj_cutoff]\n",
    "        strnj_snps[i][pheno].to_csv(os.path.join(an_dir + str('/5stringent'),\"%s_%s_strinjSNPS.txt\" % (x,pheno)),header=True,Index=True,sep=\"\\t\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,dic in enumerate(strnj_snps.items()):\n",
    "    x = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        print \"%s_%s\" % (x,pheno)\n",
    "        print len(strnj_snps[i][pheno])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,dic in enumerate(rel_snps.items()):\n",
    "    x = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        print \"%s_%s\" % (x,pheno)\n",
    "        print len(rel_snps[i][pheno])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, dic in enumerate(sig_snps.items()):\n",
    "    x = ['imp','mis'][i]\n",
    "    for pheno in phenos:\n",
    "        print \"%s_%s\" % (x,pheno)\n",
    "        print len(sig_snps[i][pheno])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get input for SQUAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regress dosages against phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"/home/lindb/eckertlab/wbp/bowtie2.1/bowtierun/dup_dir/WBP_IDS_MATCHED_POP_FINAL_110915.xlsx\")\n",
    "for idx, row in test.iterrows():\n",
    "    sample = str(row['ID'])\n",
    "    if len(sample) == 1:\n",
    "        test.loc[idx,'ID'] = ''.join(['0','0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 2:\n",
    "        test.loc[idx,'ID'] = ''.join(['0',sample,'compiled_sorted'])\n",
    "    if len(sample) == 3:\n",
    "        test.loc[idx,'ID'] = ''.join([sample,'compiled_sorted'])\n",
    "idxlst = []\n",
    "samplst = []\n",
    "for idx,row in test.iterrows():\n",
    "    #print str(test.loc[idx,'ID'])\n",
    "    if ('sorted' in str(test.loc[idx,'ID'])) and (str(test.loc[idx,'ID']) not in samplst):\n",
    "        idxlst.append(idx)\n",
    "        samplst.append(str(test.loc[idx,'ID']))\n",
    "test = test.loc[idxlst,:]\n",
    "test.index = [x for x in test['ID']]\n",
    "#new = pd.DataFrame(missingData.loc[:,missingData.columns[2:14]])\n",
    "test = pd.DataFrame(test.loc[:,[col for idx,col in enumerate(test.columns) if idx != 2]])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.loc[[x for x in new_imppifile.columns[3:]],:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(test.index),len(new_imppifile.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#want to regress dosages from a single locus against predictions of mother phenotype\n",
    "# x = sample-specific dosage\n",
    "# y = sample-specific pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_imppifile = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/imppifileIntersection.txt',header=None,sep=\"\\t\")\n",
    "new_mispifile = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/mispifileIntersection.txt',header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/IntersectionColNames.txt',header=None,sep=\"\\t\")\n",
    "columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_imppifile.columns = [x for x in columns[0]]\n",
    "new_imppifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_mispifile.columns = [x for x in columns[0]]\n",
    "new_mispifile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impresiddf = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/impResidDf.txt',header=0,index_col=0,sep=\"\\t\")\n",
    "misresiddf = pd.read_csv('/home/lindb/eckertlab/wbp/piMASS/misResidDf.txt',header=0,index_col=0,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impresiddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misresiddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resids = OrderedDict()\n",
    "resids['imp'] = impresiddf\n",
    "resids['mis'] = misresiddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pifiles = OrderedDict()\n",
    "pifiles['imp'] = new_imppifile\n",
    "pifiles['mis'] = new_mispifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = test.columns[5:]\n",
    "phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsets = ['imp','mis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dset in dsets:\n",
    "    print dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenots = OrderedDict()\n",
    "for dset in pifiles.keys():\n",
    "    phenots[dset] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        lst = resids[dset][pheno].values.tolist()\n",
    "        phenots[dset][pheno] = pd.DataFrame(resids[dset].loc[resids[dset].index[np.where(np.array(pd.notnull(lst)))[0].tolist()],pheno])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phenots[dset][pheno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pifiles[dset].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is what I used for the final alpha values\n",
    "#this is what I used to recalculate alphas making sure that the df was being read in as numbers\n",
    "alphas = OrderedDict() #k = imp or mis, v = data\n",
    "rowz   = OrderedDict()\n",
    "for dset in dsets:\n",
    "    print \"starting\",dset\n",
    "    count = 0\n",
    "    row_idx = []\n",
    "    alphas[dset] = OrderedDict()\n",
    "    \n",
    "    for row in pifiles[dset].index: #for each locus\n",
    "        lineDict = OrderedDict()\n",
    "        row_idx.append(pifiles[dset].loc[row,'locus'])\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print \"rowCount =\",count\n",
    "        for pheno in phenos:     #for each phenotype\n",
    "            df = pd.DataFrame()\n",
    "            phenot = phenots[dset][pheno]\n",
    "            dosages = pd.DataFrame(pifiles[dset].loc[row,phenot.index.tolist()])\n",
    "            dosages.columns = ['dosages']\n",
    "            \n",
    "            dosages = dosages.dropna()\n",
    "            phenot = phenot[phenot.index.isin(dosages.index)]\n",
    "            \n",
    "            df = pd.merge(phenot,dosages,left_index=True,right_index=True)\n",
    "            df = df.astype(float)\n",
    "            \n",
    "            formula = '%s~dosages' % str(pheno)\n",
    "            lineDict[str(pheno)] = smf.ols(formula,df).fit().params[1] # = alpha\n",
    "            #alphas[i].loc[row,str(pheno)] = alpha\n",
    "            #break\n",
    "        alphas[dset][row] = lineDict\n",
    "        #break\n",
    "    rowz[dset] = row_idx\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(alphas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flz = OrderedDict()\n",
    "flz['imp'] = '/home/lindb/eckertlab/wbp/piMASS/analyses2/6alphas/new_imputed_alphas.txt'\n",
    "flz['mis'] = '/home/lindb/eckertlab/wbp/piMASS/analyses2/6alphas/new_missing_alphas.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas['imp'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dset,v in alphas.items():\n",
    "    for row,data in alphas[dset].items():\n",
    "        print row\n",
    "        print '\\t'.join([str(x) for x in alphas[dset][row].values()])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'\\t'.join(alphas[dset][0].keys()) + str('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dset in alphas.keys():\n",
    "    print flz[dset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dset in alphas.keys():\n",
    "    filE = flz[dset]\n",
    "    with open(filE,'w') as o:\n",
    "        rowCount = 0\n",
    "        line = '\\t'.join(alphas[dset][0].keys()) + str('\\n')\n",
    "        o.write(\"%s\" % line)\n",
    "        for row,data in alphas[dset].items():\n",
    "            line = '\\t'.join(str(x) for x in alphas[dset][row].values()) + str('\\n')\n",
    "            o.write(\"%s\" % line)\n",
    "            rowCount += 1\n",
    "            if rowCount % 1000==0:\n",
    "                print \"writing %s file\" % dset,\"line\",rowCount\n",
    "    o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(alphas['imp'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(alphas['mis'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impalphas = pd.read_csv(flz['imp'],header=0,sep=\"\\t\")\n",
    "impalphas.index = rowz['imp']\n",
    "impalphas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misalphas = pd.read_csv(flz['mis'],header=0,sep='\\t')\n",
    "misalphas.index = rowz['mis']\n",
    "misalphas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(misalphas.index),len(impalphas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misalphas.to_csv('/home/lindb/eckertlab/wbp/piMASS/analyses2/6alphas/new_missing_alphasHEADROW.txt',sep='\\t',header=True,index=True)\n",
    "impalphas.to_csv('/home/lindb/eckertlab/wbp/piMASS/analyses2/6alphas/new_imputed_alphasHEADROW.txt',sep='\\t',header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in impalphas.columns:\n",
    "    print impalphas[i].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in impalphas.columns:\n",
    "    print impalphas[i].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in misalphas.columns:\n",
    "    print misalphas[i].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in misalphas.columns:\n",
    "    print misalphas[i].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phenot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dosages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(dosages.loc['020compiled_sorted','dosages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dos = dosages.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenot.index.isin(dos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ph = phenot[phenot.index.isin(dos.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ph.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenos = ['c13popx',\n",
    " 'rspopx',\n",
    " 'htfamx',\n",
    " 'bfpopx',\n",
    " 'n15popx',\n",
    " 'rsfamx',\n",
    " 'bffamx',\n",
    " 'c13famx',\n",
    " 'htpopx',\n",
    " 'n15famx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData = OrderedDict()\n",
    "for dset in mcmcDict.keys():\n",
    "    mcmcData[dset] = OrderedDict()\n",
    "    print '\\t',dset\n",
    "    for pheno in phenos:\n",
    "        print pheno\n",
    "        mcmcData[dset][pheno] = []\n",
    "        DFs =[pd.read_csv(x,sep=\"\\t\") for x in mcmcDict[dset][pheno]]\n",
    "\n",
    "        count = 0\n",
    "        for df in DFs:\n",
    "            df.columns = [\"_\".join([x.strip(),str(count)]) for x in df.columns]\n",
    "            count += 1\n",
    "        mcmcData[dset][pheno] = [x.ix[:,:-1] for x in DFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData['imp']['c13popx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData['imp']['c13popx'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dset in mcmcData.keys():\n",
    "    for pheno in mcmcData[dset].keys():\n",
    "        for df in mcmcData[dset][pheno]:\n",
    "            df.index = df[df.columns[0]].values.tolist()\n",
    "            #mcmcData[dset][pheno] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmcData['imp']['c13popx'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDF = OrderedDict()\n",
    "dset = 'imp'\n",
    "allDF[dset] = OrderedDict()\n",
    "for pheno in mcmcData[dset].keys():\n",
    "    print pheno\n",
    "    allDF[dset][pheno] = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(mcmcData[dset][pheno][9],mcmcData[dset][pheno][0],left_index=True,right_index=True),mcmcData[dset][pheno][1],left_index=True,right_index=True),mcmcData[dset][pheno][2],left_index=True,right_index=True),mcmcData[dset][pheno][3],left_index=True,right_index=True),mcmcData[dset][pheno][4],left_index=True,right_index=True),mcmcData[dset][pheno][5],left_index=True,right_index=True),mcmcData[dset][pheno][6],left_index=True,right_index=True),mcmcData[dset][pheno][7],left_index=True,right_index=True),mcmcData[dset][pheno][8],left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in allDF['imp'].keys():\n",
    "    filE = '/home/lindb/eckertlab/wbp/piMASS/Final/imp_%s_allBETASandPIPS.txt' %pheno\n",
    "    allDF['imp'][pheno].to_csv(filE,header=True,index=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#look at overlap between missing and imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('/home/lindb/wbp/piMASS/analyses2/7xstringent')\n",
    "files = [os.path.join('/home/lindb/wbp/piMASS/analyses2/7xstringent',f) for f in files]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dictionary of SNPs\n",
    "snpDict = OrderedDict()\n",
    "snpDict['imp'] = OrderedDict()\n",
    "snpDict['mis'] = OrderedDict()\n",
    "for f in files:\n",
    "    dset = os.path.basename(f).split(\"_\")[0]\n",
    "    pheno = os.path.basename(f).split(\"_\")[1]\n",
    "    df = pd.read_csv(f,header=0,index_col=0,sep=\"\\t\")\n",
    "    snps = df['rs'].tolist()\n",
    "    snpDict[dset][pheno] = snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in snpDict['imp'].keys():\n",
    "    print 'snps',len(snpDict['imp'][pheno]),len(snpDict['mis'][pheno])\n",
    "    overlap = set(snpDict['imp'][pheno]).intersection(set(snpDict['mis'][pheno]))\n",
    "    print pheno, len(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(coda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc = r('mcmc')\n",
    "mcmc_list = r('mcmc.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathMCMC_lst = OrderedDict()\n",
    "for i,x in enumerate(pathData): #0 = imp, 1 = mis\n",
    "    print i\n",
    "    pathMCMC_lst[i] = OrderedDict()\n",
    "    for pheno in phenos:\n",
    "        pathMCMC_lst[i][pheno] = []\n",
    "        for x in pathData[i][pheno]:\n",
    "            pathMCMC_lst[i][pheno].append(mcmc(pd2ri.DataFrame(x.sample(frac=1).sort_index())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathMCMC_lst[0]['htfamx'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_mcmc_list['htfamx'][0]\n",
    "#<Matrix - Python:0x2b6422e37e60 / R:0x8053bc0>\n",
    "#[0.271000, 0.156000, 0.047000, ..., -1.786000, -13.826000, -14.495000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_pathMCMC_htpopx = mcmc_list(pathMCMC_lst[0]['htpopx'])\n",
    "imp_pathMCMC_htfamx = mcmc_list(pathMCMC_lst[0]['htfamx'])\n",
    "imp_pathMCMC_n15popx = mcmc_list(pathMCMC_lst[0]['n15popx'])\n",
    "imp_pathMCMC_bffamx = mcmc_list(pathMCMC_lst[0]['bffamx'])\n",
    "imp_pathMCMC_c13popx = mcmc_list(pathMCMC_lst[0]['c13popx'])\n",
    "imp_pathMCMC_bfpopx = mcmc_list(pathMCMC_lst[0]['bfpopx'])\n",
    "imp_pathMCMC_c13famx = mcmc_list(pathMCMC_lst[0]['c13famx'])\n",
    "imp_pathMCMC_rspopx = mcmc_list(pathMCMC_lst[0]['rspopx'])\n",
    "imp_pathMCMC_n15famx = mcmc_list(pathMCMC_lst[0]['n15famx'])\n",
    "imp_pathMCMC_rsfamx = mcmc_list(pathMCMC_lst[0]['rsfamx'])\n",
    "\n",
    "mis_pathMCMC_htpopx = mcmc_list(pathMCMC_lst[1]['htpopx'])\n",
    "mis_pathMCMC_htfamx = mcmc_list(pathMCMC_lst[1]['htfamx'])\n",
    "mis_pathMCMC_n15popx = mcmc_list(pathMCMC_lst[1]['n15popx'])\n",
    "mis_pathMCMC_bffamx = mcmc_list(pathMCMC_lst[1]['bffamx'])\n",
    "mis_pathMCMC_c13popx = mcmc_list(pathMCMC_lst[1]['c13popx'])\n",
    "mis_pathMCMC_bfpopx = mcmc_list(pathMCMC_lst[1]['bfpopx'])\n",
    "mis_pathMCMC_c13famx = mcmc_list(pathMCMC_lst[1]['c13famx'])\n",
    "mis_pathMCMC_rspopx = mcmc_list(pathMCMC_lst[1]['rspopx'])\n",
    "mis_pathMCMC_n15famx = mcmc_list(pathMCMC_lst[1]['n15famx'])\n",
    "mis_pathMCMC_rsfamx = mcmc_list(pathMCMC_lst[1]['rsfamx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i imp_pathMCMC_htpopx -i mis_pathMCMC_htpopx -i imp_pathMCMC_htfamx -i imp_pathMCMC_n15popx -i imp_pathMCMC_bffamx -i imp_pathMCMC_c13popx -i imp_pathMCMC_bfpopx -i imp_pathMCMC_c13famx -i imp_pathMCMC_rspopx -i imp_pathMCMC_n15famx -i imp_pathMCMC_rsfamx -i mis_pathMCMC_htfamx -i mis_pathMCMC_n15popx -i mis_pathMCMC_bffamx -i mis_pathMCMC_c13popx -i mis_pathMCMC_bfpopx -i mis_pathMCMC_c13famx -i mis_pathMCMC_rspopx -i mis_pathMCMC_n15famx -i mis_pathMCMC_rsfamx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "eff_imp_htfamx  = lapply(imp_pathMCMC_htfamx,effectiveSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "eff_imp_n15popx = lapply(imp_pathMCMC_n15popx,effectiveSize)\n",
    "eff_imp_htpopx  = lapply(imp_pathMCMC_htpopx,effectiveSize)\n",
    "eff_imp_bffamx  = lapply(imp_pathMCMC_bffamx,effectiveSize)\n",
    "eff_imp_c13popx = lapply(imp_pathMCMC_c13popx,effectiveSize)\n",
    "eff_imp_bfpopx  = lapply(imp_pathMCMC_bfpopx,effectiveSize)\n",
    "eff_imp_c13famx = lapply(imp_pathMCMC_c13famx ,effectiveSize)\n",
    "eff_imp_rspopx  = lapply(imp_pathMCMC_rspopx ,effectiveSize)\n",
    "eff_imp_n15famx = lapply(imp_pathMCMC_n15famx  ,effectiveSize)\n",
    "eff_imp_rsfamx  = lapply(imp_pathMCMC_n15famx  ,effectiveSize)\n",
    "\n",
    "eff_mis_n15popx = lapply(mis_pathMCMC_n15popx,effectiveSize)\n",
    "eff_mis_htpopx  = lapply(mis_pathMCMC_htpopx,effectiveSize)\n",
    "eff_mis_bffamx  = lapply(mis_pathMCMC_bffamx,effectiveSize)\n",
    "eff_mis_c13popx = lapply(mis_pathMCMC_c13popx,effectiveSize)\n",
    "eff_mis_bfpopx  = lapply(mis_pathMCMC_bfpopx,effectiveSize)\n",
    "eff_mis_c13famx = lapply(mis_pathMCMC_c13famx ,effectiveSize)\n",
    "eff_mis_rspopx  = lapply(mis_pathMCMC_rspopx ,effectiveSize)\n",
    "eff_mis_n15famx = lapply(mis_pathMCMC_n15famx  ,effectiveSize)\n",
    "eff_mis_rsfamx  = lapply(mis_pathMCMC_n15famx  ,effectiveSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "eff_imp_htfamx[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_effective_sizes(r_name):\n",
    "    df = pd.DataFrame([pd2ri.ri2py(x) for x in r[r_name]])\n",
    "    test = r[r_name].rx2(1)\n",
    "    df.columns = r('names')(test)\n",
    "    return df\n",
    "ne_htfamx = get_effective_sizes('eff_imp_htfamx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne_htfamx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_effective_sizes('eff_p_htfamx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
